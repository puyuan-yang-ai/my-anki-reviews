好的，我完全理解您的需求了。这是一个非常清晰的计划，通过脚本自动化生成技术文档，并加入了关键的断点续传功能。

让我用自己的语言为您复述一下整个流程，以确保我的理解准确无误：

您希望我编写一个名为 `triton_to_hip_prompts.py` 的 Python 脚本。这个脚本的整体架构和执行流程将高度参考现有的 `hip_to_prompt.py`，但其核心任务和数据处理逻辑有所不同。

**脚本的核心执行流程如下：**

1.  **初始化与加载**：
    *   脚本启动后，会首先加载我们刚刚共同优化好的提示词模板，即 `TritonBench/triton_to_hip/template/CN/v3/` 目录下的 `system_message.txt` 和 `prompt_template.txt`。
    *   同时，它会像参考脚本一样，设置好调用大语言模型（LLM）所需的一切配置。

2.  **输入与断点续传**：
    *   脚本的主要输入是一个名为 `20250709_gaagent_hip_15_execution_failure.jsonl` 的 **JSONL 文件**（每行一个 JSON 对象）。
    *   在开始处理之前，脚本会智能地检查输出文件（如果已存在），读取所有已经成功处理过（即 `"pass": true`）的任务，并将它们过滤掉。这样就实现了高效的**“断点续传”**功能，只处理失败或未处理的任务。

3.  **循环处理核心任务**：
    *   对于每一个需要处理的任务（JSON对象），脚本会执行以下操作：
        a.  从 JSON 对象中提取 `label` 字段，这里面包含了**原始的 Triton 代码**。
        b.  将这段 Triton 代码填入到用户提示词模板 (`prompt_template.txt`) 的 `{triton_code}` 占位符中。
        c.  结合系统提示词 (`system_message.txt`)，构建一个完整的、高度优化的请求。
        d.  将这个完整的请求发送给大语言模型（LLM）进行处理。

4.  **结果处理与丰富化**：
    *   模型返回的结果就是我们需要的**“HIP技术文档”**。
    *   脚本会获取这份文档，并将其作为 `instruction` 字段的值。
    *   同时，脚本会根据 LLM 调用的成败情况，生成两个状态字段：
        *   `pass`: 如果成功获取到 `instruction`，则为 `true`；否则为 `false`。
        *   `error_msg`: 如果 `pass` 为 `false`，这里会记录具体的错误原因（如 "LLM调用失败"）；如果为 `true`，则为 `null`。

5.  **输出与保存**：
    *   最后，脚本会将这个**增强后**的完整 JSON 对象（包含了原始的 `label`, `filename`, `test_code` 以及新增的 `instruction`, `pass`, `error_msg`）追加写入到一个输出文件中。这个输出文件很可能就是输入的那个文件，或者是一个新的结果文件，从而实现了对原始数据集的逐步丰富和完善。

**总结一下数据流就是：**

`原始.jsonl` -> **读取** -> **过滤已完成任务** -> `for-each 未完成任务`: `[Triton Code + Prompt Template -> LLM -> HIP 技术文档]` -> **增强JSON对象** -> **写入/追加** -> `最终丰富的.jsonl`

我的这个复述是否准确地捕捉了您的全部意uto？如果理解无误，我就可以开始为您编写这个 `triton_to_hip_prompts.py` 脚本了。
