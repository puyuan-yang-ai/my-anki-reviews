**主持人**：这次咱们探讨的主题主要围绕查询改写、RAG系统在房地产培训场景中的应用，以及相关技术细节，像大模型的特性、不同检索方式，还有FastAPI与Flask的对比等。先从查询改写说起，它主要目的是优化检索效果，将用户输入精准转化为更适配检索的形式。比如用户输入‘最新房产税政策’，查询改写模块可能就会改写成‘2025年最新商业地产税收政策有哪些变化？’。这里就涉及到改写方式，在简单场景下倾向单一改写，复杂或模糊场景则更适合多查询生成。
**嘉宾**：确实，选择合适的改写方式很关键。像在系统里采用生成多查询策略，一个主查询搭配两个扩展查询，不同查询经过文本、语义、图谱检索后返回不同数量的文档。这不仅要考虑查询生成，排序前还得去重，避免检索到重复内容。说到房地产培训系统的查询改写，它的提示词设计也有讲究，得明确角色、任务、背景、涵盖内容、改写要求和返回格式，还得有示例。
**主持人**：没错，从背景来看，这是面向房地产公司内部员工的培训系统，涵盖法规、知识、技巧等多方面。在改写时，要考虑专业性，把口语化表达转为专业术语；结构化，将零散问题变成有条理的查询；完整性，考虑法规和公司制度，适当扩展查询范围。就像用户问‘合同有什么要注意的’，可以拆分成‘销售合同关键条款’等具体方面。
**嘉宾**：对，这几个方面相辅相成。再看用大模型进行查询改写的原因，从实现角度，大模型理解能力强，能很好把握用户意图，而且实现比规则基础的改写简单；从维护角度，维护成本更低。大模型返回的一个主查询紧扣用户原始意图，两个扩展查询从不同角度补充相关信息。
**主持人**：说到RAG系统，以用户问‘怎么卖房子’为例，主查询可能是‘房地产销售技巧要点’，扩展查询如‘房产销售基础技巧’等。这里返回三个查询是为了平衡检索全面性和系统性能，单一查询结果可能不全面，查询过多又会引入噪声、降低效率。改写后的查询会并行进行文本、语义和图谱检索，这三种检索方式各有目的。
**嘉宾**：确实，文本检索找关键词匹配，语义检索通过向量相似度找相关内容，图谱检索借助知识图谱找知识节点和关系。这三种方式相互补充，文本检索确保准确性，语义检索提供相关性，图谱检索补充结构化知识。在房地产培训系统的RAG流程里，用户输入先改写，生成主查询和扩展查询，然后并行检索，检索结果去重，之后进入重排。
**主持人**：对，从用户输入到形成最终提示词，过程还挺复杂。输入先经查询改写，生成的查询向量化后进行文本和语义检索，实体识别后进行图谱检索，混合检索出500条结果，初步排序选top200，重排模块粗排选100条，精排选10条，构建上下文后与原始输入拼成最终提示词。这里面粗排考虑内容时效性、来源可靠性和完整性，粗排快速过滤噪音，精排进行复杂相似度计算。
**嘉宾**：没错，而且在混合检索和上下文构建阶段还有优化点。混合检索中，根据查询类型动态调整检索方式权重，像事实类查询图谱检索权重可加大，观点类问题语义检索权重加大。上下文构建阶段添加元信息标记，如时效性、可信度，辅助大模型生成更准确回答。说到大模型，LLaMA 1和LLaMA 2的上下文窗口和嵌入维度等都有差异。
**主持人**：是的，LLaMA 1上下文窗口是2048，嵌入维度对所有版本都是4096；LLaMA 2的嵌入维度根据模型大小不同，7B模型是4096，65B模型是8192 ，上下文窗口是4096。由于模型基于自回归机制，最大输入token数包含生成输出，随着生成token增加，输入上下文会增长直到达到上限。像LLaMA 1最大输入token数是2048 ，如果prompt是2000个token，输出最多48个token。
**嘉宾**：确实，这就要求注意输入内容长度管理，避免重要信息因截断丢失。在实际应用中，比如利用检索文档构建上下文时，要为系统提示词和查询预留空间，还得对信息去重、合并和分类。再看RAG项目，输入用户查询后进行改写，生成主查询和扩展查询，并行混合检索，检索结果进入不同模块处理。
**主持人**：对，上下文构建模块输入TOP 10排序结果，输出结构化上下文信息；答案生成模块输入原始查询和结构化上下文构成的提示词，输出答案文本。混合检索模块输入改写后的查询向量表示，输出500条候选结果；重排序模块输入500条候选结果，输出TOP 10结果。另外，在后端API开发上，FastAPI对比Flask有不少优势。
**嘉宾**：没错，FastAPI性能更好，原生支持异步处理，适合RAG系统长时间运算，并发处理能力强，还自带API文档，类型提示支持也更好。在实际项目中，特别适合处理异步操作和高并发的现代应用。在构建context时，要构建结构化context ，利用检索文档构建时，提示词明确了组织信息的要求。
**主持人**：就像给定的检索结果示例，按照要求整理后能形成结构化的上下文。总的来说，这些技术和流程相互配合，从查询改写、检索到结果处理，每个环节都对提升系统性能和回答准确性至关重要。无论是在房地产培训系统这样的特定场景，还是更广泛的RAG应用中，都需要精细把控各个环节，才能为用户提供高质量的服务。
**嘉宾**：非常同意，今天探讨的这些内容涉及多个技术点和应用细节，它们共同构成了一个复杂但高效的信息处理和反馈体系。希望通过我们的讨论，能让大家对这些技术和应用有更清晰深入的理解，在实际工作或学习中更好地运用相关知识。


# 深入剖析RAG系统在房地产培训场景中的应用与技术细节
## 开场
大家好，欢迎来到本期播客。在今天的节目中，我们将深入探讨查询改写、RAG系统在房地产培训场景中的应用，以及相关技术细节，像大模型的特性、不同检索方式，还有FastAPI与Flask的对比等。这些内容不仅在房地产培训领域至关重要，对于理解现代智能信息处理技术也很有帮助。

## 查询改写
查询改写主要目的是优化检索效果，精准地将用户输入转换成更加适合检索的形式。比如用户输入“最新房产税政策”，查询改写模块（小型7B Llama2）可能将其改写成“2025年最新商业地产税收政策有哪些变化？”。这一改写过程看似简单，实则涉及到对用户意图的理解、领域知识的运用以及检索需求的适配。

主流的Query改写方式有单一改写和多查询生成。在简单场景下倾向于单一改写，因为简单场景中用户意图明确，单一改写足以满足检索需求。而在复杂或模糊场景下更倾向于多查询生成，例如当用户的问题比较宽泛、语义模糊时，多查询生成可以从不同角度去探索可能的答案。

在实际系统中，有些会采用生成多查询的策略，像一个主查询搭配两个扩展查询。主查询紧扣用户原始意图，是核心检索方向；扩展查询则从不同角度补充相关信息，拓宽检索范围。而且，不同查询经过文本、语义、图谱检索后会返回不同数量的文档。但在将这些检索结果排序之前，需要先进行去重处理，避免重复信息干扰后续流程。

以房地产培训系统为例，其查询Query改写的提示词设计很关键。要明确角色，比如设定为专业的房地产培训系统查询专家；清楚任务，即对用户查询进行专业化改写；了解背景，这是面向房地产公司内部员工的培训系统，涵盖法律法规、房产知识、销售技巧和话术等内容；还要明确改写要求，像返回1个主查询和2个扩展查询、使用房地产行业标准术语、确保改写后的查询涵盖必要的上下文、每个查询控制在20字以内；以及规定返回格式，并给出示例。这样详细的提示词能引导模型生成高质量的改写查询。

在房地产培训系统的Query改写中，要考虑专业性、结构化和完整性三个方面。专业性要求把用户的口语化表达转成标准专业用语，因为房地产行业有大量专业术语，使用专业用语能提高检索的准确性和专业性。结构化是将用户零散的问题转成更有条理的查询，比如把“合同有什么要注意的”拆分为“销售合同关键条款”“合同签订流程”“风险防控要点”等具体方面，便于更精准地检索相关信息。完整性则是考虑到培训系统要涉及相关法规和公司制度，在改写时适当扩展查询范围，确保把必要信息都覆盖到。

## RAG系统
RAG系统在房地产培训场景中也发挥着重要作用。当用户提出问题，如“怎么卖房子”，改写后的结果包括一个主查询，可能是“房地产销售技巧要点”，以及两个扩展查询，像“房产销售基础技巧”和“新手置业顾问客户开发方法” 。这里选择返回3个查询是经过实践验证的，3个查询能够很好地平衡检索的全面性和系统性能。单一查询可能导致结果不够全面，而过多查询会引入噪声，降低系统效率。

改写后的query会并行地进行文本、语义和图谱检索。文本检索通过找最基础的关键词匹配，能快速定位包含特定关键词的文档，确保检索结果的准确性。语义检索借助向量相似度找相关内容，它可以理解文本的语义含义，找到与查询语义相近的内容，提供相关性。图谱检索则通过知识图谱找到相关的知识节点和关系，补充结构化知识，让检索结果更加全面和深入。这三种检索方式相互补充，共同为用户提供高质量的检索结果。

在房地产培训系统的RAG流程中，用户输入先进入改写模块，生成主查询和两个扩展查询。然后这些查询经过嵌入模型向量化，进行文本检索和语义检索，同时查询使用实体识别后进行图谱检索。混合检索会产生500条结果，先对这500条结果进行初步排序，选出top200，再进入重排模块。重排模块中，粗排筛选出100条，重点是快速过滤掉无关的噪音；精排筛选出10条，主要进行复杂的相似度计算。之后对筛选到的10条内容进行上下文构建，采用结构化的信息组织策略来构建上下文Context，最后将构建的结构化context与用户的原始输入query拼接到prompt模板中，形成最终的prompt提示词。

在这个过程中，有不少优化点。在混合检索阶段，可以根据查询类型动态调整检索方式权重，事实类查询可以加大图谱检索权重，观点类问题加大语义检索权重。在上下文构建阶段，添加元信息标记，如信息的时效性、可信度等，辅助大模型生成更准确的回答。

## 大模型相关
在实际应用中，大模型在查询改写等环节有着重要作用。之所以使用大模型进行查询改写，从实现角度看，大模型理解能力强，可以很好地理解用户意图，而且实现起来比基于规则的改写更简单；从维护角度，其维护成本也更低。

像LLaMA 1和LLaMA 2，它们在上下文窗口和嵌入维度等方面存在差异。LLaMA 1上下文窗口是2048，嵌入维度对所有版本都是4096；LLaMA 2的嵌入维度根据模型大小不同，7B模型是4096，65B模型是8192 ，上下文窗口是4096。由于模型基于自回归机制，最大输入token数包含生成输出。随着生成token增加，输入上下文会不断增长，直到达到上限。所以在使用模型时，要注意输入内容长度管理，避免重要信息因截断丢失。在利用检索文档构建上下文时，要为系统提示词和查询预留空间，还需要对信息去重、合并和分类。

## 后端API开发
在后端API开发方面，FastAPI对比Flask有明显优势。FastAPI性能更好，原生支持异步处理，特别适合RAG系统这种长时间运算的场景，其并发处理能力也更强。而且FastAPI自带API文档（Swagger/ReDoc），类型提示支持也更好。在实际项目中，尤其是处理异步操作和高并发的现代应用，FastAPI已经成为Python后端API开发的主流选择。

## 总结
今天我们深入探讨了查询改写、RAG系统在房地产培训场景中的应用，以及大模型特性、后端API开发等相关技术细节。这些技术和流程相互配合，每个环节都对提升系统性能和回答准确性至关重要。无论是在房地产培训系统这样的特定场景，还是更广泛的RAG应用中，都需要精细把控各个环节，才能为用户提供高质量的服务。希望通过本期播客，能让大家对这些技术和应用有更清晰深入的理解，在实际工作或学习中更好地运用相关知识。感谢大家收听，我们下期再见！ 
