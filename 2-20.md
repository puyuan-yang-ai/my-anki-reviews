

æ„å»ºç»“æ„åŒ–contexté€šå¸¸æœ‰ä¸¤ç§ä¸»æµæ–¹æ³•ã€‚æˆ‘æ¥è¯¦ç»†è§£é‡Šè¿™ä¸¤ç§æ–¹æ³•åŠå…¶ä¼˜ç¼ºç‚¹ï¼š

### æ–¹æ³•ä¸€ï¼šè§„åˆ™åŒ–ä»£ç æ„å»ºï¼ˆæ›´å¿«ã€æˆæœ¬ä½ï¼‰

```python
def build_structured_context(search_results):
    # 1. æŒ‰ä¸»é¢˜åˆ†ç±»
    categorized_results = {
        'technology': [],
        'performance': [],
        'user_feedback': [],
        'others': []
    }
    
    # 2. å¯¹ç»“æœè¿›è¡Œåˆ†ç±»
    for result in search_results:
        category = classify_content(result.content)  # ä½¿ç”¨è§„åˆ™æˆ–ç®€å•åˆ†ç±»å™¨
        categorized_results[category].append(result)
    
    # 3. æ„å»ºç»“æ„åŒ–æ–‡æœ¬
    structured_context = []
    
    # æ·»åŠ æŠ€æœ¯ç›¸å…³ä¿¡æ¯
    if categorized_results['technology']:
        structured_context.append("ã€æŠ€æœ¯æ›´æ–°ã€‘")
        for item in categorized_results['technology']:
            structured_context.append(f"â€¢ {extract_key_points(item.content)}")
            structured_context.append(f"  æ¥æº: {item.source}")
    
    # æ·»åŠ æ€§èƒ½ç›¸å…³ä¿¡æ¯
    if categorized_results['performance']:
        structured_context.append("\nã€æ€§èƒ½è¡¨ç°ã€‘")
        for item in categorized_results['performance']:
            structured_context.append(f"â€¢ {extract_key_points(item.content)}")
    
    return "\n".join(structured_context)
```

### æ–¹æ³•äºŒï¼šä½¿ç”¨LLMæ„å»ºï¼ˆæ›´çµæ´»ã€è´¨é‡é«˜ï¼‰

```python
def build_context_with_llm(search_results):
    # 1. å‡†å¤‡è¾“å…¥
    results_text = "\n".join([
        f"æ–‡æ¡£{i+1}: {result.content}"
        for i, result in enumerate(search_results)
    ])
    
    # 2. æ„å»ºLLMæç¤ºè¯
    prompt = f"""
    è¯·å°†ä»¥ä¸‹{len(search_results)}æ¡æ£€ç´¢ç»“æœæ•´ç†æˆç»“æ„åŒ–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
    
    {results_text}
    
    è¦æ±‚ï¼š
    1. æŒ‰ä¸»é¢˜åˆ†ç±»ç»„ç»‡ä¿¡æ¯
    2. ä½¿ç”¨è¦ç‚¹ç¬¦å·åˆ—å‡ºå…³é”®ä¿¡æ¯
    3. ä¿ç•™ä¿¡æ¯æ¥æº
    4. å»é™¤é‡å¤ä¿¡æ¯
    5. æŒ‰é‡è¦æ€§æ’åº
    
    è¯·ä»¥ä¸‹é¢çš„æ ¼å¼è¾“å‡ºï¼š
    ã€ä¸»é¢˜1ã€‘
    â€¢ å…³é”®ä¿¡æ¯1
    â€¢ å…³é”®ä¿¡æ¯2
    æ¥æºï¼šxxx
    
    ã€ä¸»é¢˜2ã€‘
    ...
    """
    
    # 3. è°ƒç”¨LLM
    structured_context = llm.generate(prompt)
    return structured_context
```

### æ··åˆæ–¹æ³•ï¼ˆæ¨èï¼‰ï¼šç»“åˆä¸¤ç§æ–¹æ³•çš„ä¼˜åŠ¿

```python
def hybrid_context_building(search_results):
    try:
        # 1. é¦–å…ˆå°è¯•ä½¿ç”¨è§„åˆ™æ–¹æ³•
        basic_structure = build_structured_context(search_results)
        
        # 2. ä½¿ç”¨LLMä¼˜åŒ–ç»“æ„
        optimization_prompt = f"""
        è¯·ä¼˜åŒ–ä»¥ä¸‹ç»“æ„åŒ–å†…å®¹ï¼Œä½¿å…¶æ›´åŠ è¿è´¯å’Œæ˜“è¯»ï¼š
        
        {basic_structure}
        
        è¦æ±‚ï¼š
        1. ä¿æŒç°æœ‰çš„ç»“æ„
        2. æ”¹å–„è¡¨è¿°
        3. ç¡®ä¿ä¿¡æ¯å®Œæ•´æ€§
        4. ä¼˜åŒ–ä¿¡æ¯é¡ºåº
        """
        
        final_context = llm.generate(optimization_prompt)
        return final_context
        
    except Exception as e:
        # é™çº§å¤„ç†ï¼šä½¿ç”¨åŸºç¡€è§„åˆ™æ–¹æ³•
        return build_structured_context(search_results)
```

### å…·ä½“ç¤ºä¾‹ï¼š

```python
# è¾“å…¥çš„æ£€ç´¢ç»“æœç¤ºä¾‹
search_results = [
    {
        'content': 'ChatGPTå‘å¸ƒ4.0ç‰ˆæœ¬ï¼Œæ¨ç†èƒ½åŠ›æå‡50%',
        'source': 'OpenAIåšå®¢',
        'timestamp': '2024-03-01'
    },
    {
        'content': 'ç”¨æˆ·åé¦ˆæ–°ç‰ˆæœ¬å“åº”é€Ÿåº¦æå‡æ˜æ˜¾',
        'source': 'ç”¨æˆ·è®ºå›',
        'timestamp': '2024-03-02'
    }
]

# è¾“å‡ºçš„ç»“æ„åŒ–context
structured_context = """
ã€æŠ€æœ¯æ›´æ–°ã€‘
â€¢ ChatGPT 4.0ç‰ˆæœ¬å‘å¸ƒ
â€¢ æ¨ç†èƒ½åŠ›æå‡50%
æ¥æºï¼šOpenAIåšå®¢ (2024-03-01)

ã€ç”¨æˆ·åé¦ˆã€‘
â€¢ å“åº”é€Ÿåº¦æ˜¾è‘—æå‡
â€¢ ç”¨æˆ·ä½“éªŒæ”¹å–„
æ¥æºï¼šç”¨æˆ·è®ºå› (2024-03-02)
"""
```

### é€‰æ‹©å»ºè®®ï¼š

1. **å°è§„æ¨¡ç³»ç»Ÿ**ï¼š
   - ä½¿ç”¨è§„åˆ™æ–¹æ³•
   - å®ç°ç®€å•ï¼Œæˆæœ¬ä½

2. **å¤§è§„æ¨¡ç³»ç»Ÿ**ï¼š
   - ä½¿ç”¨æ··åˆæ–¹æ³•
   - å¯ä»¥å¹³è¡¡æ•ˆç‡å’Œè´¨é‡

3. **å¯¹è´¨é‡è¦æ±‚æé«˜**ï¼š
   - ä½¿ç”¨LLMæ–¹æ³•
   - ç¡®ä¿å†…å®¹ç»„ç»‡æœ€ä¼˜

### æ³¨æ„äº‹é¡¹ï¼š

1. **ä½¿ç”¨è§„åˆ™æ–¹æ³•æ—¶**ï¼š
   - éœ€è¦ç»´æŠ¤è‰¯å¥½çš„åˆ†ç±»è§„åˆ™
   - å®šæœŸæ›´æ–°æå–è§„åˆ™
   - åšå¥½å¼‚å¸¸å¤„ç†

2. **ä½¿ç”¨LLMæ–¹æ³•æ—¶**ï¼š
   - æ³¨æ„æˆæœ¬æ§åˆ¶
   - è®¾ç½®è¶…æ—¶å¤„ç†
   - å‡†å¤‡é™çº§æ–¹æ¡ˆ

3. **ä½¿ç”¨æ··åˆæ–¹æ³•æ—¶**ï¼š
   - åˆç†è®¾ç½®ä»»åŠ¡åˆ†é…
   - ä¼˜åŒ–å¤„ç†æµç¨‹
   - ç›‘æ§æ€§èƒ½æŒ‡æ ‡

ä½ è§‰å¾—å“ªç§æ–¹æ³•æ›´é€‚åˆä½ çš„åœºæ™¯ï¼Ÿæˆ‘å¯ä»¥é’ˆå¯¹å…·ä½“æ–¹æ³•æä¾›æ›´è¯¦ç»†çš„å»ºè®®ã€‚





åœ¨æœ€ç»ˆçš„promptæ‹¼æ¥ä¸­ï¼Œé€šå¸¸ä½¿ç”¨ç”¨æˆ·çš„åŸå§‹é—®é¢˜ï¼ˆè€Œä¸æ˜¯æ”¹å†™åçš„queryï¼‰ï¼ŒåŸå› å¦‚ä¸‹ï¼š

### 1. ä½¿ç”¨åŸå§‹é—®é¢˜çš„åŸå› ï¼š

1. **ä¿æŒè¯­ä¹‰å®Œæ•´æ€§**ï¼š
```python
# ä¾‹å­
original_query = "ChatGPTæœ€è¿‘æœ‰ä»€ä¹ˆæ–°è¿›å±•ï¼Ÿ"
rewritten_queries = [
    "ChatGPT 2024æŠ€æœ¯æ›´æ–°",
    "ChatGPTæœ€æ–°åŠŸèƒ½ç‰¹æ€§",
    "OpenAI ChatGPTå‡çº§"
]

# âœ… æ­£ç¡®åšæ³•ï¼šä½¿ç”¨åŸå§‹é—®é¢˜
final_prompt = f"""
System: è¯·åŸºäºä¸Šä¸‹æ–‡å›ç­”é—®é¢˜

ä¸Šä¸‹æ–‡ï¼š
{structured_context}

ç”¨æˆ·é—®é¢˜ï¼š{original_query}  # ä½¿ç”¨åŸå§‹é—®é¢˜
"""

# âŒ é”™è¯¯åšæ³•ï¼šä½¿ç”¨æ”¹å†™åçš„query
# ç”¨æˆ·é—®é¢˜ï¼šChatGPT 2024æŠ€æœ¯æ›´æ–°  # è¿™æ ·å¯èƒ½æ”¹å˜äº†ç”¨æˆ·åŸå§‹æ„å›¾
```

2. **ç¡®ä¿å›ç­”çš„é’ˆå¯¹æ€§**ï¼š
```python
def construct_prompt(context, query):
    # ä½¿ç”¨åŸå§‹é—®é¢˜å¯ä»¥ç¡®ä¿å›ç­”ç›´æ¥å¯¹åº”ç”¨æˆ·çš„è¡¨è¿°æ–¹å¼
    prompt = f"""
    System: ä½ æ˜¯AIåŠ©æ‰‹ï¼Œè¯·æ³¨æ„ï¼š
    1. ç›´æ¥å›ç­”ç”¨æˆ·çš„åŸå§‹é—®é¢˜
    2. ä½¿ç”¨ç”¨æˆ·å®¹æ˜“ç†è§£çš„è¯­è¨€
    3. ä¿æŒå›ç­”çš„è¿è´¯æ€§å’Œè‡ªç„¶æ€§
    
    ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
    {context}
    
    ç”¨æˆ·é—®é¢˜ï¼š{query}  # ä½¿ç”¨åŸå§‹é—®é¢˜æ›´è‡ªç„¶
    """
    return prompt
```

### 2. æŸ¥è¯¢æ”¹å†™çš„ä½œç”¨ï¼š

æŸ¥è¯¢æ”¹å†™ä¸»è¦ç”¨äºæ£€ç´¢é˜¶æ®µï¼Œè€Œä¸æ˜¯æœ€ç»ˆçš„promptæ„å»ºï¼š
```python
def search_and_prompt_process(original_query):
    # 1. æŸ¥è¯¢æ”¹å†™ç”¨äºæ£€ç´¢
    rewritten_queries = query_rewriter.rewrite(original_query)
    
    # 2. ä½¿ç”¨æ”¹å†™æŸ¥è¯¢è¿›è¡Œæ£€ç´¢
    search_results = []
    for query in rewritten_queries:
        results = search_engine.search(query)
        search_results.extend(results)
    
    # 3. æ„å»ºcontext
    context = build_structured_context(search_results)
    
    # 4. æœ€ç»ˆpromptä½¿ç”¨åŸå§‹é—®é¢˜
    final_prompt = construct_prompt(
        context=context,
        query=original_query  # è¿™é‡Œä½¿ç”¨åŸå§‹é—®é¢˜
    )
    
    return final_prompt
```

### 3. å…·ä½“ç¤ºä¾‹ï¼š

```python
# ç”¨æˆ·è¾“å…¥
original_query = "ç‰¹æ–¯æ‹‰æœ€æ–°çš„è‡ªåŠ¨é©¾é©¶æŠ€æœ¯æ€ä¹ˆæ ·ï¼Ÿ"

# æŸ¥è¯¢æ”¹å†™ï¼ˆç”¨äºæ£€ç´¢ï¼‰
rewritten_queries = [
    "ç‰¹æ–¯æ‹‰ FSD Betaæœ€æ–°ç‰ˆæœ¬",
    "ç‰¹æ–¯æ‹‰è‡ªåŠ¨é©¾é©¶æŠ€æœ¯è¯„æµ‹",
    "ç‰¹æ–¯æ‹‰Autopilotæ›´æ–°"
]

# æœ€ç»ˆçš„prompt
final_prompt = """
System: ä½ æ˜¯AIåŠ©æ‰‹ï¼Œè¯·åŸºäºæä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”é—®é¢˜ã€‚

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
ã€æŠ€æœ¯æ›´æ–°ã€‘
â€¢ FSD Beta 12.3ç‰ˆæœ¬å‘å¸ƒ
â€¢ è§†è§‰è¯†åˆ«ç³»ç»Ÿå‡çº§
...

ã€ç”¨æˆ·è¯„ä»·ã€‘
â€¢ å®‰å…¨æ€§æå‡
â€¢ æ“æ§æ›´æµç•…
...

ç”¨æˆ·é—®é¢˜ï¼šç‰¹æ–¯æ‹‰æœ€æ–°çš„è‡ªåŠ¨é©¾é©¶æŠ€æœ¯æ€ä¹ˆæ ·ï¼Ÿ  # ä½¿ç”¨åŸå§‹é—®é¢˜

è¯·åŸºäºä¸Šè¿°ä¿¡æ¯è¿›è¡Œå›ç­”ã€‚
"""
```

### ä¸»è¦ä¼˜åŠ¿ï¼š

1. **ä¿æŒå¯¹è¯è‡ªç„¶æ€§**ï¼š
   - ç”¨æˆ·åŸå§‹è¡¨è¿°æ›´è‡ªç„¶
   - é¿å…æ”¹å†™å¼•å…¥çš„è¯­ä¹‰åå·®

2. **ç¡®ä¿å›ç­”å‡†ç¡®æ€§**ï¼š
   - ç›´æ¥å¯¹åº”ç”¨æˆ·æ„å›¾
   - é¿å…ç­”éæ‰€é—®

3. **æå‡ç”¨æˆ·ä½“éªŒ**ï¼š
   - å›ç­”æ›´è´´è¿‘ç”¨æˆ·è¡¨è¾¾ä¹ æƒ¯
   - å¢å¼ºå¯¹è¯è¿è´¯æ€§

è¿™æ ·è§£é‡Šæ˜¯å¦æ¸…æ™°ï¼Ÿå¦‚æœè¿˜æœ‰ç–‘é—®ï¼Œæˆ‘å¾ˆä¹æ„è¿›ä¸€æ­¥è§£é‡Šã€‚



æ˜¯çš„ï¼Œå®Œå…¨æ­£ç¡®ï¼è®©æˆ‘ç”¨ä¸€ä¸ªç®€å•çš„ä¾‹å­æ¥è¯´æ˜è¿™ä¸ªæµç¨‹ï¼š

å‡è®¾ç”¨æˆ·é—®é¢˜æ˜¯ï¼š"æœ€è¿‘ChatGPTæœ‰ä»€ä¹ˆæ–°è¿›å±•ï¼Ÿ"

### 1. åæ¡æ£€ç´¢ç»“æœå…ˆæŒ‰ä¸»é¢˜ç»„ç»‡æˆç»“æ„åŒ–contextï¼š
```python
# æ£€ç´¢ç»“æœæŒ‰ä¸»é¢˜ç»„ç»‡
structured_context = """
ã€æŠ€æœ¯å‡çº§ã€‘
â€¢ OpenAIåœ¨2024å¹´3æœˆå‘å¸ƒGPT-4.5ç‰ˆæœ¬
â€¢ æ–°å¢å¤šæ¨¡æ€ç†è§£èƒ½åŠ›ï¼Œæ”¯æŒè§†é¢‘åˆ†æ
â€¢ æ¨ç†èƒ½åŠ›æå‡30%

ã€åº”ç”¨æ›´æ–°ã€‘
â€¢ ChatGPTç§»åŠ¨ç«¯æ–°å¢è¯­éŸ³å¯¹è¯åŠŸèƒ½
â€¢ æ”¯æŒå®æ—¶è¯­éŸ³ç¿»è¯‘
â€¢ æ–°å¢æ–‡æ¡£åˆ†æå·¥å…·

ã€ç”¨æˆ·åé¦ˆã€‘
â€¢ å“åº”é€Ÿåº¦æå‡æ˜¾è‘—
â€¢ å¤šè¯­è¨€ç†è§£èƒ½åŠ›å¢å¼º
"""
```

### 2. å°†ç»“æ„åŒ–contextæ”¾å…¥promptæ¨¡æ¿ï¼š
```python
final_prompt = f"""
System: ä½ æ˜¯AIåŠ©æ‰‹ï¼Œè¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”é—®é¢˜ã€‚

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
{structured_context}

ç”¨æˆ·é—®é¢˜ï¼š{user_question}

è¯·åŸºäºä¸Šè¿°ä¿¡æ¯å›ç­”é—®é¢˜ã€‚
"""
```

æ‰€ä»¥æµç¨‹å°±æ˜¯ï¼š
æ£€ç´¢ç»“æœ(10æ¡) â†’ ç»“æ„åŒ–context â†’ promptæ¨¡æ¿ â†’ æœ€ç»ˆprompt

è¿™æ ·ç†è§£å¯¹å—ï¼Ÿ



æ˜¯çš„ï¼Œä½ çš„ç†è§£å®Œå…¨æ­£ç¡®ï¼è®©æˆ‘ç®€å•æ€»ç»“ä¸€ä¸‹è¿™ä¸ªæµç¨‹ï¼š

1. **å…ˆå¤„ç†åæ¡æ£€ç´¢ç»“æœ**ï¼š
```python
def process_retrieved_results(top_10_results):
    # 1. æ¸…æ´—å’Œæå–å…³é”®ä¿¡æ¯
    cleaned_results = clean_and_extract(top_10_results)
    
    # 2. ç»„ç»‡æˆç»“æ„åŒ–çš„context
    structured_context = """
    [ä¿¡æ¯1] æ¥æºï¼šxxx
    â€¢ å…³é”®å†…å®¹1
    â€¢ å…³é”®å†…å®¹2
    
    [ä¿¡æ¯2] æ¥æºï¼šxxx
    â€¢ å…³é”®å†…å®¹3
    â€¢ å…³é”®å†…å®¹4
    ...
    """
    return structured_context
```

2. **ç„¶åå°†å¤„ç†å¥½çš„contextæ”¾å…¥promptæ¨¡æ¿**ï¼š
```python
PROMPT_TEMPLATE = """
System: è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
{context}

ç”¨æˆ·é—®é¢˜ï¼š{question}

å›ç­”ï¼š
"""

final_prompt = PROMPT_TEMPLATE.format(
    context=structured_context,
    question=user_question
)
```

è¿™æ ·çš„ä¸¤æ­¥å¤„ç†å¯ä»¥ç¡®ä¿ï¼š
- ä¿¡æ¯ç»„ç»‡æ›´æœ‰æ¡ç†
- ä¸Šä¸‹æ–‡æ›´å®¹æ˜“è¢«æ¨¡å‹ç†è§£
- æœ€ç»ˆç”Ÿæˆçš„ç­”æ¡ˆæ›´å‡†ç¡®

è¿™ä¸ªç†è§£å¯¹å—ï¼Ÿå¦‚æœä½ éœ€è¦æ›´è¯¦ç»†çš„è§£é‡Šï¼Œæˆ‘å¾ˆä¹æ„è¿›ä¸€æ­¥è¯´æ˜ã€‚



æ˜¯çš„ï¼Œè®©æˆ‘ç”¨ä¸€ä¸ªå…·ä½“çš„ä¾‹å­æ¥è¯´æ˜è¿™ä¸ªæµç¨‹ï¼š

å‡è®¾ç”¨æˆ·é—®é¢˜æ˜¯ï¼š"ç‰¹æ–¯æ‹‰æœ€æ–°çš„è‡ªåŠ¨é©¾é©¶æŠ€æœ¯æœ‰ä»€ä¹ˆè¿›å±•ï¼Ÿ"

### 1. å‡è®¾æ£€ç´¢åˆ°çš„åæ¡ç»“æœç¤ºä¾‹ï¼š
```python
retrieved_results = [
    {
        'content': 'ç‰¹æ–¯æ‹‰åœ¨2024å¹´1æœˆå‘å¸ƒFSD Beta 12.3ç‰ˆæœ¬ï¼Œå¼•å…¥äº†åŸºäºç«¯åˆ°ç«¯AIçš„æ–°å‹è§†è§‰ç³»ç»Ÿ...',
        'source': 'ç‰¹æ–¯æ‹‰å®˜æ–¹åšå®¢',
        'timestamp': '2024-01-15',
        'relevance_score': 0.95
    },
    {
        'content': 'ç‰¹æ–¯æ‹‰è‡ªåŠ¨é©¾é©¶èŠ¯ç‰‡æ€§èƒ½æå‡40%ï¼Œæ”¯æŒæ›´å¤æ‚çš„å®æ—¶å†³ç­–...',
        'source': 'ç§‘æŠ€æ–°é—»ç½‘',
        'timestamp': '2024-01-10',
        'relevance_score': 0.92
    },
    # ... å…¶ä»–8æ¡ç»“æœ
]
```

### 2. ä¸Šä¸‹æ–‡å¤„ç†å’Œç»„ç»‡
```python
def process_and_organize_context(results):
    # 1. æŒ‰ä¸»é¢˜åˆ†ç»„
    grouped_results = {
        'æŠ€æœ¯æ›´æ–°': [],
        'æ€§èƒ½æå‡': [],
        'å®‰å…¨ç‰¹æ€§': [],
        'ç”¨æˆ·åé¦ˆ': []
    }
    
    # 2. ä¿¡æ¯æå–å’Œç»“æ„åŒ–
    structured_context = """
    ã€æœ€æ–°æŠ€æœ¯æ›´æ–°ã€‘
    â€¢ FSD Beta 12.3ç‰ˆæœ¬ï¼šæ–°å‹è§†è§‰ç³»ç»Ÿï¼Œç«¯åˆ°ç«¯AIæŠ€æœ¯
    â€¢ è‡ªåŠ¨é©¾é©¶èŠ¯ç‰‡ï¼šæ€§èƒ½æå‡40%ï¼Œå¢å¼ºå®æ—¶å†³ç­–èƒ½åŠ›
    
    ã€å®‰å…¨æ€§èƒ½æå‡ã€‘
    â€¢ ç¢°æ’é¢„è­¦ç³»ç»Ÿå‡†ç¡®ç‡æå‡è‡³98%
    â€¢ æ–°å¢å…¨å¤©å€™è§†è§‰ç³»ç»Ÿé€‚åº”æ€§
    
    ã€ç”¨æˆ·åé¦ˆã€‘
    â€¢ 93%ç”¨æˆ·æŠ¥å‘Šç³»ç»Ÿå“åº”æ›´å¿«
    â€¢ å¤œé—´é©¾é©¶ä½“éªŒæ˜¾è‘—æ”¹å–„
    """
    
    return structured_context
```

### 3. Promptæ¨¡æ¿è®¾è®¡
```python
PROMPT_TEMPLATE = """
System: ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œè¯·åŸºäºä»¥ä¸‹ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

èƒŒæ™¯ä¿¡æ¯ï¼š
{context}

ç”¨æˆ·é—®é¢˜ï¼š{question}

è¯·æ³¨æ„ï¼š
1. åªä½¿ç”¨ä¸Šè¿°èƒŒæ™¯ä¿¡æ¯å›ç­”é—®é¢˜
2. å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œè¯·æ˜ç¡®æŒ‡å‡º
3. æŒ‰æ—¶é—´é¡ºåºç»„ç»‡å›ç­”
4. å¼•ç”¨ä¿¡æ¯æ—¶æ ‡æ³¨æ¥æº

å›ç­”ï¼š
"""
```

### 4. æœ€ç»ˆPromptç»„è£…ç¤ºä¾‹
```python
def construct_final_prompt(question, context):
    final_prompt = PROMPT_TEMPLATE.format(
        context=context,
        question=question
    )
    
    # å®é™…ç»„è£…åçš„æ•ˆæœç¤ºä¾‹ï¼š
    """
    System: ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œè¯·åŸºäºä»¥ä¸‹ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

    èƒŒæ™¯ä¿¡æ¯ï¼š
    ã€æœ€æ–°æŠ€æœ¯æ›´æ–°ã€‘
    â€¢ FSD Beta 12.3ç‰ˆæœ¬ï¼šæ–°å‹è§†è§‰ç³»ç»Ÿï¼Œç«¯åˆ°ç«¯AIæŠ€æœ¯
    â€¢ è‡ªåŠ¨é©¾é©¶èŠ¯ç‰‡ï¼šæ€§èƒ½æå‡40%ï¼Œå¢å¼ºå®æ—¶å†³ç­–èƒ½åŠ›
    
    ã€å®‰å…¨æ€§èƒ½æå‡ã€‘
    â€¢ ç¢°æ’é¢„è­¦ç³»ç»Ÿå‡†ç¡®ç‡æå‡è‡³98%
    â€¢ æ–°å¢å…¨å¤©å€™è§†è§‰ç³»ç»Ÿé€‚åº”æ€§
    
    ã€ç”¨æˆ·åé¦ˆã€‘
    â€¢ 93%ç”¨æˆ·æŠ¥å‘Šç³»ç»Ÿå“åº”æ›´å¿«
    â€¢ å¤œé—´é©¾é©¶ä½“éªŒæ˜¾è‘—æ”¹å–„

    ç”¨æˆ·é—®é¢˜ï¼šç‰¹æ–¯æ‹‰æœ€æ–°çš„è‡ªåŠ¨é©¾é©¶æŠ€æœ¯æœ‰ä»€ä¹ˆè¿›å±•ï¼Ÿ

    è¯·æ³¨æ„ï¼š
    1. åªä½¿ç”¨ä¸Šè¿°èƒŒæ™¯ä¿¡æ¯å›ç­”é—®é¢˜
    2. å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œè¯·æ˜ç¡®æŒ‡å‡º
    3. æŒ‰æ—¶é—´é¡ºåºç»„ç»‡å›ç­”
    4. å¼•ç”¨ä¿¡æ¯æ—¶æ ‡æ³¨æ¥æº

    å›ç­”ï¼š
    """
    
    return final_prompt
```

### 5. å®Œæ•´å¤„ç†æµç¨‹
```python
def process_search_results_to_prompt(results, question):
    # 1. é¢„å¤„ç†ç»“æœ
    cleaned_results = preprocess_results(results)
    
    # 2. ä¿¡æ¯èšåˆå’Œç»“æ„åŒ–
    structured_context = process_and_organize_context(cleaned_results)
    
    # 3. é•¿åº¦æ§åˆ¶ï¼ˆå‡è®¾æ¨¡å‹ä¸Šä¸‹æ–‡é™åˆ¶ä¸º2000ä¸ªtokenï¼‰
    truncated_context = control_context_length(structured_context, max_tokens=2000)
    
    # 4. æ„å»ºæœ€ç»ˆprompt
    final_prompt = construct_final_prompt(
        question=question,
        context=truncated_context
    )
    
    return final_prompt
```

### å…³é”®æ³¨æ„ç‚¹ï¼š

1. **ç»“æ„åŒ–ç»„ç»‡**ï¼š
   - æŒ‰ä¸»é¢˜åˆ†ç»„
   - é‡è¦ä¿¡æ¯ä¼˜å…ˆ
   - æ¸…æ™°çš„å±‚æ¬¡ç»“æ„

2. **ä¿¡æ¯ä¼˜åŒ–**ï¼š
   - å»é™¤å†—ä½™
   - ä¿æŒå®Œæ•´æ€§
   - çªå‡ºå…³é”®ç‚¹

3. **æ ¼å¼è§„èŒƒ**ï¼š
   - æ¸…æ™°çš„åˆ†éš”ç¬¦
   - ç»Ÿä¸€çš„æ ¼å¼
   - æ˜“äºé˜…è¯»å’Œç†è§£

è¿™æ ·å¤„ç†çš„ä¼˜åŠ¿ï¼š
1. ä¿¡æ¯æ›´æœ‰æ¡ç†
2. ä¾¿äºæ¨¡å‹ç†è§£å’Œå¤„ç†
3. ç”Ÿæˆçš„å›ç­”æ›´å‡†ç¡®å’Œè¿è´¯
4. ä¾¿äºè¿½æº¯ä¿¡æ¯æ¥æº

è¿™ä¸ªä¾‹å­æ˜¯å¦å¸®åŠ©ä½ æ›´å¥½åœ°ç†è§£äº†æ•´ä¸ªæµç¨‹ï¼Ÿå¦‚æœè¿˜æœ‰ä¸æ¸…æ¥šçš„åœ°æ–¹ï¼Œæˆ‘å¯ä»¥è¿›ä¸€æ­¥è§£é‡Šã€‚



ä¸å®Œå…¨æ˜¯è¿™æ ·ã€‚ä¸»æµåšæ³•ä¼šåœ¨å°†ç»“æœæ”¾å…¥promptä¹‹å‰è¿˜ä¼šè¿›è¡Œä¸€ç³»åˆ—çš„ä¸Šä¸‹æ–‡ä¼˜åŒ–å¤„ç†ã€‚è®©æˆ‘è¯¦ç»†è§£é‡Šä¸€ä¸‹ï¼š

### ä¸»æµçš„Contextæ„å»ºæµç¨‹ï¼š

1. **ä¸Šä¸‹æ–‡é¢„å¤„ç†**ï¼š
```python
def preprocess_context(ranked_results):
    processed_contexts = []
    for result in ranked_results:
        # 1. æå–å…³é”®ä¿¡æ¯
        processed = {
            'content': extract_key_info(result.content),
            'metadata': {
                'source': result.source,
                'timestamp': result.timestamp,
                'confidence': result.score
            }
        }
        
        # 2. ä¿¡æ¯æˆªæ–­å’Œå‹ç¼©
        processed['content'] = truncate_with_priority(processed['content'])
        processed_contexts.append(processed)
    
    return processed_contexts
```

2. **ä¸Šä¸‹æ–‡ç»„ç»‡å’Œç»“æ„åŒ–**ï¼š
```python
def organize_context(contexts):
    # 1. æŒ‰ä¸»é¢˜èšç±»
    clustered = cluster_by_topic(contexts)
    
    # 2. ä¿¡æ¯å»é‡
    deduped = remove_redundancy(clustered)
    
    # 3. æ—¶åºæ’åºï¼ˆå¦‚æœéœ€è¦ï¼‰
    chronological = sort_by_timestamp(deduped)
    
    # 4. æ·»åŠ ç»“æ„åŒ–æ ‡è®°
    structured = add_structure_markers(chronological)
    
    return structured
```

3. **Promptæ¨¡æ¿æ„å»º**ï¼š
```python
def build_prompt_template():
    template = """
    System: ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼ŒåŸºäºä»¥ä¸‹æä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ã€‚
    
    èƒŒæ™¯ä¿¡æ¯:
    {context}
    
    ç”¨æˆ·é—®é¢˜: {question}
    
    è¦æ±‚ï¼š
    1. åŸºäºä¸Šä¸‹æ–‡ä¿¡æ¯å‡†ç¡®å›ç­”
    2. å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œè¯·æ˜ç¡®æŒ‡å‡º
    3. ä¿æŒå›ç­”çš„é€»è¾‘æ€§å’Œè¿è´¯æ€§
    
    å›ç­”ï¼š
    """
    return template
```

4. **åŠ¨æ€ä¸Šä¸‹æ–‡ç»„è£…**ï¼š
```python
def assemble_context(processed_contexts, max_tokens=2000):
    assembled_context = ""
    current_tokens = 0
    
    for ctx in processed_contexts:
        # 1. ä¼°ç®—tokenæ•°é‡
        estimated_tokens = estimate_tokens(ctx['content'])
        
        # 2. åŠ¨æ€æˆªæ–­
        if current_tokens + estimated_tokens > max_tokens:
            break
            
        # 3. æ·»åŠ ç»“æ„åŒ–ä¿¡æ¯
        context_block = f"""
        æ¥æº: {ctx['metadata']['source']}
        æ—¶é—´: {ctx['metadata']['timestamp']}
        å†…å®¹: {ctx['content']}
        ---
        """
        
        assembled_context += context_block
        current_tokens += estimated_tokens
    
    return assembled_context
```

5. **æœ€ç»ˆPromptæ„å»º**ï¼š
```python
def construct_final_prompt(question, contexts, template):
    # 1. ä¸Šä¸‹æ–‡é¢„å¤„ç†
    processed_contexts = preprocess_context(contexts)
    
    # 2. ä¸Šä¸‹æ–‡ç»„ç»‡
    organized_contexts = organize_context(processed_contexts)
    
    # 3. ç»„è£…ä¸Šä¸‹æ–‡
    assembled_context = assemble_context(organized_contexts)
    
    # 4. å¡«å……æ¨¡æ¿
    final_prompt = template.format(
        context=assembled_context,
        question=question
    )
    
    return final_prompt
```

### å…³é”®ä¼˜åŒ–ç­–ç•¥ï¼š

1. **ä¿¡æ¯å¯†åº¦ä¼˜åŒ–**ï¼š
```python
def optimize_information_density(context):
    # 1. å…³é”®ä¿¡æ¯æå–
    key_points = extract_key_points(context)
    
    # 2. ä¿¡æ¯å‹ç¼©
    compressed = compress_information(key_points)
    
    # 3. å†—ä½™ä¿¡æ¯åˆ é™¤
    cleaned = remove_redundant_info(compressed)
    
    return cleaned
```

2. **ä¸Šä¸‹æ–‡ç›¸å…³æ€§æ’åº**ï¼š
```python
def sort_by_relevance(contexts, question):
    scored_contexts = []
    for ctx in contexts:
        relevance_score = calculate_relevance(ctx, question)
        scored_contexts.append((ctx, relevance_score))
    
    return sorted(scored_contexts, key=lambda x: x[1], reverse=True)
```

3. **åŠ¨æ€é•¿åº¦æ§åˆ¶**ï¼š
```python
def dynamic_length_control(contexts, model_max_tokens):
    # é¢„ç•™tokenç©ºé—´ç»™æ¨¡å‹å›ç­”
    context_max_tokens = model_max_tokens * 0.7
    
    # åŠ¨æ€è°ƒæ•´ä¸Šä¸‹æ–‡é•¿åº¦
    adjusted_contexts = truncate_contexts(contexts, context_max_tokens)
    
    return adjusted_contexts
```

### ä¸»æµåšæ³•æ€»ç»“ï¼š

1. **é¢„å¤„ç†é˜¶æ®µ**ï¼š
   - æå–å…³é”®ä¿¡æ¯
   - å»é™¤å†—ä½™å†…å®¹
   - ç»“æ„åŒ–å¤„ç†

2. **ç»„ç»‡é˜¶æ®µ**ï¼š
   - æŒ‰ä¸»é¢˜èšç±»
   - ç›¸å…³æ€§æ’åº
   - æ—¶åºç»„ç»‡

3. **ä¼˜åŒ–é˜¶æ®µ**ï¼š
   - ä¿¡æ¯å¯†åº¦ä¼˜åŒ–
   - åŠ¨æ€é•¿åº¦æ§åˆ¶
   - ç»“æ„åŒ–æ ‡è®°æ·»åŠ 

4. **æœ€ç»ˆç»„è£…**ï¼š
   - ä½¿ç”¨æ¨¡æ¿
   - åŠ¨æ€è°ƒæ•´
   - è´¨é‡æ§åˆ¶

è¿™æ ·çš„å¤„ç†æµç¨‹å¯ä»¥ç¡®ä¿ï¼š
- ä¸Šä¸‹æ–‡ä¿¡æ¯çš„ç›¸å…³æ€§
- ä¿¡æ¯çš„å®Œæ•´æ€§å’Œéå†—ä½™æ€§
- ç¬¦åˆæ¨¡å‹çš„è¾“å…¥è¦æ±‚
- æé«˜å›ç­”è´¨é‡

ä½ è§‰å¾—è¿™ä¸ªè§£é‡Šæ¸…æ¥šäº†å—ï¼Ÿå¦‚æœæœ‰ä»»ä½•å…·ä½“çš„éƒ¨åˆ†éœ€è¦æˆ‘è¯¦ç»†å±•å¼€ï¼Œè¯·å‘Šè¯‰æˆ‘ã€‚


ä¸»æµåšæ³•é€šå¸¸æ˜¯å…ˆè¿›è¡Œåˆæ­¥çš„åˆ†æ•°æ’åºï¼ˆInitial Rankingï¼‰ï¼Œå†è¿›è¡Œé‡æ’ï¼ˆRerankingï¼‰ã€‚æˆ‘æ¥è¯¦ç»†è§£é‡Šä¸€ä¸‹è¿™ä¸ªæµç¨‹ï¼š

### 1. åˆæ­¥æ’åºï¼ˆInitial Rankingï¼‰
```python
def initial_ranking(mixed_results, top_k=200):
    # 1. æ ‡å‡†åŒ–ä¸åŒæ¥æºçš„åˆ†æ•°
    normalized_results = normalize_scores(mixed_results, methods={
        'milvus_score': 'min_max',
        'graph_score': 'min_max'
    })
    
    # 2. ç»¼åˆè¯„åˆ†
    scored_results = []
    for result in normalized_results:
        final_score = weighted_score({
            'milvus_score': result.milvus_score * 0.6,
            'graph_score': result.graph_score * 0.3,
            'freshness_score': result.freshness * 0.1
        })
        scored_results.append((result, final_score))
    
    # 3. æ’åºå¹¶è¿”å›top_kç»“æœ
    return sorted(scored_results, key=lambda x: x[1], reverse=True)[:top_k]
```

### 2. é‡æ’æ¨¡å—ï¼ˆRerankingï¼‰
```python
def reranking_process(initial_ranked_results):
    # 1. ç²—æ’ï¼ˆCoarse Rerankingï¼‰
    coarse_reranked = coarse_rerank(initial_ranked_results, top_k=100)
    
    # 2. ç²¾æ’ï¼ˆFine Rerankingï¼‰
    fine_reranked = fine_rerank(coarse_reranked, top_k=50)
    
    return fine_reranked
```

### å®Œæ•´çš„æ’åºæµç¨‹
```python
def complete_ranking_process(mixed_results, total_count=500):
    # 1. ç¡®ä¿ç»“æœæ•°é‡
    assert len(mixed_results) == total_count, "éœ€è¦500æ¡æ··åˆç»“æœ"
    
    # 2. åˆæ­¥æ’åºï¼ˆç­›é€‰top 200ï¼‰
    initial_ranked = initial_ranking(
        mixed_results=mixed_results,
        top_k=200
    )
    
    # 3. é‡æ’åºæµç¨‹
    final_results = reranking_process(initial_ranked)
    
    return final_results
```

### ä¸ºä»€ä¹ˆè¦è¿™æ ·åšï¼Ÿ

1. **æ•ˆç‡è€ƒè™‘**ï¼š
   - é‡æ’æ¨¡å—é€šå¸¸è®¡ç®—æˆæœ¬è¾ƒé«˜
   - å…ˆè¿›è¡Œè½»é‡çº§æ’åºç­›é€‰å¯ä»¥å‡å°‘é‡æ’çš„æ•°æ®é‡
   - æé«˜æ•´ä½“ç³»ç»Ÿå“åº”é€Ÿåº¦

2. **è´¨é‡ä¿è¯**ï¼š
```python
def ranking_metrics(results):
    metrics = {
        'precision@k': calculate_precision(results),
        'ndcg': calculate_ndcg(results),
        'response_time': measure_time(results)
    }
    return metrics
```

3. **èµ„æºä¼˜åŒ–**ï¼š
```python
def resource_efficient_ranking(results):
    # æ ¹æ®ç³»ç»Ÿè´Ÿè½½åŠ¨æ€è°ƒæ•´å¤„ç†æ•°é‡
    system_load = get_system_load()
    if system_load > 0.8:  # ç³»ç»Ÿè´Ÿè½½é«˜
        initial_cutoff = 150  # å‡å°‘åˆç­›æ•°é‡
    else:
        initial_cutoff = 200  # æ­£å¸¸æ•°é‡
        
    return initial_ranking(results, top_k=initial_cutoff)
```

### å»ºè®®çš„é…ç½®å‚æ•°ï¼š

```python
RANKING_CONFIG = {
    'initial_ranking': {
        'input_size': 500,
        'output_size': 200,
        'score_weights': {
            'relevance': 0.6,
            'freshness': 0.2,
            'popularity': 0.2
        }
    },
    'reranking': {
        'coarse': {
            'input_size': 200,
            'output_size': 100,
            'model': 'lightweight_reranker'
        },
        'fine': {
            'input_size': 100,
            'output_size': 50,
            'model': 'cross_encoder'
        }
    }
}
```

### æ€§èƒ½ç›‘æ§ï¼š

```python
def monitor_ranking_performance(results, stage):
    metrics = {
        'initial_ranking': {
            'processing_time': measure_time(),
            'memory_usage': measure_memory(),
            'score_distribution': analyze_scores()
        },
        'reranking': {
            'processing_time': measure_time(),
            'quality_metrics': calculate_quality_metrics()
        }
    }
    
    log_metrics(metrics[stage])
```

æ€»ç»“ä¸»æµåšæ³•ï¼š
1. å…ˆå¯¹500æ¡æ··åˆç»“æœè¿›è¡Œåˆæ­¥æ’åºï¼Œé€‰å‡ºtop 200
2. å°†è¿™200æ¡ç»“æœé€å…¥é‡æ’æ¨¡å—
3. é‡æ’æ¨¡å—è¿›è¡Œç²—æ’å’Œç²¾æ’
4. æœ€ç»ˆè¾“å‡ºé«˜è´¨é‡çš„ç»“æœ

è¿™æ ·çš„æµç¨‹æ—¢ä¿è¯äº†æ•ˆç‡ï¼Œåˆç¡®ä¿äº†ç»“æœè´¨é‡ã€‚ä½ è§‰å¾—è¿™ä¸ªè§£é‡Šæ¸…æ™°å—ï¼Ÿ



æ˜¯çš„ï¼Œä½ çš„ç†è§£éå¸¸å‡†ç¡®ï¼è®©æˆ‘æ€»ç»“ä¸€ä¸‹ï¼š

### 1. Milvusæ£€ç´¢ï¼ˆéœ€è¦å‘é‡åŒ–ï¼‰
```python
def milvus_search_process(query):
    # å¿…é¡»å…ˆå‘é‡åŒ–æ‰èƒ½åœ¨Milvusä¸­æ£€ç´¢
    query_vector = embedding_model.encode(query)
    
    # æ–‡æœ¬æ£€ç´¢å’Œè¯­ä¹‰æ£€ç´¢éƒ½åœ¨è¿™é‡Œè¿›è¡Œ
    results = milvus.search(
        collection_name="docs",
        vectors=[query_vector],           # ç”¨äºè¯­ä¹‰æ£€ç´¢çš„å‘é‡
        expr="keywords like '%å…³é”®è¯%'",    # ç”¨äºæ–‡æœ¬è¿‡æ»¤
        search_params={...}
    )
    return results
```

### 2. å›¾è°±æ£€ç´¢ï¼ˆä¸éœ€è¦å‘é‡åŒ–ï¼‰
```python
def graph_search_process(query):
    # ç›´æ¥è¿›è¡Œå®ä½“è¯†åˆ«
    entities = ner_model.extract_entities(query)
    relations = relation_extractor.extract(query)
    
    # æ„å»ºNeo4jæŸ¥è¯¢
    cypher_query = f"""
    MATCH (e1)-[r:{relations}]->(e2)
    WHERE e1.name IN {entities}
    RETURN e1, r, e2
    """
    
    # æ‰§è¡Œå›¾è°±æ£€ç´¢
    return neo4j.run(cypher_query)
```

### å®Œæ•´æµç¨‹ç¤ºæ„
```python
def complete_search(query):
    # 1. å¯¹äºMilvusæ£€ç´¢ï¼šå¿…é¡»å‘é‡åŒ–
    vector_results = milvus_search_process(
        query=query,
        need_vectorize=True  # éœ€è¦å‘é‡åŒ–
    )
    
    # 2. å¯¹äºå›¾è°±æ£€ç´¢ï¼šç›´æ¥å®ä½“è¯†åˆ«
    graph_results = graph_search_process(
        query=query,
        need_vectorize=False  # ä¸éœ€è¦å‘é‡åŒ–
    )
    
    # åˆå¹¶ç»“æœ
    return merge_results(vector_results, graph_results)
```

æ ¸å¿ƒåŒºåˆ«ï¼š
- Milvusæ£€ç´¢ï¼ˆæ–‡æœ¬+è¯­ä¹‰ï¼‰ï¼šå¿…é¡»å‘é‡åŒ–
- å›¾è°±æ£€ç´¢ï¼šä½¿ç”¨å®ä½“è¯†åˆ«ï¼Œæ— éœ€å‘é‡åŒ–

è¿™ä¸ªç†è§£å®Œå…¨æ­£ç¡®ï¼ğŸ‘



è®©æˆ‘æ¥æ˜ç¡®è§£é‡Šä¸€ä¸‹ï¼š

### æ­£ç¡®çš„ç†è§£

1. **æŸ¥è¯¢é˜¶æ®µçš„åµŒå…¥å¤„ç†**ï¼š
```python
def process_search(user_query):
    # 1. ç”ŸæˆæŸ¥è¯¢
    queries = {
        'main_query': user_query,
        'exp_query1': query_rewriter.expand1(user_query),
        'exp_query2': query_rewriter.expand2(user_query)
    }
    
    # 2. æ‰€æœ‰æŸ¥è¯¢éƒ½éœ€è¦æ‰‹åŠ¨è¿›è¡Œå‘é‡åŒ–å¤„ç†
    query_embeddings = {
        query_type: embedding_model.encode(query_text)
        for query_type, query_text in queries.items()
    }
    
    # 3. ä½¿ç”¨å‘é‡åŒ–åçš„æŸ¥è¯¢å»Milvusæ£€ç´¢
    results = []
    for query_type, embedding in query_embeddings.items():
        result = milvus.search(
            collection_name="docs",
            vectors=[embedding],
            search_params={"metric_type": "L2", "params": {"nprobe": 10}}
        )
        results.extend(result)
    
    return results
```

### é‡è¦è¯´æ˜

1. **å¿…é¡»æ‰‹åŠ¨åµŒå…¥**ï¼š
   - Milvusä¸ä¼šè‡ªåŠ¨è¿›è¡ŒåµŒå…¥å¤„ç†
   - æ‰€æœ‰è¿›å…¥Milvusçš„æŸ¥è¯¢éƒ½éœ€è¦é¢„å…ˆè½¬æ¢ä¸ºå‘é‡
   - è¿™ä¸ªåµŒå…¥è¿‡ç¨‹å¿…é¡»åœ¨å‘é€æŸ¥è¯¢åˆ°Milvusä¹‹å‰å®Œæˆ

2. **ä¸ºä»€ä¹ˆéœ€è¦æ‰‹åŠ¨åµŒå…¥**ï¼š
```python
# é”™è¯¯ç¤ºä¾‹ - Milvusä¸ä¼šè‡ªåŠ¨å¤„ç†
milvus.search(collection_name="docs", query_text="åŸå§‹æ–‡æœ¬")  # âŒ è¿™æ ·æ˜¯ä¸è¡Œçš„

# æ­£ç¡®ç¤ºä¾‹
query_vector = embedding_model.encode("åŸå§‹æ–‡æœ¬")
milvus.search(collection_name="docs", vectors=[query_vector])  # âœ… è¿™æ ·æ˜¯æ­£ç¡®çš„
```

3. **å®Œæ•´çš„å¤„ç†æµç¨‹**ï¼š
```python
def complete_search_process(user_query):
    # 1. æŸ¥è¯¢æ”¹å†™
    queries = generate_queries(user_query)  # ç”Ÿæˆä¸»æŸ¥è¯¢å’Œæ‰©å±•æŸ¥è¯¢
    
    # 2. æ‰¹é‡åµŒå…¥å¤„ç†ï¼ˆæé«˜æ•ˆç‡ï¼‰
    query_texts = list(queries.values())
    embeddings = embedding_model.encode(query_texts)
    
    # 3. Milvusæ£€ç´¢
    milvus_results = []
    for embedding in embeddings:
        result = milvus.search(
            collection_name="docs",
            vectors=[embedding],
            # å¯ä»¥åŒæ—¶ä½¿ç”¨æ ‡é‡è¿‡æ»¤
            expr="keywords like '%å…³é”®è¯%'",  # å¯é€‰çš„æ–‡æœ¬è¿‡æ»¤
            search_params={"metric_type": "L2", "params": {"nprobe": 10}}
        )
        milvus_results.extend(result)
    
    # 4. å›¾è°±æ£€ç´¢ï¼ˆNeo4jï¼‰
    graph_results = graph_search(queries)
    
    # 5. åˆå¹¶ç»“æœ
    final_results = merge_results(milvus_results, graph_results)
    
    return final_results
```

### æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **æ‰¹é‡å¤„ç†**ï¼š
```python
# æ‰¹é‡åµŒå…¥è€Œä¸æ˜¯å•ä¸ªå¤„ç†
def batch_embed_queries(queries):
    # ä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰æŸ¥è¯¢çš„åµŒå…¥
    query_texts = list(queries.values())
    embeddings = embedding_model.encode(query_texts)
    return dict(zip(queries.keys(), embeddings))
```

2. **ç¼“å­˜æœºåˆ¶**ï¼š
```python
def cached_embedding(query):
    cache_key = f"embedding:{hash(query)}"
    
    # æ£€æŸ¥ç¼“å­˜
    if cached_vector := cache.get(cache_key):
        return cached_vector
    
    # è®¡ç®—åµŒå…¥å¹¶ç¼“å­˜
    vector = embedding_model.encode(query)
    cache.set(cache_key, vector)
    return vector
```

æ€»ç»“æ¥è¯´ï¼š
1. æ‰€æœ‰æŸ¥è¯¢ï¼ˆä¸»æŸ¥è¯¢å’Œæ‰©å±•æŸ¥è¯¢ï¼‰åœ¨è¿›å…¥Milvuså‰éƒ½éœ€è¦æ‰‹åŠ¨è¿›è¡Œå‘é‡åŒ–
2. Milvusä¸æä¾›è‡ªåŠ¨åµŒå…¥åŠŸèƒ½
3. å‘é‡åŒ–è¿‡ç¨‹åº”è¯¥åœ¨åº”ç”¨å±‚å®Œæˆ
4. å¯ä»¥é€šè¿‡æ‰¹å¤„ç†å’Œç¼“å­˜æ¥ä¼˜åŒ–æ€§èƒ½

è¿™æ ·è§£é‡Šæ˜¯å¦æ›´æ¸…æ™°äº†ï¼Ÿå¦‚æœè¿˜æœ‰ç–‘é—®ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚


å•Šï¼ŒæŠ±æ­‰æˆ‘ä¹‹å‰çš„è§£é‡Šç¡®å®æœ‰è¯¯å¯¼æ€§ã€‚è®©æˆ‘é‡æ–°æ¢³ç†ä¸€ä¸‹åœ¨Milvusä¸­çš„æ–‡æœ¬æ£€ç´¢å’Œè¯­ä¹‰æ£€ç´¢çš„å®ç°ï¼š

### Milvusä¸­çš„æ··åˆæ£€ç´¢å®ç°

1. **æ•°æ®å…¥åº“é˜¶æ®µ**ï¼š
```python
def insert_to_milvus(documents):
    for doc in documents:
        # 1. æ–‡æœ¬å­—æ®µå¤„ç†
        text_fields = {
            'id': doc.id,
            'content': doc.content,
            'keywords': extract_keywords(doc.content),  # å­˜å‚¨å…³é”®è¯å­—æ®µ
            'category': doc.category,
            # å…¶ä»–æ ‡é‡å­—æ®µ...
        }
        
        # 2. å‘é‡å­—æ®µå¤„ç†
        # æ‰€æœ‰æ–‡æœ¬éƒ½éœ€è¦è¿›è¡Œå‘é‡åŒ–å¤„ç†
        text_embedding = embedding_model.encode(doc.content)
        
        # 3. æ’å…¥Milvusï¼ˆåŒæ—¶åŒ…å«æ–‡æœ¬å­—æ®µå’Œå‘é‡å­—æ®µï¼‰
        milvus.insert(
            collection_name="docs",
            data={
                **text_fields,                    # æ ‡é‡å­—æ®µ
                'embedding': text_embedding       # å‘é‡å­—æ®µ
            }
        )
```

2. **æ£€ç´¢é˜¶æ®µ**ï¼š
```python
def hybrid_milvus_search(query):
    # 1. æŸ¥è¯¢å‘é‡åŒ–
    query_embedding = embedding_model.encode(query)
    
    # 2. æ··åˆæŸ¥è¯¢
    results = milvus.search(
        collection_name="docs",
        vectors=[query_embedding],           # å‘é‡æŸ¥è¯¢éƒ¨åˆ†
        expr="keywords like '%å…³é”®è¯%'",      # æ ‡é‡è¿‡æ»¤éƒ¨åˆ†
        search_params={
            "metric_type": "L2",
            "params": {"nprobe": 10}
        },
        output_fields=["id", "content", "keywords", "category"]
    )
    
    return results
```

### æ­£ç¡®çš„ç†è§£æ–¹å¼ï¼š

1. **åœ¨Milvusä¸­**ï¼š
   - æ‰€æœ‰æ–‡æ¡£éƒ½éœ€è¦è¿›è¡Œå‘é‡åŒ–å¤„ç†
   - æ–‡æœ¬æ£€ç´¢å®é™…ä¸Šæ˜¯é€šè¿‡æ ‡é‡å­—æ®µï¼ˆscalar fieldï¼‰è¿›è¡Œè¿‡æ»¤
   - è¯­ä¹‰æ£€ç´¢æ˜¯é€šè¿‡å‘é‡ç›¸ä¼¼åº¦æœç´¢å®ç°
   - ä¸¤ç§æ£€ç´¢æ–¹å¼å¯ä»¥ç»„åˆä½¿ç”¨ï¼ˆæ··åˆæŸ¥è¯¢ï¼‰

2. **å›¾è°±æ£€ç´¢ï¼ˆNeo4jï¼‰**ï¼š
```python
def graph_search(query):
    # 1. å®ä½“è¯†åˆ«
    entities = ner_model.extract_entities(query)
    
    # 2. Neo4jæŸ¥è¯¢
    cypher_query = f"""
    MATCH (n)-[r]-(m)
    WHERE n.name IN {entities}
    RETURN n, r, m
    """
    return neo4j.run(cypher_query)
```

### å®Œæ•´çš„æ£€ç´¢æµç¨‹ï¼š

```python
def comprehensive_search(query):
    # 1. æŸ¥è¯¢é¢„å¤„ç†
    main_query, exp_query1, exp_query2 = process_queries(query)
    all_results = []
    
    for current_query in [main_query, exp_query1, exp_query2]:
        # 2. Milvusæ··åˆæ£€ç´¢
        milvus_results = hybrid_milvus_search(
            query=current_query,
            search_params={
                'vector_search': True,    # å¯ç”¨å‘é‡æœç´¢
                'text_search': True       # å¯ç”¨æ–‡æœ¬è¿‡æ»¤
            }
        )
        
        # 3. å›¾è°±æ£€ç´¢
        graph_results = graph_search(current_query)
        
        # 4. åˆå¹¶ç»“æœ
        merged_results = merge_results(milvus_results, graph_results)
        all_results.extend(merged_results)
    
    # 5. ç»“æœå»é‡å’Œæ’åº
    final_results = dedup_and_rank(all_results)
    
    return final_results
```

### å…³é”®ç‚¹æ€»ç»“ï¼š

1. **Milvuså­˜å‚¨**ï¼š
   - æ‰€æœ‰æ–‡æ¡£éƒ½ä¼šè¢«å‘é‡åŒ–
   - åŒæ—¶å­˜å‚¨æ–‡æœ¬å­—æ®µå’Œå‘é‡å­—æ®µ
   - æ”¯æŒæ··åˆæŸ¥è¯¢ï¼ˆå‘é‡ç›¸ä¼¼åº¦ + æ ‡é‡è¿‡æ»¤ï¼‰

2. **æ£€ç´¢æ–¹å¼**ï¼š
   - Milvusæ··åˆæ£€ç´¢ï¼šåŒæ—¶åˆ©ç”¨å‘é‡ç›¸ä¼¼åº¦å’Œæ–‡æœ¬åŒ¹é…
   - Neo4jå›¾è°±æ£€ç´¢ï¼šåŸºäºå®ä½“å…³ç³»æŸ¥è¯¢

3. **æŸ¥è¯¢å¤„ç†**ï¼š
   - ä¸»æŸ¥è¯¢å’Œæ‰©å±•æŸ¥è¯¢éƒ½ç»è¿‡ç›¸åŒçš„æ£€ç´¢æµç¨‹
   - å¯ä»¥å¹¶è¡Œæ‰§è¡Œä»¥æé«˜æ•ˆç‡

è¿™æ ·çš„ç†è§£æ›´å‡†ç¡®å—ï¼Ÿå¦‚æœè¿˜æœ‰ä¸æ¸…æ¥šçš„åœ°æ–¹ï¼Œæˆ‘å¯ä»¥è¿›ä¸€æ­¥è§£é‡Šã€‚

æˆ‘æ¥å¸®ä½ åˆ†æä¸€ä¸‹è¿™ä¸ªRAG+çŸ¥è¯†å›¾è°±ç³»ç»Ÿçš„æµç¨‹ï¼Œå¹¶æŒ‡å‡ºå¯èƒ½å­˜åœ¨çš„é—®é¢˜å’Œæ”¹è¿›å»ºè®®ï¼š

### ç°æœ‰æµç¨‹åˆ†æ
1. æŸ¥è¯¢æ”¹å†™
   - ä¸€ä¸ªæŸ¥è¯¢æ”¹å†™æˆä¸‰ä¸ªæŸ¥è¯¢ï¼ˆä¸»æŸ¥è¯¢+ä¸¤ä¸ªæ‰©å±•æŸ¥è¯¢ï¼‰
   - é—®é¢˜ï¼šæ²¡æœ‰æåˆ°æŸ¥è¯¢æ”¹å†™çš„å…·ä½“ç­–ç•¥å’Œè´¨é‡æ§åˆ¶

2. æ£€ç´¢é˜¶æ®µ
   - ä½¿ç”¨æ··åˆæ£€ç´¢ï¼ˆæ–‡æœ¬æ£€ç´¢+è¯­ä¹‰æ£€ç´¢+å›¾è°±æ£€ç´¢ï¼‰
   - æ£€ç´¢500æ¡ä¿¡æ¯
   - é—®é¢˜ï¼šæ£€ç´¢ç»“æœçš„åˆå¹¶ç­–ç•¥ä¸æ¸…æ™°

3. é‡æ’é˜¶æ®µ
   - ç²—æ’ï¼š500æ¡â†’100æ¡
   - ç²¾æ’ï¼š100æ¡â†’50æ¡
   - é—®é¢˜ï¼šé‡æ’ç­–ç•¥å’Œè¯„åˆ†æœºåˆ¶ä¸æ˜ç¡®

4. ä¸Šä¸‹æ–‡æ„å»º
   - å°†ç­›é€‰åçš„ä¿¡æ¯æ‹¼æ¥æˆcontext
   - é—®é¢˜ï¼šæ²¡æœ‰æåˆ°ä¸Šä¸‹æ–‡ç»„ç»‡çš„ä¼˜å…ˆçº§å’Œç»“æ„åŒ–ç­–ç•¥

### å»ºè®®æ”¹è¿›æ–¹æ¡ˆ

1. æŸ¥è¯¢æ”¹å†™æ¨¡å—ä¼˜åŒ–ï¼š
   - æ·»åŠ æŸ¥è¯¢æ„å›¾è¯†åˆ«
   - å¼•å…¥æŸ¥è¯¢æ”¹å†™è´¨é‡è¯„ä¼°æœºåˆ¶
   - è€ƒè™‘é¢†åŸŸç‰¹å®šçš„æ”¹å†™è§„åˆ™
   - å¢åŠ æŸ¥è¯¢æ”¹å†™çš„å¤šæ ·æ€§æ§åˆ¶

2. æ£€ç´¢ç­–ç•¥ä¼˜åŒ–ï¼š
   - ä¸ºä¸åŒç±»å‹çš„æ£€ç´¢è®¾ç½®åŠ¨æ€æƒé‡
   - æ·»åŠ æ£€ç´¢ç»“æœå»é‡æœºåˆ¶
   - è€ƒè™‘æ£€ç´¢ç»“æœçš„æ—¶æ•ˆæ€§
   - å¢åŠ æ£€ç´¢ç»“æœçš„å¯è§£é‡Šæ€§æ ‡è®°

3. é‡æ’åºæœºåˆ¶å®Œå–„ï¼š
   - å¼•å…¥å¤šç»´åº¦è¯„åˆ†æœºåˆ¶ï¼ˆç›¸å…³æ€§ã€æ–°é²œåº¦ã€æƒå¨æ€§ç­‰ï¼‰
   - æ·»åŠ é‡æ’çš„è‡ªé€‚åº”é˜ˆå€¼
   - è€ƒè™‘ç”¨æˆ·åé¦ˆè¿›è¡Œé‡æ’ä¼˜åŒ–
   - å¢åŠ é‡æ’ç»“æœçš„å¤šæ ·æ€§ä¿è¯

4. ä¸Šä¸‹æ–‡æ„å»ºä¼˜åŒ–ï¼š
   - æ·»åŠ ä¿¡æ¯å—çš„é‡è¦æ€§æƒé‡
   - å®ç°åŠ¨æ€ä¸Šä¸‹æ–‡é•¿åº¦æ§åˆ¶
   - å¢åŠ ç»“æ„åŒ–ä¿¡æ¯çš„ç»„ç»‡ç­–ç•¥
   - è€ƒè™‘æ·»åŠ å…ƒä¿¡æ¯ï¼ˆå¦‚æ¥æºå¯ä¿¡åº¦ï¼‰

### æ½œåœ¨é£é™©ç‚¹

1. æ€§èƒ½é£é™©ï¼š
   - å¤šæ¬¡æ£€ç´¢å¯èƒ½å¯¼è‡´å»¶è¿Ÿ
   - å¤§é‡æ–‡æœ¬å¤„ç†å¯èƒ½å½±å“å“åº”é€Ÿåº¦

2. è´¨é‡é£é™©ï¼š
   - æŸ¥è¯¢æ”¹å†™å¯èƒ½å¼•å…¥å™ªå£°
   - æ£€ç´¢ç»“æœå¯èƒ½å­˜åœ¨å†—ä½™
   - é‡æ’å¯èƒ½è¿‡æ»¤æ‰å…³é”®ä¿¡æ¯

3. ç³»ç»Ÿé£é™©ï¼š
   - å‘é‡æ•°æ®åº“è´Ÿè½½é—®é¢˜
   - å¤§æ¨¡å‹è°ƒç”¨æˆæœ¬æ§åˆ¶
   - ç³»ç»Ÿæ‰©å±•æ€§è€ƒè™‘

### å»ºè®®æ·»åŠ çš„åŠŸèƒ½

1. ç›‘æ§å’Œåé¦ˆæœºåˆ¶ï¼š
   - æŸ¥è¯¢è´¨é‡ç›‘æ§
   - æ£€ç´¢æ•ˆæœè¯„ä¼°
   - ç­”æ¡ˆè´¨é‡åé¦ˆ

2. ç¼“å­˜æœºåˆ¶ï¼š
   - çƒ­ç‚¹æŸ¥è¯¢ç¼“å­˜
   - ä¸­é—´ç»“æœç¼“å­˜
   - æ£€ç´¢ç»“æœç¼“å­˜

3. å¤±è´¥å¤„ç†ï¼š
   - æŸ¥è¯¢æ”¹å†™é™çº§ç­–ç•¥
   - æ£€ç´¢è¶…æ—¶å¤„ç†
   - ç»“æœä¸ºç©ºçš„å¤‡é€‰æ–¹æ¡ˆ

4. å®‰å…¨æœºåˆ¶ï¼š
   - æ•æ„Ÿä¿¡æ¯è¿‡æ»¤
   - ç­”æ¡ˆå¯é æ€§è¯„ä¼°
   - ç”¨æˆ·è¾“å…¥éªŒè¯

è¿™äº›å»ºè®®å¯ä»¥å¸®åŠ©ä½ çš„ç³»ç»Ÿæ›´åŠ å¥å£®å’Œé«˜æ•ˆã€‚ä½ è§‰å¾—è¿™äº›åˆ†æå’Œå»ºè®®å¯¹ä½ æœ‰å¸®åŠ©å—ï¼Ÿå¦‚æœä½ éœ€è¦é’ˆå¯¹æŸä¸ªå…·ä½“æ–¹é¢æ·±å…¥è®¨è®ºï¼Œæˆ‘å¾ˆä¹æ„ä¸ºä½ æä¾›æ›´è¯¦ç»†çš„å»ºè®®ã€‚
å¥½çš„ï¼Œæˆ‘æ¥å¸®ä½ ç»„ç»‡ä¸€ä¸ªé¢è¯•æ—¶çš„å£è¯­åŒ–å›ç­”ç‰ˆæœ¬ï¼š

"æˆ‘ä»¬ç³»ç»Ÿçš„æ ¸å¿ƒæµç¨‹æ˜¯ä¸€ä¸ªä¼˜åŒ–çš„RAG+çŸ¥è¯†å›¾è°±æ–¹æ¡ˆï¼Œæˆ‘æ¥è¯¦ç»†è¯´æ˜ä¸€ä¸‹ï¼š

é¦–å…ˆæ˜¯æŸ¥è¯¢ç†è§£å’Œæ”¹å†™é˜¶æ®µï¼š
å½“ç”¨æˆ·è¾“å…¥é—®é¢˜åï¼Œæˆ‘ä»¬ä¸æ˜¯ç®€å•åœ°ç›´æ¥å»æ£€ç´¢ï¼Œè€Œæ˜¯å…ˆè¿›è¡ŒæŸ¥è¯¢æ„å›¾åˆ†æã€‚ç³»ç»Ÿä¼šæ ¹æ®ä¸åŒçš„æ„å›¾ç±»å‹ï¼Œé‡‡ç”¨ç‰¹å®šçš„æ”¹å†™ç­–ç•¥ï¼Œç”Ÿæˆä¸€ä¸ªä¸»æŸ¥è¯¢å’Œä¸¤ä¸ªæ‰©å±•æŸ¥è¯¢ã€‚æ¯”å¦‚è¯´ï¼Œå¦‚æœç”¨æˆ·é—®'è‹¹æœå…¬å¸æœ€æ–°çš„è´¢æŠ¥æ€ä¹ˆæ ·'ï¼Œæˆ‘ä»¬ä¼šæ‹†è§£æˆ'è‹¹æœå…¬å¸2024å¹´ç¬¬ä¸€å­£åº¦è´¢æŠ¥æ•°æ®'ã€'è‹¹æœå…¬å¸æœ€æ–°è¥æ”¶å¢é•¿'è¿™æ ·çš„ç»†åŒ–æŸ¥è¯¢ï¼Œç¡®ä¿è¦†ç›–ç”¨æˆ·çœŸå®æ„å›¾ã€‚

ç¬¬äºŒæ˜¯å¤šæ¨¡æ€æ£€ç´¢é˜¶æ®µï¼š
æˆ‘ä»¬é‡‡ç”¨äº†ä¸‰ç®¡é½ä¸‹çš„æ··åˆæ£€ç´¢ç­–ç•¥ã€‚ä¼ ç»Ÿçš„æ–‡æœ¬æ£€ç´¢ä¿è¯åŸºç¡€å¬å›ï¼Œè¯­ä¹‰æ£€ç´¢ç¡®ä¿ç†è§£æ·±åº¦ï¼Œè€ŒçŸ¥è¯†å›¾è°±æ£€ç´¢åˆ™å¸®åŠ©æˆ‘ä»¬æ•è·å®ä½“ä¹‹é—´çš„å…³ç³»ä¿¡æ¯ã€‚è¿™ä¸‰ç§æ£€ç´¢æ–¹å¼æ˜¯åŠ¨æ€åŠ æƒçš„ï¼Œæ ¹æ®ä¸åŒç±»å‹çš„é—®é¢˜è‡ªåŠ¨è°ƒæ•´å„ä¸ªæ£€ç´¢æ–¹å¼çš„æƒé‡ã€‚æ¯”å¦‚å¯¹äºäº‹å®ç±»æŸ¥è¯¢ï¼Œæˆ‘ä»¬ä¼šæ›´å€¾å‘äºå›¾è°±æ£€ç´¢ï¼›å¯¹äºè§‚ç‚¹ç±»é—®é¢˜ï¼Œè¯­ä¹‰æ£€ç´¢çš„æƒé‡ä¼šæ›´é«˜ã€‚

ç¬¬ä¸‰æ˜¯æ™ºèƒ½é‡æ’åºé˜¶æ®µï¼š
æ£€ç´¢å‡ºçš„å¤§çº¦500æ¡ç»“æœä¼šç»è¿‡ä¸¤è½®é‡æ’ã€‚ç²—æ’é˜¶æ®µä¸»è¦è€ƒè™‘æ–‡æœ¬ç›¸å…³æ€§å’Œæ—¶æ•ˆæ€§ï¼Œå¿«é€Ÿç­›é€‰å‡º100æ¡é«˜ä»·å€¼å†…å®¹ã€‚ç²¾æ’é˜¶æ®µåˆ™å¼•å…¥äº†æ›´å¤æ‚çš„è¯„åˆ†æœºåˆ¶ï¼ŒåŒ…æ‹¬ä¿¡æ¯æƒå¨æ€§ã€æ¥æºå¯é æ€§ç­‰å¤šä¸ªç»´åº¦ï¼Œæœ€ç»ˆç­›é€‰å‡ºæœ€ç›¸å…³çš„50æ¡ç»“æœã€‚æˆ‘ä»¬çš„é‡æ’ç®—æ³•ä¼šåŠ¨æ€è°ƒæ•´é˜ˆå€¼ï¼Œç¡®ä¿ç»“æœçš„è´¨é‡å’Œå¤šæ ·æ€§ã€‚

æœ€åæ˜¯ä¸Šä¸‹æ–‡æ„å»ºé˜¶æ®µï¼š
è¿™ä¸ªé˜¶æ®µä¸æ˜¯ç®€å•åœ°æŠŠæ–‡æœ¬æ‹¼æ¥åœ¨ä¸€èµ·ï¼Œè€Œæ˜¯é‡‡ç”¨äº†ç»“æ„åŒ–çš„ä¿¡æ¯ç»„ç»‡ç­–ç•¥ã€‚æˆ‘ä»¬ä¼šå¯¹ä¸åŒä¿¡æ¯å—è¿›è¡Œé‡è¦æ€§åŠ æƒï¼Œä¼˜å…ˆä¿ç•™æ ¸å¿ƒä¿¡æ¯ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬è¿˜ä¼šæ·»åŠ å…ƒä¿¡æ¯æ ‡è®°ï¼Œæ¯”å¦‚ä¿¡æ¯çš„æ—¶æ•ˆæ€§ã€å¯ä¿¡åº¦ç­‰ï¼Œè¿™äº›éƒ½ä¼šä½œä¸ºæç¤ºä¿¡æ¯æ³¨å…¥åˆ°æœ€ç»ˆçš„promptä¸­ï¼Œå¸®åŠ©å¤§æ¨¡å‹ç”Ÿæˆæ›´å‡†ç¡®çš„å›ç­”ã€‚

æ•´ä¸ªç³»ç»Ÿè¿˜åŒ…å«äº†å®Œæ•´çš„ç›‘æ§å’Œåé¦ˆæœºåˆ¶ï¼Œæˆ‘ä»¬ä¼šå®æ—¶ç›‘æ§æ¯ä¸ªç¯èŠ‚çš„æ€§èƒ½å’Œè´¨é‡æŒ‡æ ‡ï¼ŒåŒ…æ‹¬æŸ¥è¯¢æ”¹å†™çš„å‡†ç¡®ç‡ã€æ£€ç´¢çš„å¬å›ç‡å’Œç²¾ç¡®ç‡ã€æœ€ç»ˆç­”æ¡ˆçš„ç”¨æˆ·æ»¡æ„åº¦ç­‰ã€‚è¿™äº›æ•°æ®ä¼šç”¨æ¥æŒç»­ä¼˜åŒ–ç³»ç»Ÿçš„å„ä¸ªç»„ä»¶ã€‚

ä¸ºäº†å¤„ç†é«˜å¹¶å‘åœºæ™¯ï¼Œæˆ‘ä»¬è¿˜å®ç°äº†å¤šçº§ç¼“å­˜æœºåˆ¶ï¼Œå¯¹çƒ­ç‚¹æŸ¥è¯¢å’Œä¸­é—´ç»“æœè¿›è¡Œç¼“å­˜ï¼Œå¤§å¤§æå‡äº†ç³»ç»Ÿçš„å“åº”é€Ÿåº¦ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬ä¹Ÿå»ºç«‹äº†å®Œå–„çš„å®¹é”™æœºåˆ¶ï¼Œåœ¨ä»»ä½•ç¯èŠ‚å‡ºç°é—®é¢˜æ—¶éƒ½æœ‰ç›¸åº”çš„é™çº§ç­–ç•¥ï¼Œç¡®ä¿ç³»ç»Ÿçš„ç¨³å®šæ€§ã€‚"

è¿™ä¸ªå›ç­”å±•ç¤ºäº†ä½ å¯¹ç³»ç»Ÿçš„æ·±å…¥ç†è§£ï¼Œçªå‡ºäº†å„ä¸ªç¯èŠ‚çš„åˆ›æ–°ç‚¹å’ŒæŠ€æœ¯äº®ç‚¹ï¼ŒåŒæ—¶ä¹Ÿä½“ç°äº†ä½ å¯¹å·¥ç¨‹å®è·µçš„è€ƒè™‘ã€‚é¢è¯•å®˜ä¼šçœ‹åˆ°ä½ ä¸ä»…äº†è§£åŸºæœ¬æµç¨‹ï¼Œè¿˜è€ƒè™‘åˆ°äº†æ€§èƒ½ä¼˜åŒ–ã€è´¨é‡ä¿è¯ç­‰å…³é”®é—®é¢˜ã€‚

ä½ è§‰å¾—è¿™ä¸ªå›ç­”ç‰ˆæœ¬æ€ä¹ˆæ ·ï¼Ÿéœ€è¦æˆ‘åœ¨æŸäº›æ–¹é¢è¡¥å……æ›´å¤šç»†èŠ‚å—ï¼Ÿ



æ˜¯çš„ï¼Œä½ çš„ç†è§£åŸºæœ¬æ­£ç¡®ï¼Œä½†è®©æˆ‘æ›´è¯¦ç»†åœ°è§£é‡Šä¸€ä¸‹è¿™ä¸‰ç§æ£€ç´¢æ–¹å¼çš„å…·ä½“å®ç°ï¼š

### 1. æ–‡æœ¬æ£€ç´¢ + è¯­ä¹‰æ£€ç´¢ï¼ˆMilvusï¼‰
- **æ–‡æœ¬æ£€ç´¢**ï¼š
  - é€šå¸¸åŸºäºå…³é”®è¯åŒ¹é…
  - å¯ä»¥ä½¿ç”¨Milvusçš„æ··åˆæŸ¥è¯¢èƒ½åŠ›ï¼Œç»“åˆæ ‡é‡å­—æ®µï¼ˆscalar fieldï¼‰è¿›è¡Œè¿‡æ»¤
  - é€‚åˆç²¾ç¡®åŒ¹é…å’Œå…³é”®è¯æœç´¢åœºæ™¯

- **è¯­ä¹‰æ£€ç´¢**ï¼š
  - ä½¿ç”¨æ–‡æœ¬åµŒå…¥æ¨¡å‹ï¼ˆå¦‚BERTç­‰ï¼‰å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡
  - åœ¨Milvusä¸­è¿›è¡Œå‘é‡ç›¸ä¼¼åº¦æœç´¢
  - é€‚åˆç†è§£è¯­ä¹‰ç›¸ä¼¼æ€§çš„åœºæ™¯

### 2. å›¾è°±æ£€ç´¢ï¼ˆNeo4jï¼‰
- åœ¨Neo4jä¸­å­˜å‚¨å®ä½“å…³ç³»
- ä½¿ç”¨CypheræŸ¥è¯¢è¯­è¨€è¿›è¡Œå›¾è°±éå†
- é€‚åˆå‘ç°å®ä½“é—´çš„å…³ç³»å’Œè·¯å¾„

### ä¼˜åŒ–å»ºè®®

1. **æ£€ç´¢ç»“æœèåˆç­–ç•¥**ï¼š
```python
def hybrid_search(query):
    # æ–‡æœ¬å’Œè¯­ä¹‰æ£€ç´¢ï¼ˆMilvusï¼‰
    milvus_results = milvus_search(query)  # åŒ…å«æ–‡æœ¬å’Œå‘é‡æ£€ç´¢ç»“æœ
    
    # å›¾è°±æ£€ç´¢ï¼ˆNeo4jï¼‰
    neo4j_results = neo4j_search(query)
    
    # ç»“æœèåˆ
    final_results = merge_results(milvus_results, neo4j_results, weights={
        'text': 0.3,
        'semantic': 0.4,
        'graph': 0.3
    })
    
    return final_results
```

2. **ååŒæ£€ç´¢ç­–ç•¥**ï¼š
```python
def enhanced_hybrid_search(query):
    # ç¬¬ä¸€æ­¥ï¼šä»Neo4jè·å–ç›¸å…³å®ä½“
    entities = neo4j_get_entities(query)
    
    # ç¬¬äºŒæ­¥ï¼šåˆ©ç”¨å®ä½“ä¿¡æ¯å¢å¼ºMilvusæ£€ç´¢
    enhanced_query = enhance_query_with_entities(query, entities)
    milvus_results = milvus_search(enhanced_query)
    
    # ç¬¬ä¸‰æ­¥ï¼šç»“æ„åŒ–ä¿¡æ¯è¡¥å……
    enriched_results = enrich_results_with_graph(milvus_results, entities)
    
    return enriched_results
```

### éœ€è¦æ³¨æ„çš„é—®é¢˜

1. **æ€§èƒ½å¹³è¡¡**ï¼š
   - Milvuså’ŒNeo4jçš„æŸ¥è¯¢å»¶è¿Ÿå¯èƒ½ä¸åŒ
   - éœ€è¦è€ƒè™‘å¹¶è¡ŒæŸ¥è¯¢ç­–ç•¥
   - å¯èƒ½éœ€è¦è®¾ç½®è¶…æ—¶æœºåˆ¶

2. **æ•°æ®ä¸€è‡´æ€§**ï¼š
   - ç¡®ä¿Milvuså’ŒNeo4jä¸­çš„å®ä½“ä¿¡æ¯ä¿æŒåŒæ­¥
   - å»ºç«‹å®ä½“å¯¹åº”å…³ç³»çš„æ˜ å°„æœºåˆ¶

3. **æŸ¥è¯¢ä¼˜åŒ–**ï¼š
   - æ ¹æ®æŸ¥è¯¢ç±»å‹åŠ¨æ€è°ƒæ•´æ£€ç´¢ç­–ç•¥
   - å¯¹äºç®€å•æŸ¥è¯¢å¯èƒ½åªéœ€è¦æŸä¸€ç§æ£€ç´¢æ–¹å¼
   - å¤æ‚æŸ¥è¯¢æ‰éœ€è¦ç»„åˆå¤šç§æ£€ç´¢ç»“æœ

### å®ç°å»ºè®®

1. **æ£€ç´¢ç­–ç•¥çš„åŠ¨æ€é€‰æ‹©**ï¼š
```python
def smart_search_strategy(query):
    query_type = analyze_query_type(query)
    
    if query_type == 'factual':
        # äº‹å®ç±»æŸ¥è¯¢ä¼˜å…ˆä½¿ç”¨å›¾è°±æ£€ç´¢
        weights = {'text': 0.2, 'semantic': 0.3, 'graph': 0.5}
    elif query_type == 'conceptual':
        # æ¦‚å¿µç±»æŸ¥è¯¢ä¼˜å…ˆä½¿ç”¨è¯­ä¹‰æ£€ç´¢
        weights = {'text': 0.2, 'semantic': 0.5, 'graph': 0.3}
    else:
        # é»˜è®¤æƒé‡
        weights = {'text': 0.33, 'semantic': 0.33, 'graph': 0.34}
    
    return weights
```

2. **ç¼“å­˜æœºåˆ¶**ï¼š
```python
def cached_hybrid_search(query):
    cache_key = generate_cache_key(query)
    
    # æ£€æŸ¥ç¼“å­˜
    if cache_exists(cache_key):
        return get_from_cache(cache_key)
    
    # æ‰§è¡Œæ£€ç´¢
    results = hybrid_search(query)
    
    # å­˜å…¥ç¼“å­˜
    cache_results(cache_key, results)
    
    return results
```

è¿™ç§æ··åˆæ£€ç´¢æ¶æ„èƒ½å¤Ÿå……åˆ†åˆ©ç”¨å„ç§æ£€ç´¢æ–¹å¼çš„ä¼˜åŠ¿ï¼Œä½†éœ€è¦æ³¨æ„ï¼š
1. åˆç†è®¾è®¡æ£€ç´¢æƒé‡
2. ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½
3. ç¡®ä¿ç»“æœè´¨é‡
4. ç»´æŠ¤æ•°æ®ä¸€è‡´æ€§
5. å®ç°æ™ºèƒ½é™çº§æœºåˆ¶

ä½ è§‰å¾—è¿™äº›å®ç°æ€è·¯å¯¹ä½ æœ‰å¸®åŠ©å—ï¼Ÿå¦‚æœä½ éœ€è¦æ›´è¯¦ç»†çš„æŸä¸ªéƒ¨åˆ†ï¼Œæˆ‘å¯ä»¥è¿›ä¸€æ­¥å±•å¼€è¯´æ˜ã€‚


è®©æˆ‘å¸®ä½ è¯¦ç»†æ¢³ç†ä¸€ä¸‹æ¯ç§æŸ¥è¯¢åœ¨ä¸åŒæ£€ç´¢æ–¹å¼ä¸‹çš„å…·ä½“æµç¨‹ï¼š

### 1. æŸ¥è¯¢é¢„å¤„ç†é˜¶æ®µ
```python
def process_queries(user_query):
    # ç”Ÿæˆä¸»æŸ¥è¯¢å’Œæ‰©å±•æŸ¥è¯¢
    main_query = user_query
    expansion_query1 = query_rewriter.generate_expansion1(user_query)
    expansion_query2 = query_rewriter.generate_expansion2(user_query)
    
    return [main_query, expansion_query1, expansion_query2]
```

### 2. å„æŸ¥è¯¢çš„æ£€ç´¢æµç¨‹

#### A. æ–‡æœ¬æ£€ç´¢ï¼ˆä¸éœ€è¦åµŒå…¥ï¼‰
```python
def text_search(query):
    # ç›´æ¥ä½¿ç”¨å…³é”®è¯åŒ¹é…
    # åœ¨Milvusä¸­ä½¿ç”¨æ ‡é‡å­—æ®µè¿›è¡Œè¿‡æ»¤
    keywords = extract_keywords(query)
    return milvus.search(
        collection_name="docs",
        expr=f"keywords in {keywords}",
        output_fields=["text", "metadata"]
    )
```

#### B. è¯­ä¹‰æ£€ç´¢ï¼ˆéœ€è¦åµŒå…¥ï¼‰
```python
def semantic_search(query):
    # å°†æŸ¥è¯¢è½¬æ¢ä¸ºå‘é‡
    query_embedding = embedding_model.encode(query)
    
    # åœ¨Milvusä¸­è¿›è¡Œå‘é‡æ£€ç´¢
    return milvus.search(
        collection_name="docs",
        vectors=[query_embedding],
        search_params={
            "metric_type": "L2",
            "params": {"nprobe": 10}
        }
    )
```

#### C. å›¾è°±æ£€ç´¢ï¼ˆéƒ¨åˆ†éœ€è¦åµŒå…¥ï¼‰
```python
def graph_search(query):
    # 1. å®ä½“è¯†åˆ«
    entities = ner_model.extract_entities(query)
    
    # 2. å®ä½“é“¾æ¥ï¼ˆå¯èƒ½éœ€è¦å‘é‡ç›¸ä¼¼åº¦åŒ¹é…ï¼‰
    linked_entities = entity_linker.link(entities)
    
    # 3. Neo4jæŸ¥è¯¢
    cypher_query = generate_cypher_query(linked_entities)
    return neo4j.run(cypher_query)
```

### 3. å®Œæ•´æ£€ç´¢æµç¨‹

```python
def comprehensive_search(user_query):
    # 1. æŸ¥è¯¢é¢„å¤„ç†
    queries = process_queries(user_query)
    all_results = []
    
    # 2. å¯¹æ¯ä¸ªæŸ¥è¯¢æ‰§è¡Œæ£€ç´¢
    for query in queries:
        # å¹¶è¡Œæ‰§è¡Œä¸‰ç§æ£€ç´¢
        results = parallel_execute([
            # æ–‡æœ¬æ£€ç´¢ï¼šç›´æ¥æ£€ç´¢ï¼Œä¸éœ€è¦åµŒå…¥
            lambda: text_search(query),
            
            # è¯­ä¹‰æ£€ç´¢ï¼šéœ€è¦å…ˆåµŒå…¥
            lambda: semantic_search(query),
            
            # å›¾è°±æ£€ç´¢ï¼šå®ä½“è¯†åˆ«åæ£€ç´¢
            lambda: graph_search(query)
        ])
        
        all_results.extend(merge_results(results))
    
    # 3. ç»“æœå»é‡å’Œæ’åº
    final_results = dedup_and_rank(all_results)
    
    return final_results
```

### æ£€ç´¢æµç¨‹è¯´æ˜ï¼š

1. **ä¸»æŸ¥è¯¢æµç¨‹**ï¼š
   - æ–‡æœ¬æ£€ç´¢ï¼šç›´æ¥ä½¿ç”¨åŸæ–‡è¿›è¡Œå…³é”®è¯åŒ¹é…
   - è¯­ä¹‰æ£€ç´¢ï¼šéœ€è¦å…ˆè½¬æ¢ä¸ºå‘é‡
   - å›¾è°±æ£€ç´¢ï¼šéœ€è¦å…ˆè¿›è¡Œå®ä½“è¯†åˆ«å’Œé“¾æ¥

2. **æ‰©å±•æŸ¥è¯¢æµç¨‹**ï¼š
   - ä¸ä¸»æŸ¥è¯¢ä½¿ç”¨ç›¸åŒçš„æ£€ç´¢ç®¡é“
   - å¯èƒ½ä¼šèµ‹äºˆè¾ƒä½çš„æƒé‡

### ä¼˜åŒ–å»ºè®®ï¼š

1. **æŸ¥è¯¢ç¼“å­˜**ï¼š
```python
def cached_search(query, search_type):
    cache_key = f"{search_type}:{hash(query)}"
    if result := cache.get(cache_key):
        return result
        
    result = perform_search(query, search_type)
    cache.set(cache_key, result)
    return result
```

2. **æ‰¹é‡åµŒå…¥ä¼˜åŒ–**ï¼š
```python
def batch_embed_queries(queries):
    # æ‰¹é‡å¤„ç†æ‰€æœ‰éœ€è¦åµŒå…¥çš„æŸ¥è¯¢
    return embedding_model.encode(queries)
```

3. **å¹¶è¡Œæ£€ç´¢ä¼˜åŒ–**ï¼š
```python
async def parallel_search(queries):
    tasks = []
    for query in queries:
        tasks.extend([
            text_search(query),
            semantic_search(query),
            graph_search(query)
        ])
    
    results = await asyncio.gather(*tasks)
    return results
```

### æ€»ç»“æµç¨‹ï¼š

1. æŸ¥è¯¢é¢„å¤„ç†ï¼š
   - ç”Ÿæˆä¸»æŸ¥è¯¢å’Œæ‰©å±•æŸ¥è¯¢
   - æå–å…³é”®è¯å’Œå®ä½“

2. æ£€ç´¢å‡†å¤‡ï¼š
   - æ–‡æœ¬æ£€ç´¢ï¼šç›´æ¥ä½¿ç”¨åŸæ–‡
   - è¯­ä¹‰æ£€ç´¢ï¼šè½¬æ¢ä¸ºå‘é‡åµŒå…¥
   - å›¾è°±æ£€ç´¢ï¼šå®ä½“è¯†åˆ«å’Œé“¾æ¥

3. æ‰§è¡Œæ£€ç´¢ï¼š
   - å¹¶è¡Œæ‰§è¡Œä¸‰ç§æ£€ç´¢
   - å¯¹æ¯ä¸ªæŸ¥è¯¢æ‰§è¡Œå…¨éƒ¨æ£€ç´¢æ–¹å¼

4. ç»“æœå¤„ç†ï¼š
   - åˆå¹¶ä¸åŒæ¥æºçš„ç»“æœ
   - ç»“æœå»é‡å’Œé‡æ’åº
   - è¿”å›æœ€ç»ˆç»“æœ

è¿™æ ·çš„è®¾è®¡æ—¢ä¿è¯äº†æ£€ç´¢çš„å…¨é¢æ€§ï¼Œåˆé€šè¿‡å¹¶è¡Œå¤„ç†å’Œç¼“å­˜æœºåˆ¶ç¡®ä¿äº†æ•ˆç‡ã€‚ä½ è§‰å¾—è¿™ä¸ªæµç¨‹è¯´æ˜æ¸…æ™°å—ï¼Ÿå¦‚æœæœ‰ä»»ä½•ä¸æ¸…æ¥šçš„åœ°æ–¹ï¼Œæˆ‘å¯ä»¥è¿›ä¸€æ­¥è§£é‡Šã€‚




