
<html>
<head>
<meta charset="UTF-8">
<title>Export Notes by xxhk.org</title>
<style>

body { font-family: Arial, sans-serif; }
.card { border: 2px solid #000; padding: 10px; border-radius: 10px; margin-bottom: 20px; }
img {
max-width: 100%;
height: auto;
border: 1px solid lightgray;
border-radius: 10px;
display: inline-block;
margin: 10px 0px;
}
.separator { border-top: 1px dashed #000; margin: 10px 0; }
.tags { background-color: lightgray; padding: 5px 10px; margin-bottom: 10px; border-radius: 5px; display: inline-block; }
.footer {
text-align: center;
color: grey;
margin-top: 20px;
padding: 10px;
}

.video-container {
margin: 10px 0;
}
.video-placeholder {
position: relative;
cursor: pointer;
}
.play-button {
position: absolute;
top: 50%;
left: 50%;
transform: translate(-50%, -50%);
width: 68px;
height: 48px;
background-color: rgba(0, 0, 0, 0.7);
border-radius: 14px;
cursor: pointer;
}
.play-button::before {
content: '';
position: absolute;
top: 50%;
left: 55%;
transform: translate(-50%, -50%);
border-style: solid;
border-width: 12px 0 12px 20px;
border-color: transparent transparent transparent white;
}
.play-button:hover {
background-color: red;
}

</style>

</head>
<body>
<div id="cards-container">
<div class="card">
<div class="field_0"><div>团队里面的&nbsp; 产品经理主要负责哪些工作？</div></div>
<div class="separator"></div>
<div class="field_1">负责需求收集、功能规划和用户反馈处理。</div>
</div>
<div class="card">
<div class="field_0">构建一个RAG系统并进行微调的流程大致是什么？</div>
<div class="separator"></div>
<div class="field_1"><ol><li><div><strong>模型微调阶段</strong>：首先使用LoRA对基础LLM(如LLaMA)进行微调，提高模型的指令遵循能力和特定领域知识<a href="https://blog.csdn.net/star1210644725/article/details/140409355" aria-hidden="true"><span style="color: oklch(var(--text-color-100)/var(--tw-text-opacity));">1</span></a><a href="https://www.aizws.net/news/detail/1408" aria-hidden="true"><span style="color: oklch(var(--text-color-100)/var(--tw-text-opacity));">4</span></a>。这一步可以帮助模型更好地适应下游任务，尤其是在RAG任务中从检索到的上下文中提取答案的能力<a href="https://blog.csdn.net/star1210644725/article/details/140409355" aria-hidden="true"><span style="color: oklch(var(--text-color-100)/var(--tw-text-opacity));">1</span></a>。</div></li><li><div><strong>RAG系统构建</strong>：将微调后的LLM集成到RAG架构中，实现"检索-重排-生成"的流程<a href="https://blog.csdn.net/star1210644725/article/details/140409355" aria-hidden="true"><span style="color: oklch(var(--text-color-100)/var(--tw-text-opacity));">1</span></a>。这包括:</div><ul><li><div>构建检索系统</div></li><li><div>集成微调后的LLM</div></li><li><div>实现上下文处理机制</div></li></ul></li><li><div><strong>RAG系统微调</strong>：使用QCA(问题+上下文+答案)格式的数据集对整个RAG系统进行进一步优化<a href="https://blog.csdn.net/star1210644725/article/details/140409355" aria-hidden="true"><span style="color: oklch(var(--text-color-100)/var(--tw-text-opacity));">1</span></a><a href="https://luxiangdong.com/2023/09/01/ragvsft/" aria-hidden="true"><span style="color: oklch(var(--text-color-100)/var(--tw-text-opacity));">5</span></a>。这一步可以提升系统在上下文排序和答案生成方面的表现。</div></li></ol></div>
</div>
<div class="card">
<div class="field_0">目前主流的LoRA微调数据集分别是收集垂直领域QA对 以及&nbsp;生成QCA三元组，<br>其中，生成QCA三元组，核心思想是什么？</div>
<div class="separator"></div>
<div class="field_1">循环迭代的方式构建数据集。</div>
</div>
<div class="card">
<div class="field_0"><div>在您的RAG系统中，Function Call机制 涉及到复杂计算处理，包括哪三方面？</div></div>
<div class="separator"></div>
<div class="field_1">房贷计算、租金回报率 以及 汇率转换。</div>
</div>
<div class="card">
<div class="field_0">LoRA 数据格式有哪两种？</div>
<div class="separator"></div>
<div class="field_1">对话格式以及指令格式。&nbsp;</div>
</div>
<div class="card">
<div class="field_0">Perplexity和F1 Score ，评估重点，优势，局限性 分别是什么？</div>
<div class="separator"></div>
<div class="field_1"><img src="images/paste-fff905e661690a19709ad905d1b792cf512202b5.jpg"></div>
</div>
<div class="card">
<div class="field_0">利用 Hugging Face 的 哪个库构造 QLoRA 配置。<br>我设定了低秩矩阵的秩数是多少？和更新策略。</div>
<div class="separator"></div>
<div class="field_1"><ul><li><div>&nbsp;利用 Hugging Face 的 PEFT 库构造 QLoRA 配置。在这一阶段，我设定了低秩矩阵的秩数（例如&nbsp;r=8<span style="font-style: italic;">r</span>=8）和更新策略，通常选择仅针对 Transformer 模型中的注意力模块或全部线性层进行参数更新，以避免灾难性遗忘，同时确保适应目标任务。</div></li></ul></div>
</div>
<div class="card">
<div class="field_0">EM的优缺点 分别是什么？</div>
<div class="separator"></div>
<div class="field_1">优点是，<br>简单直观：容易理解和实现<br>计算效率：计算速度快，不需要复杂算法<br>缺点是，<br>过于严格：即使答案语义相同但表述不同也会被判为不匹配</div>
</div>
<div class="card">
<div class="field_0"><div>LoRA的三个步骤是什么？</div></div>
<div class="separator"></div>
<div class="field_1"><ol><li><strong>冻结原始权重</strong>：保持预训练模型的权重不变</li><li><strong>添加低秩适应矩阵</strong>：为每个需要微调的权重矩阵W添加一个低秩分解：ΔW = A × B<ul><li>A是一个d×r的矩阵</li><li>B是一个r×k的矩阵</li><li>r是秩，通常远小于d和k</li></ul></li><li><strong>最终权重</strong>：W' = W + ΔW = W + A × B</li></ol></div>
</div>
<div class="card">
<div class="field_0">默认情况下，LoRA仅在哪里启用？但可以扩展到哪里？</div>
<div class="separator"></div>
<div class="field_1">在多头自注意力块中的键(Key)和查询(Query)矩阵上启用，但可以扩展到：<ul><li><div>值(Value)矩阵</div></li><li><div>投影层</div></li><li><div>线性层</div></li></ul></div>
</div>
<div class="card">
<div class="field_0">QLoRA 使用什么样的数据格式以及每一行代表什么？&nbsp;</div>
<div class="separator"></div>
<div class="field_1"><div>使用JSON或JSONL格式存储数据，每一行代表一个完整的对话或样本。</div></div>
</div>
<div class="card">
<div class="field_0">RAGAS框架实际上包含多个评估维度，分别是什么以及什么含义？</div>
<div class="separator"></div>
<div class="field_1"><ul><li><strong>Answer Relevance</strong>：回答与问题的相关性</li><li><strong>Answer Correctness</strong>：回答的事实准确性</li><li><strong>Context Precision</strong>：检索文档的精确度</li><li><strong>Context Recall</strong>：检索文档的召回率</li><li><strong>Faithfulness</strong>：回答对检索内容的忠实度</li><li><img src="images/paste-1923263f150de69ec0c1d2ed14a510e67bd1b1d6.jpg"><br></li></ul></div>
</div>
<div class="card">
<div class="field_0">A10G 配备 多少显存？</div>
<div class="separator"></div>
<div class="field_1">24GB 。</div>
</div>
<div class="card">
<div class="field_0">QLoRA（Quantized Low-Rank Adaptation）是结合什么和什么的微调技术？&nbsp;</div>
<div class="separator"></div>
<div class="field_1">一种结合量化和低秩适配器的微调技术。</div>
</div>
<div class="card">
<div class="field_0">无论是QLoRA还是LoRA微调，数据格式的核心要求都是明确区分什么和什么，保证模型能够正确理解什么？</div>
<div class="separator"></div>
<div class="field_1">输入（提示或指令）与输出（回复或答案），理解任务上下文。</div>
</div>
<div class="card">
<div class="field_0">默认情况下，LoRA微调的时候学习率&nbsp; 和 dropout分别的设置是什么？</div>
<div class="separator"></div>
<div class="field_1"><ul><li><div>常用学习率为3e-4</div></li><li><div>LoRA dropout通常设置为0.05</div></li></ul></div>
</div>
<div class="card">
<div class="field_0">QLoRA 配置 为什么通常选择仅针对 Transformer 模型中的注意力模块或全部线性层进行参数更新？</div>
<div class="separator"></div>
<div class="field_1">避免灾难性遗忘，同时确保适应目标任务。</div>
</div>
<div class="card">
<div class="field_0">如何使用QLoRA进行微调？【4步骤】</div>
<div class="separator"></div>
<div class="field_1"><ul><li><div>首先，我使用 bitsandbytes 库将预训练模型加载为 4-bit 量化格式，显著降低了 GPU 内存占用，从而使得在有限显存资源下微调成为可能。</div></li><li><div>接着，利用 Hugging Face 的 PEFT 库构造 QLoRA 配置。在这一阶段，我设定了低秩矩阵的秩数（例如&nbsp;r=8<span style="font-style: italic;">r</span>=8）和更新策略，通常选择仅针对 Transformer 模型中的注意力模块或全部线性层进行参数更新，以避免灾难性遗忘，同时确保适应目标任务。</div></li><li><div>然后，我准备了一个格式化一致的指令-响应数据集（例如包含 5000 条样本），将数据分割为训练集和验证集，为监督式微调提供一致的输入格式。</div></li><li><div>在训练阶段，我采用 AWS SageMaker平台上的单个 NVIDIA A10G，并通过如 Hugging Face&nbsp;TRL&nbsp;库中的 SFTTrainer 类设定训练参数（包括 epoch 数、batch size 及其它超参数），实现快速、低成本的微调训练</div></li></ul></div>
</div>
<div class="card">
<div class="field_0">F1 Score&nbsp;，评估重点，优势，局限性 分别是什么？</div>
<div class="separator"></div>
<div class="field_1">生成答案与参考答案的匹配度，<br>平衡评估答案精确性和完整性。<br>依赖参考答案质量。</div>
</div>
<div class="card">
<div class="field_0">使用&nbsp;bitsandbytes&nbsp;将模型加载为什么版本？</div>
<div class="separator"></div>
<div class="field_1">低精度版本。</div>
</div>
<div class="card">
<div class="field_0">支持 LoRA 和 QLoRA 微调 用到了哪个第三方库？&nbsp;&nbsp;<br>实现低精度量化（4-bit 权重）&nbsp;用到了哪个第三方库？&nbsp;&nbsp;</div>
<div class="separator"></div>
<div class="field_1"><ul><li><div><code>peft</code>：支持 LoRA 和 QLoRA 微调。</div></li><li><div><code>bitsandbytes</code>：实现低精度量化（4-bit 权重）。</div></li></ul></div>
</div>
<div class="card">
<div class="field_0">目前主流的LoRA微调数据集分别是收集垂直领域QA对 以及&nbsp;生成QCA三元组，<br>其中，生成QCA三元组，具体的要点分别是什么？</div>
<div class="separator"></div>
<div class="field_1">1. 先用大模型从context生成问题<br>2. 再用另一个模型或同一模型的不同prompt回答这些问题<br>3. 第三轮评估问答质量，筛选高质量对</div>
</div>
<div class="card">
<div class="field_0">NVIDIA A10G，<br>NVIDIA A100，<br>分别作用是什么？&nbsp;</div>
<div class="separator"></div>
<div class="field_1">NVIDIA A10G更适合中等规模的AI推理任务和图形处理，而A100则是面向高性能任务（如大型模型训练和科学计算）的更强大解决方案。</div>
</div>
<div class="card">
<div class="field_0"><div>团队里面的&nbsp; NLP算法工程师，后端工程师，数据工程师，前端开发人员 以及产品经理，他们分别的岗位职责是什么？简要列举一下。</div></div>
<div class="separator"></div>
<div class="field_1"><ul><li><strong>NLP算法工程师</strong>（您的角色）：负责核心算法实现、模型训练与优化</li><li><strong>后端工程师</strong>：负责API开发、系统集成和部署</li><li><strong>数据工程师</strong>：负责数据处理、向量库维护</li><li><strong>前端开发人员</strong>：负责用户界面设计与实现</li><li><strong>产品经理</strong>：负责需求分析和产品规划</li></ul></div>
</div>
<div class="card">
<div class="field_0">Perplexity(困惑度)是评估语言模型对文本什么能力的指标？</div>
<div class="separator"></div>
<div class="field_1">预测能力。</div>
</div>
<div class="card">
<div class="field_0">Exact Match (EM) 检查的是什么？</div>
<div class="separator"></div>
<div class="field_1">它检查模型生成的答案是否与标准答案完全一致。这是一个二元指标：要么完全匹配(得分1)，要么不匹配(得分0)。</div>
</div>
<div class="card">
<div class="field_0"><div>&nbsp;EM，F1，ROUGE，BLEU 分别的工作原理是什么？</div></div>
<div class="separator"></div>
<div class="field_1">EM 检查完全匹配，<br>F1 词级别的精确率和召回率，<br>ROUGE 评估n-gram重叠，<br>BLEU 评估n-gram精确度。</div>
</div>
<div class="card">
<div class="field_0">BLEU和ROUGE是否是评估问答系统最合适的指标？</div>
<div class="separator"></div>
<div class="field_1">不是。</div>
</div>
<div class="card">
<div class="field_0">秩(r)是QLoRA最重要的参数之一，&nbsp;<br>哪个参数与秩(r)密切相关？</div>
<div class="separator"></div>
<div class="field_1">Alpha。</div>
</div>
<div class="card">
<div class="field_0"><div>团队里面的&nbsp; 后端 工程师主要负责哪些工作？</div></div>
<div class="separator"></div>
<div class="field_1">合理配置。负责API网关、FastAPI框架实现、系统集成以及性能优化，2人团队可以有效处理。</div>
</div>
<div class="card">
<div class="field_0">QLoRA 在 4-bit 量化下对 7B 模型的显存需求约是多少？</div>
<div class="separator"></div>
<div class="field_1">需要约 11GB 显存。</div>
</div>
<div class="card">
<div class="field_0"><div>团队里面的&nbsp; 前端 工程师主要负责哪些工作？</div></div>
<div class="separator"></div>
<div class="field_1">对于内部员工培训系统，界面可能相对简单，1人足够。</div>
</div>
<div class="card">
<div class="field_0">QLoRA&nbsp; 仅仅微调了很小的一部分参数，这些参数相当于全模型参数的多少比例?</div>
<div class="separator"></div>
<div class="field_1">0.06%到0.1%。&nbsp;</div>
</div>
<div class="card">
<div class="field_0"><div>LoRA的核心思想是什么？</div></div>
<div class="separator"></div>
<div class="field_1">通过低秩矩阵分解来高效适应预训练模型。</div>
</div>
<div class="card">
<div class="field_0"><div>RAGAS 是否是专门评估LoRA微调效果的工具？</div></div>
<div class="separator"></div>
<div class="field_1">不是专门评估LoRA微调效果的工具，RAGAS是评估RAG系统的框架。</div>
</div>
<div class="card">
<div class="field_0">微调&nbsp;<span style="color: oklch(0.304 0.04 213.681); background-color: oklch(0.99 0.004 106.471);">Llama 2 7B&nbsp;</span>的时候使用的数据格式是什么？包含什么字段？&nbsp;&nbsp;</div>
<div class="separator"></div>
<div class="field_1">微调数据通常采用JSON格式，包含字段如instruction、input、output，支持多轮对话。</div>
</div>
<div class="card">
<div class="field_0"><div>LoRA适用的模型类型只有文本生成模型吗？</div></div>
<div class="separator"></div>
<div class="field_1">不是的，还包含下面内容，<br><ol><li><div><strong>分类任务模型</strong>（完全适用）</div><ul><li>文本分类模型</li><li>情感分析模型</li><li>意图识别模型</li><li>命名实体识别模型</li></ul></li><li><div><strong>其他模态模型</strong></div><ul><li>多模态模型（如CLIP、Stable Diffusion等）</li><li>语音模型</li><li>计算机视觉模型</li></ul></li></ol></div>
</div>
<div class="card">
<div class="field_0">问答系统中最直观的评估指标是什么？</div>
<div class="separator"></div>
<div class="field_1"><div>Exact Match (EM)。</div><div><br></div></div>
</div>
<div class="card">
<div class="field_0">目前主流的LoRA微调数据集分别是收集垂直领域QA对 以及&nbsp;生成QCA三元组，<br>其中，生成QCA三元组，核心思想是循环迭代的方式构建数据集。如何理解？</div>
<div class="separator"></div>
<div class="field_1"><ol><li>先构建小规模高质量种子数据集</li><li>微调初步模型</li><li>使用该模型生成更多数据</li><li>人工筛选和修正</li><li>扩充数据集后再次微调</li></ol></div>
</div>
<div class="card">
<div class="field_0">EM指标的工作原理以及适用场景分别是什么？</div>
<div class="separator"></div>
<div class="field_1">检查完全匹配，有明确唯一答案的问题。</div>
</div>
<div class="card">
<div class="field_0">典型的QLoRA对话格式示例是什么？</div>
<div class="separator"></div>
<div class="field_1">{<br>&nbsp; "conversations": [<br>&nbsp;&nbsp;&nbsp; { "role": "system", "content": "你是一个有帮助的助手。" },<br>&nbsp;&nbsp;&nbsp; { "role": "user", "content": "请问如何使用QLoRA进行微调？" },<br>&nbsp;&nbsp;&nbsp; { "role": "assistant", "content": "可以先准备符合要求的数据集，然后使用QLoRA的工具加载预训练模型并开始训练。" }<br>&nbsp; ]<br>}</div>
</div>
<div class="card">
<div class="field_0">目前主流的LoRA微调数据集获取方式是什么？【2种】</div>
<div class="separator"></div>
<div class="field_1"><ol><li>收集垂直领域的QA对</li><li>利用大模型从现有文本生成QCA三元组</li></ol></div>
</div>
<div class="card">
<div class="field_0">微调后，模型在房地产领域文本上的Perplexity应显著降低还是升高？</div>
<div class="separator"></div>
<div class="field_1">降低。</div>
</div>
<div class="card">
<div class="field_0">在房地产领域问答系统中，EM为什么设置多个参考答案?</div>
<div class="separator"></div>
<div class="field_1"><div>设置多个参考答案：对于有多种正确表述的问题，准备多个参考答案，只要匹配其中一个即算正确.</div></div>
</div>
<div class="card">
<div class="field_0">目前主流的LoRA微调数据集分别是收集垂直领域QA对 以及&nbsp;生成QCA三元组，<br>其中，生成QCA三元组，具体的要点分别是什么？</div>
<div class="separator"></div>
<div class="field_1"><ul><li><div><strong>多样化问题类型</strong>：设计不同prompt生成不同类型的问题（事实型、推理型、比较型等）</div></li><li><div><strong>对抗性样本生成</strong>：故意生成一些难以回答或需要推理的问题，提高模型能力</div></li><li><div><strong>结构化知识提取</strong>：从context中提取结构化知识（如实体关系），基于此生成更精准的问题</div></li><li><div><strong>反事实样本</strong>：生成一些context中没有直接答案的问题，训练模型识别"不知道"的情况</div></li></ul></div>
</div>
<div class="card">
<div class="field_0">秩(r)是QLoRA最重要的参数之一，决定了什么？直接影响什么？</div>
<div class="separator"></div>
<div class="field_1">决定了LoRA矩阵的秩或维度，直接影响模型的复杂度和容量。</div>
</div>
<div class="card">
<div class="field_0">Perplexity ，评估重点，优势，局限性 分别是什么？</div>
<div class="separator"></div>
<div class="field_1">模型对领域语言的内在理解，<br>不需参考答案，直接评估领域适应性，<br>不直接反映答案质量</div>
</div>
<div class="card">
<div class="field_0">bitsandbytes&nbsp;在 QLoRA 中负责谁量化处理？</div>
<div class="separator"></div>
<div class="field_1">权重的量化。</div>
</div>
<div class="card">
<div class="field_0">PEFT 的中文全称是什么？</div>
<div class="separator"></div>
<div class="field_1">参数高效微调。</div>
</div>
<div class="card">
<div class="field_0">NVIDIA A10G 定价约为每小时多少？</div>
<div class="separator"></div>
<div class="field_1">$1.212。</div>
</div>
<div class="card">
<div class="field_0"><div>团队里面的&nbsp; 数据 工程师主要负责哪些工作？</div></div>
<div class="separator"></div>
<div class="field_1">考虑到需要处理房地产领域知识库构建、向量化、Milvus和Neo4j数据库维护，以及可能的数据清洗和增强工作，2人是合理的。</div>
</div>
<div class="card">
<div class="field_0">如何使用QLoRA进行微调？【4步骤，口语化】</div>
<div class="separator"></div>
<div class="field_1"><span style="color: oklch(0.304 0.04 213.681); background-color: oklch(0.99 0.004 106.471);">我首先用了 bitsandbytes 把预训练模型加载成 4-bit 量化版本，这样能大大减少 GPU 占用。<br>接下来，我利用 Hugging Face 的 PEFT 库定义了 QLoRA 的参数，比如设定低秩矩阵的秩数（比如&nbsp;</span><span style="color: oklch(0.304 0.04 213.681); background-color: oklch(0.99 0.004 106.471);">r=8<span style="font-style: italic;">r</span>=8</span><span style="color: oklch(0.304 0.04 213.681); background-color: oklch(0.99 0.004 106.471);">），并决定只更新 Transformer 里的注意力层或者所有线性层，这样既保证了模型不忘记预训练的</span>知识，又能更快地收敛。<br>然后我准备了一份大约 5000 条指令-响应对的数据集，<br>并在 AWS SageMaker平台上的单个 NVIDIA A10G<span style="color: oklch(0.304 0.04 213.681); background-color: oklch(0.99 0.004 106.471);">&nbsp;上，用 SFTTrainer 等工具进行训练。</span></div>
</div>
<div class="card">
<div class="field_0">NVIDIA A10G 内存显存分别多少？</div>
<div class="separator"></div>
<div class="field_1">24 GB显存，<br>32 GiB内存。</div>
</div>
<div class="card">
<div class="field_0"><div>整个团队有几个人？分别各个岗位是几个人？</div></div>
<div class="separator"></div>
<div class="field_1">团队一共9个人，<br>算法工程师3人，<br>后端工程师2个人，<br>前端工程师1个人，<br>数据工程师2个人，<br>产品经理1个人。</div>
</div>
<div class="card">
<div class="field_0">在房地产领域问答系统中，EM适用于评估什么类型的问题？</div>
<div class="separator"></div>
<div class="field_1"><ol><li><div><strong>事实性问题</strong>：</div><ul><li>问：英国房产租赁最短合同期通常是多久？</li><li>答：6个月</li></ul></li><li><div><strong>定义类问题</strong>：</div><ul><li>问：什么是HMO许可证？</li><li>答：HMO许可证是多户共住房屋的必要许可证明</li></ul></li><li><div><strong>法规查询</strong>：</div><ul><li>问：伦敦区域的EPC最低要求是什么级别？</li><li>答：E级</li></ul></li></ol></div>
</div>
<div class="card">
<div class="field_0">目前主流的LoRA微调数据集分别是收集垂直领域QA对 以及&nbsp;生成QCA三元组，<br>其中，生成QCA三元组，其中对抗性样本生成是什么意思？</div>
<div class="separator"></div>
<div class="field_1"><div>故意生成一些难以回答或需要推理的问题，提高模型能力.</div></div>
</div>
<div class="card">
<div class="field_0">模型使用的是什么卡以及多大显存？&nbsp;&nbsp;</div>
<div class="separator"></div>
<div class="field_1">NVIDIA A10G，24 GB。</div>
</div>
<div class="card">
<div class="field_0">目前主流的LoRA微调数据集分别是收集垂直领域QA对 以及&nbsp;生成QCA三元组，<br>其中，收集垂直领域QA对，具体的要点分别是什么？</div>
<div class="separator"></div>
<div class="field_1"><ul><li><strong>数据多样性</strong>：确保覆盖领域内不同难度和类型的问题</li><li><strong>人工审核环节</strong>：引入专家审核机制，确保数据准确性</li><li><strong>数据增强</strong>：对现有QA对进行改写、扩展，增加数据多样性</li></ul></div>
</div>
<div class="card">
<div class="field_0"><div>LoRA是否适用于分类任务？</div></div>
<div class="separator"></div>
<div class="field_1">LoRA完全适用于分类任务。</div>
</div>
<div class="card">
<div class="field_0">Exact Match (EM) 和 F1 Score 分别评估是什么?</div>
<div class="separator"></div>
<div class="field_1">Exact Match (EM)：答案是否完全匹配参考答案<br>F1 Score：评估预测答案与参考答案的词级重叠&nbsp;</div>
</div>
<div class="card">
<div class="field_0"><div>LoRA的添加低秩适应矩阵，具体内容是什么？</div></div>
<div class="separator"></div>
<div class="field_1"><span style="color: rgb(31, 35, 40); background-color: rgb(255, 255, 255);">为每个需要微调的权重矩阵W添加一个低秩分解：ΔW = A × B</span><ul><li>A是一个d×r的矩阵</li><li>B是一个r×k的矩阵</li><li>r是秩，通常远小于d和k</li></ul></div>
</div>
<div class="card">
<div class="field_0">秩(r)是QLoRA最重要的参数之一， 较高的r值 和 较低的r值 分别的影响是什么？常见设置值是什么？</div>
<div class="separator"></div>
<div class="field_1"><ul><li><div>较高的r值提供更强的表达能力，但可能导致过拟合</div></li><li><div>较低的r值可以减少过拟合，但会降低表达能力</div></li><li><div>常见设置值为8或16</div></li></ul></div>
</div>
<div class="card">
<div class="field_0">目前主流的LoRA微调数据集分别是收集垂直领域QA对 以及&nbsp;生成QCA三元组，分别的数量是什么？</div>
<div class="separator"></div>
<div class="field_1">内部文档生成QCA：约20000条 ，<br>人工编写核心QA：约1000条。</div>
</div>
<div class="card">
<div class="field_0">F1 Score是什么和什么的什么值？</div>
<div class="separator"></div>
<div class="field_1">F1 Score是精确率(Precision)和召回率(Recall)的调和平均值。</div>
</div>
<div class="card">
<div class="field_0"><div>团队里面的算法工程师主要负责哪些工作？</div></div>
<div class="separator"></div>
<div class="field_1">涉及多个复杂模型（LLaMA 2微调、SBERT嵌入、重排序模型等），以及RAG架构的设计与优化，3名算法工程师能够合理分工处理不同模型组件的开发与优化。</div>
</div>
<div class="card">
<div class="field_0">&nbsp;问答系统的专用指标是什么？</div>
<div class="separator"></div>
<div class="field_1"><ul><li><strong>Exact Match (EM)</strong>：答案是否完全匹配参考答案</li><li><strong>F1 Score</strong>：评估预测答案与参考答案的词级重叠</li><li><strong>Answer Correctness</strong>：评估答案的事实准确性</li></ul></div>
</div>
<div class="card">
<div class="field_0">使用 LoRA 或 QLoRA 等参数高效微调技术，可以显著降低什么需求？</div>
<div class="separator"></div>
<div class="field_1">显存需求。</div>
</div>
<div class="card">
<div class="field_0">秩(r)是QLoRA最重要的参数之一，&nbsp;<br>作为经验法则，当r=8时，当r=16时，alpha 分别设置多少？</div>
<div class="separator"></div>
<div class="field_1"><span style="color: oklch(0.304 0.04 213.681); background-color: oklch(0.99 0.004 106.471);">当r=8时，alpha可设为16；当r=16时，alpha可设为32</span></div>
</div>
<div class="card">
<div class="field_0">LoRA 数据格式 什么时候使用指令格式？以及包含哪些字段？&nbsp;</div>
<div class="separator"></div>
<div class="field_1">当任务侧重于指令跟随或摘要生成时，数据集常会采用包含明确“instruction”、“input”与“output”字段的格式，存储在一个json对象里面。</div>
</div>
<div class="card">
<div class="field_0">秩(r)是QLoRA最重要的参数之一，&nbsp;<br>作为经验法则，通常选择一个大小是多少的alpha？</div>
<div class="separator"></div>
<div class="field_1">秩两倍的alpha值。</div>
</div>
<div class="card">
<div class="field_0">bitsandbytes&nbsp;是一个什么库，作用是什么？降低什么，保持什么，适合什么环境？</div>
<div class="separator"></div>
<div class="field_1">专为深度学习优化设计的轻量级库，主要用于模型的低精度量化（如 8 位和 4 位）和高效计算。<br>它能够显著降低大型语言模型（LLM）的内存占用和计算成本，同时保持较高的性能，适合在资源受限的环境中运行。</div>
</div>
<div class="card">
<div class="field_0">实际应用EM中，通常会进行一些预处理，包含哪些步骤？</div>
<div class="separator"></div>
<div class="field_1">def normalized_exact_match(prediction, reference):<br>&nbsp;&nbsp;&nbsp; # 标准化处理<br>&nbsp;&nbsp;&nbsp; def normalize(text):<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # 转为小写<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; text = text.lower()<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # 移除标点符号<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; text = re.sub(r'[^\w\s]', '', text)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # 移除多余空格<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; text = re.sub(r'\s+', ' ', text).strip()<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return text<br>&nbsp;&nbsp;&nbsp; <br>&nbsp;&nbsp;&nbsp; return 1 if normalize(prediction) == normalize(reference) else 0</div>
</div>
<div class="card">
<div class="field_0">模型训练的平台是什么?</div>
<div class="separator"></div>
<div class="field_1">AWS SageMaker。</div>
</div>
<div class="card">
<div class="field_0">QLoRA通过将权重量化为什么样，并使用什么来处理内存峰值，可以进一步降低显存占用。</div>
<div class="separator"></div>
<div class="field_1">QLoRA通过将权重量化为<span style="color: rgb(255, 0, 127);"><b>4-bit精度</b></span>，并使用<b><span style="color: rgb(255, 0, 127);">分页优化器</span></b>来处理内存峰值，可以进一步降低显存占用。</div>
</div>

<script>
document.addEventListener('click', function(e) {
const container = e.target.closest('.video-container');
if (!container) return;

const placeholder = container.querySelector('.video-placeholder');
if (!placeholder) return;

const videoId = container.dataset.videoId;
const startParam = container.dataset.start || '';

const iframe = document.createElement('iframe');
iframe.width = '100%';
iframe.height = '100%';
iframe.src = `https://www.youtube.com/embed/${videoId}?${startParam.slice(1)}`;
iframe.title = 'YouTube video player';
iframe.frameBorder = '0';
iframe.style.position = 'absolute';
iframe.style.top = '0';
iframe.style.left = '0';
iframe.style.borderRadius = '15px';
iframe.allow = 'accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share';
iframe.allowFullscreen = true;

placeholder.innerHTML = '';
placeholder.appendChild(iframe);
});
</script>

</div>
<div class="footer">Made by <a href="https://xxhk.org">Export Notes - XXHK</a></div>
</body>
</html>

