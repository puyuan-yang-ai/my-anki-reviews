命令行参数解析和搜索参数范围设置的代码位于文件的开头部分。我来指出具体位置：

## 1. 命令行参数解析

命令行参数解析在 `get_args()` 函数中（第43-60行）：

```python
def get_args():
    parser = argparse.ArgumentParser()

    parser.add_argument('--batch_size', default=4, type=int)
    parser.add_argument('--pipe', default="SD1.5", type=str)
    parser.add_argument('--sched', default="DDIM", type=str)
    parser.add_argument('--steps', default=50, type=int)
    parser.add_argument('--num_samples', default=32, type=int)

    parser.add_argument('--req_time', default=None, type=float)
    parser.add_argument('--req_speedup', default=None, type=float)
    parser.add_argument('--req_score_loss', default=0.02, type=float)  # 2% relative precision loss

    parser.add_argument('--seed', default=42, type=int)
    # parser.add_argument('--search_targets', default='deepcache', type=str)
    return parser.parse_args()
```

这些参数定义了：
- 模型配置（`--pipe`, `--sched`, `--steps`）
- 评估设置（`--batch_size`, `--num_samples`, `--seed`）
- 优化目标（`--req_time`, `--req_speedup`, `--req_score_loss`）

## 2. 搜索参数范围设置

搜索参数范围在文件开头的全局变量 `PARAM_RANGE` 中定义（第12-37行）：

```python
PARAM_RANGE = {
    "deepcache":
        {
            "cache_interval": range(2, 6),
            "cache_branch_id": range(0, 4),
        },
    "tgate":
        {
            "gate_step": range(5, 20),
            "sp_interval": range(2, 10),
            "fi_interval": range(1, 6),
            "warmup": range(1, 4)
        },
    "tome": {
        "ratio": np.arange(0.1, 1.0, 0.1),
        "max_downsample": range(4, 0, -1),
    }
}
```

这个字典定义了三种优化方法的参数搜索范围：
- DeepCache参数: `cache_interval`和`cache_branch_id`
- TGate参数: `gate_step`, `sp_interval`, `fi_interval`和`warmup`
- ToMe参数: `ratio`和`max_downsample`

此外，文件中还有模型和调度器的映射字典（第39-51行）：

```python
model_map = {
    "SD1.5": "runwayml/stable-diffusion-v1-5",
    "SD2.1": "stabilityai/stable-diffusion-2-1",
    "SDXL": "stabilityai/stable-diffusion-xl-base-1.0"
}

scheduler_map = {
    "DDIM": "DDIMScheduler",
    "DPM-Solver++": "DPMSolverMultistepScheduler",
    "UniPCMultistepScheduler": "UniPCMultistepScheduler"
}
```

这些代码一起定义了整个搜索空间和实验配置。


## 数据处理流程

1. **参数初始化**：
   - 解析命令行参数（模型类型、调度器、步数等）
   - 设置搜索参数范围（DeepCache、ToMe、TGate等优化方法）

2. **基准测试**：
   - 加载原始稳定扩散模型
   - 加载CLIP模型用于评估图像质量
   - 从COCO数据集加载提示词
   - 执行原始模型推理，记录基准时间和CLIP分数

3. **参数搜索**：
   - 对不同优化组合进行遍历搜索（DeepCache、ToMe、TGate）
   - 对每组参数：
     - 应用优化设置
     - 执行推理并测量时间和质量分数
     - 计算加速比和质量损失
     - 如果满足要求（高加速率、低质量损失），记录参数

4. **结果保存**：
   - 将最佳参数保存到`search_params.json`文件
   - 根据不同条件保存不同配置

## 优化方法组合

脚本测试四种优化组合：
- 仅DeepCache
- DeepCache+ToMe
- DeepCache+TGate
- DeepCache+ToMe+TGate

每种组合有不同的参数需要优化，如cache_interval、ratio、gate_step等。

## 搜索目标

两种搜索模式：
1. **满足指定加速要求**：找到满足特定加速率且质量损失可接受的参数
2. **寻找上限**：寻找在质量损失阈值内能达到的最大加速率

最终，脚本输出最佳参数组合及其性能指标，并保存到JSON文件中供后续使用。


