

**发现**：  
- 提示工程是通过设计自然语言指令（提示）从LLMs中提取知识的关键技术。   

**说明**：  
提示工程的核心思想是通过精心设计的输入（提示）引导模型生成更准确的输出。例如，在问答任务中，通过添加“请逐步推理”这样的提示，模型可能会生成更详细的解答过程。

---

#### **2. 提示工程的分类**
**发现**：  
论文将提示方法分为以下几类（部分代表性方法）：  
1. **基础提示**（Basic Prompting）：直接输入问题，无额外设计。  
2. **思维链提示**（Chain-of-Thought, CoT）：要求模型分步推理。  
3. **自洽性提示**（Self-Consistency）：生成多条推理路径并选择最一致的答案。  
4. **程序化提示**（Program-of-Thoughts, PoT）：生成代码而非自然语言推理。  
5. **知识增强提示**（如Chain-of-Knowledge, CoK）：结合外部知识纠正错误。  
6. **树状思维提示**（Tree-of-Thoughts, ToT）：通过树状搜索探索多种推理路径。

**说明**：  
- **CoT**适用于需要逻辑推理的任务（如数学题），而**PoT**更适合需要数值计算的任务（如生成Python代码解决数学问题）。  
- **ToT**通过模拟人类多路径思考，在复杂任务（如逻辑谜题）中表现更好。

---

#### **3. 提示工程在不同NLP任务中的应用**
**发现**：  
论文总结了29种NLP任务及其对应的最佳提示方法，例如：  
1. **数学问题求解**（Mathematical Problem Solving）：PoT和CoT表现最佳。  
   - *示例*：在GSM8K数据集上，PoT的准确率比基础提示高13.8%。  
2. **常识推理**（Commonsense Reasoning）：Maieutic Prompting（通过递归消除矛盾假设）效果显著。  
3. **多跳推理**（Multi-Hop Reasoning）：Decomposed Prompting（将问题分解为子问题）优于传统CoT。  
4. **表格问答**（Table-Based QA）：Chain-of-Table（动态操作表格）达到SOTA性能。  

**说明**：  
- 不同任务需要不同的提示策略。例如，表格任务需要模型理解结构化数据，而PoT或Chain-of-Table能更好地处理这类任务。  
- 在需要事实核查的任务（如Truthfulness）中，Chain-of-Verification（CoVe）通过多轮验证减少幻觉（hallucination）。

---

#### **4. 关键结论**
**发现**：  
1. **少样本提示（Few-shot）优于零样本（Zero-shot）**：提供少量示例能显著提升性能，但需注意示例的偏差问题。  
2. **复杂任务需分步提示**：如Least-to-Most（先分解问题再逐步解决）在复杂推理中表现优异。  
3. **符号与代码的结合提升性能**：如Chain-of-Code（CoC）在需要数值计算的任务中比纯自然语言提示更准确。  

**说明**：  
- 少样本提示的示例需具有代表性，否则可能误导模型。例如，在数学问题中，选择覆盖多种题型的示例比单一题型更好。  
- 分步提示（如CoT）的核心是模拟人类解题过程，而PoT和CoC则进一步将计算任务卸载到外部工具（如Python解释器），减少模型的计算错误。

---

#### **5. 未来方向**
**发现**：  
1. **自动化提示设计**：如Auto-CoT自动生成示例，减少人工成本。  
2. **多模态提示**：结合文本、图像或表格的混合提示方法。  
3. **鲁棒性提升**：减少提示对微小变化的敏感性（如措辞调整导致不同结果）。  

**说明**：  
当前的提示工程仍依赖人工设计，未来可能通过强化学习或优化算法自动生成高效提示。此外，多模态提示（如“根据图表回答问题”）是扩展LLMs应用场景的重要方向。

---

### **总结**
这篇论文的核心贡献在于：  
1. **系统性分类**：将39种提示方法与29种NLP任务映射，提供清晰的分类框架。  
2. **性能对比**：指出不同任务的最佳提示策略（如数学任务用PoT，表格任务用Chain-of-Table）。  
3. **实用建议**：强调分步推理、外部工具（代码/符号）和少样本示例的重要性。  

如果需要进一步探讨某类提示方法或具体任务的应用，可以随时告诉我！
