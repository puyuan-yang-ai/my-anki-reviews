# ä½ æ˜¯è°çš„è¯¢é—®
_Exported on 11/30/2025 at 10:38:29 GMT+8 from Cursor (2.1.39)_

---

**User**

ä½ æ˜¯è°

---

**Cursor**

æˆ‘æ˜¯ **Composer**ï¼Œç”± Cursor è®­ç»ƒçš„è¯­è¨€æ¨¡å‹ï¼Œç”¨äºåœ¨ Cursor IDE ä¸­ååŠ©ç¼–ç¨‹ã€‚

æˆ‘å¯ä»¥ï¼š
- é˜…è¯»å’Œåˆ†æä»£ç 
- å›ç­”ç¼–ç¨‹é—®é¢˜
- æä¾›ä»£ç å»ºè®®å’Œè§£é‡Š
- æœç´¢ä»£ç åº“
- ååŠ©è°ƒè¯•å’Œä¼˜åŒ–

ä½ å½“å‰åœ¨ **ask æ¨¡å¼**ï¼ˆåªè¯»ï¼‰ï¼Œæˆ‘å¯ä»¥æŸ¥çœ‹å’Œåˆ†æä»£ç ï¼Œä½†æ— æ³•ç›´æ¥ç¼–è¾‘æ–‡ä»¶ã€‚å¦‚éœ€ä¿®æ”¹ä»£ç ï¼Œè¯·åˆ‡æ¢åˆ° **agent æ¨¡å¼**ã€‚

éœ€è¦æˆ‘å¸®ä½ åšä»€ä¹ˆï¼Ÿ

---

**User**

@specs æˆ‘è¿™ä¸ªæ–‡ä»¶å¤¹ä¸‹é¢å­˜æ”¾çš„æ˜¯specï¼Œä½†æ˜¯æˆ‘æ˜¯ä¸æ˜¯è¿˜è¦ç»™ä»–å»ºå­ç›®å½•ï¼ŸæŒ‰ç…§åŠŸèƒ½æ¥å»ºå­ç›®å½•ï¼Œè€Œä¸æ˜¯ç›´æ¥æŠŠæ‰€æœ‰çš„mdæ–‡æ¡£éƒ½æ”¾åˆ°è¿™ä¸ªspecæ–‡ä»¶å¤¹é‡Œé¢ï¼Ÿ

---

**Cursor**

è®©æˆ‘å…ˆçœ‹çœ‹è¿™äº›æ–‡ä»¶çš„å†…å®¹ï¼Œäº†è§£ä¸€ä¸‹å®ƒä»¬çš„åŠŸèƒ½åˆ†ç±»ã€‚

åŸºäºæ‚¨æä¾›çš„æ–‡ä»¶å†…å®¹ï¼Œæˆ‘æ¥åˆ†æä¸€ä¸‹æ‚¨çš„ `specs` æ–‡ä»¶å¤¹çš„ç»„ç»‡æƒ…å†µï¼š

## å½“å‰é—®é¢˜åˆ†æ

æ‚¨è¯´å¾—å¾ˆå¯¹ï¼ç›®å‰è¿™ä¸ª `specs` æ–‡ä»¶å¤¹ç¡®å®éœ€è¦æŒ‰åŠŸèƒ½å»ºç«‹å­ç›®å½•ã€‚ä»æ–‡ä»¶å†…å®¹æ¥çœ‹ï¼Œè¿™äº›æ–‡æ¡£æ··åˆäº†ä»¥ä¸‹å‡ ç§ç±»å‹ï¼š

### ğŸ“Š å½“å‰æ–‡ä»¶åˆ†ç±»ï¼š

1. **åŠŸèƒ½è§„æ ¼æ–‡æ¡£**ï¼ˆSpecï¼‰
   - `interview-question-spec.md` - é¢è¯•é—®é¢˜ç”Ÿæˆè§„æ ¼
   - `evaluation-report-sepc.md` - è¯„ä¼°æŠ¥å‘Šè§„æ ¼
   - `evaluation-report-minimal-spec.md` - æœ€å°åŒ–è¯„ä¼°æŠ¥å‘Šè§„æ ¼
   - `evaluation-report-ultra-simple-spec.md` - è¶…ç®€åŒ–è¯„ä¼°æŠ¥å‘Šè§„æ ¼
   - `evaluation-report-ultra-simple-tasks.md` - è¶…ç®€åŒ–è¯„ä¼°ä»»åŠ¡
   - `virtual-interview-spec.md` - è™šæ‹Ÿé¢è¯•ç³»ç»Ÿå®Œæ•´è§„æ ¼

2. **ä¿®æ”¹æ€»ç»“æ–‡æ¡£**ï¼ˆModification Summaryï¼‰
   - `MODIFICATION_SUMMARY_identity_protection.md` - èº«ä»½ä¿æŠ¤æµ‹è¯•ä¿®æ”¹æ€»ç»“
   - `interview-followup-modification-summary.md` - æ™ºèƒ½è¿½é—®æœºåˆ¶ä¿®æ”¹æ€»ç»“
   - `CHANGES_SUMMARY.md` - ä¿®æ”¹æ€»è§ˆ
   - `modification-checklist.md` - ä¿®æ”¹æ£€æŸ¥æ¸…å•

3. **æµ‹è¯•ç›¸å…³æ–‡æ¡£**ï¼ˆTest Documentationï¼‰
   - `identity-protection-test-summary.md` - èº«ä»½ä¿æŠ¤æµ‹è¯•å®ç°æ€»ç»“

## ğŸ¯ å»ºè®®çš„ç›®å½•ç»“æ„ï¼š

```
specs/
â”œâ”€â”€ features/                      # åŠŸèƒ½è§„æ ¼è¯´æ˜
â”‚   â”œâ”€â”€ interview/                # é¢è¯•ç›¸å…³
â”‚   â”‚   â”œâ”€â”€ interview-question-spec.md
â”‚   â”‚   â””â”€â”€ virtual-interview-spec.md
â”‚   â””â”€â”€ evaluation/               # è¯„ä¼°æŠ¥å‘Šç›¸å…³
â”‚       â”œâ”€â”€ evaluation-report-spec.md
â”‚       â”œâ”€â”€ evaluation-report-minimal-spec.md
â”‚       â”œâ”€â”€ evaluation-report-ultra-simple-spec.md
â”‚       â””â”€â”€ evaluation-report-ultra-simple-tasks.md
â”‚
â”œâ”€â”€ modifications/                 # åŠŸèƒ½ä¿®æ”¹å’Œå®ç°è®°å½•
â”‚   â”œâ”€â”€ identity-protection/      # èº«ä»½ä¿æŠ¤åŠŸèƒ½
â”‚   â”‚   â”œâ”€â”€ MODIFICATION_SUMMARY_identity_protection.md
â”‚   â”‚   â””â”€â”€ identity-protection-test-summary.md
â”‚   â””â”€â”€ interview-followup/       # æ™ºèƒ½è¿½é—®åŠŸèƒ½
â”‚       â”œâ”€â”€ interview-followup-modification-summary.md
â”‚       â”œâ”€â”€ CHANGES_SUMMARY.md
â”‚       â””â”€â”€ modification-checklist.md
â”‚
â””â”€â”€ README.md                      # æ•´ä¸ªspecsæ–‡ä»¶å¤¹çš„ç´¢å¼•å’Œè¯´æ˜
```

## ğŸ“‹ æ›´ç®€åŒ–çš„æ–¹æ¡ˆï¼ˆå¦‚æœæ–‡æ¡£ä¸å¤šï¼‰ï¼š

```
specs/
â”œâ”€â”€ features/                      # åŠŸèƒ½è§„æ ¼
â”‚   â”œâ”€â”€ virtual-interview-spec.md
â”‚   â”œâ”€â”€ interview-question-spec.md
â”‚   â””â”€â”€ evaluation-report-specs/  # è¯„ä¼°æŠ¥å‘Šçš„å¤šä¸ªç‰ˆæœ¬æ”¾ä¸€èµ·
â”‚       â”œâ”€â”€ evaluation-report-spec.md
â”‚       â”œâ”€â”€ minimal-spec.md
â”‚       â””â”€â”€ ultra-simple-spec.md
â”‚
â”œâ”€â”€ implementations/               # å®ç°å’Œä¿®æ”¹è®°å½•
â”‚   â”œâ”€â”€ identity-protection/
â”‚   â”‚   â”œâ”€â”€ modification-summary.md
â”‚   â”‚   â””â”€â”€ test-summary.md
â”‚   â””â”€â”€ interview-followup/
â”‚       â”œâ”€â”€ modification-summary.md
â”‚       â””â”€â”€ changes-summary.md
â”‚
â””â”€â”€ README.md
```

## ğŸ’¡ æˆ‘çš„å»ºè®®ï¼š

**é‡‡ç”¨ç¬¬äºŒä¸ªç®€åŒ–æ–¹æ¡ˆ**ï¼ŒåŸå› æ˜¯ï¼š

1. **æ¸…æ™°çš„èŒè´£åˆ†ç¦»**ï¼š
   - `features/` - åŠŸèƒ½è§„æ ¼ï¼ˆWhat - è¦åšä»€ä¹ˆï¼‰
   - `implementations/` - å®ç°è®°å½•ï¼ˆHow - æ€ä¹ˆåšçš„ï¼‰

2. **ä¾¿äºç»´æŠ¤**ï¼š
   - æ–°åŠŸèƒ½è§„æ ¼æ”¾ `features/`
   - å®ç°å®Œæˆåçš„æ€»ç»“æ”¾ `implementations/`
   - æŒ‰åŠŸèƒ½æ¨¡å—å»ºå­ç›®å½•

3. **ä¾¿äºæŸ¥æ‰¾**ï¼š
   - æƒ³äº†è§£åŠŸèƒ½å®šä¹‰ â†’ çœ‹ `features/`
   - æƒ³äº†è§£å®ç°ç»†èŠ‚ â†’ çœ‹ `implementations/`

4. **éµå¾ª KISS åŸåˆ™**ï¼š
   - ä¸¤å±‚ç›®å½•ç»“æ„ï¼Œä¸è¿‡åº¦å¤æ‚
   - æŒ‰éœ€æ‰©å±•ï¼Œç°åœ¨æ–‡æ¡£è¿˜ä¸ç®—å¤ªå¤š

æ‚¨è§‰å¾—è¿™ä¸ªæ–¹æ¡ˆå¦‚ä½•ï¼Ÿéœ€è¦æˆ‘å¸®æ‚¨ç”Ÿæˆä¸€ä¸ª `README.md` æ¥è¯´æ˜è¿™ä¸ªç›®å½•ç»“æ„å—ï¼Ÿ

```plaintext
specs/
â”œâ”€â”€ features/                      # åŠŸèƒ½è§„æ ¼è¯´æ˜
â”‚   â”œâ”€â”€ interview/                # é¢è¯•ç›¸å…³
â”‚   â”‚   â”œâ”€â”€ interview-question-spec.md
â”‚   â”‚   â””â”€â”€ virtual-interview-spec.md
â”‚   â””â”€â”€ evaluation/               # è¯„ä¼°æŠ¥å‘Šç›¸å…³
â”‚       â”œâ”€â”€ evaluation-report-spec.md
â”‚       â”œâ”€â”€ evaluation-report-minimal-spec.md
â”‚       â”œâ”€â”€ evaluation-report-ultra-simple-spec.md
â”‚       â””â”€â”€ evaluation-report-ultra-simple-tasks.md
â”‚
â”œâ”€â”€ modifications/                 # åŠŸèƒ½ä¿®æ”¹å’Œå®ç°è®°å½•
â”‚   â”œâ”€â”€ identity-protection/      # èº«ä»½ä¿æŠ¤åŠŸèƒ½
â”‚   â”‚   â”œâ”€â”€ MODIFICATION_SUMMARY_identity_protection.md
â”‚   â”‚   â””â”€â”€ identity-protection-test-summary.md
â”‚   â””â”€â”€ interview-followup/       # æ™ºèƒ½è¿½é—®åŠŸèƒ½
â”‚       â”œâ”€â”€ interview-followup-modification-summary.md
â”‚       â”œâ”€â”€ CHANGES_SUMMARY.md
â”‚       â””â”€â”€ modification-checklist.md
â”‚
â””â”€â”€ README.md                      # æ•´ä¸ªspecsæ–‡ä»¶å¤¹çš„ç´¢å¼•å’Œè¯´æ˜
```

```plaintext
specs/
â”œâ”€â”€ features/                      # åŠŸèƒ½è§„æ ¼
â”‚   â”œâ”€â”€ virtual-interview-spec.md
â”‚   â”œâ”€â”€ interview-question-spec.md
â”‚   â””â”€â”€ evaluation-report-specs/  # è¯„ä¼°æŠ¥å‘Šçš„å¤šä¸ªç‰ˆæœ¬æ”¾ä¸€èµ·
â”‚       â”œâ”€â”€ evaluation-report-spec.md
â”‚       â”œâ”€â”€ minimal-spec.md
â”‚       â””â”€â”€ ultra-simple-spec.md
â”‚
â”œâ”€â”€ implementations/               # å®ç°å’Œä¿®æ”¹è®°å½•
â”‚   â”œâ”€â”€ identity-protection/
â”‚   â”‚   â”œâ”€â”€ modification-summary.md
â”‚   â”‚   â””â”€â”€ test-summary.md
â”‚   â””â”€â”€ interview-followup/
â”‚       â”œâ”€â”€ modification-summary.md
â”‚       â””â”€â”€ changes-summary.md
â”‚
â””â”€â”€ README.md
```

---

**User**

specsä¸‹é¢åŠ å…¥featuresä»¥åŠimplementations è¿™ä¸¤ä¸ªå­æ–‡ä»¶å¤¹ä½ è§‰å¾—æ˜¯ä¸»æµåšæ³•å—ï¼Ÿæˆ‘è®¤ä¸ºä¸»æµåšæ³•æ²¡è¿™ä¹ˆå¤æ‚å§ï¼Ÿä½ ä¸è¦æŒ‰ç…§æˆ‘çš„æ–‡æ¡£ç±»å‹æ¥è¿›è¡Œåˆ†ç±»å¥½å—ï¼Ÿæˆ‘çš„ä¸ä¸€å®šå¯¹å‘€

---

**Cursor**

ä½ è¯´å¾—å¯¹ï¼æˆ‘è¿‡åº¦è®¾è®¡äº†ã€‚è®©æˆ‘é‡æ–°æ€è€ƒä¸€ä¸‹ä¸šç•Œçš„ä¸»æµåšæ³•ã€‚

ä½ è¯´å¾—å¯¹ï¼æˆ‘ç¡®å®è¿‡åº¦è®¾è®¡äº†ã€‚è®©æˆ‘çœ‹çœ‹ä¸šç•Œçš„ä¸»æµåšæ³•ï¼š

## ğŸŒ ä¸šç•Œä¸»æµçš„ docs/specs ç»„ç»‡æ–¹å¼

å¤§å¤šæ•°é¡¹ç›®çš„åšæ³•å…¶å®**å¾ˆç®€å•**ï¼š

### 1ï¸âƒ£ **æœ€å¸¸è§ï¼šæŒ‰åŠŸèƒ½æ¨¡å—ç›´æ¥åˆ†æ–‡ä»¶å¤¹**
```
docs/
â”œâ”€â”€ interview/           # é¢è¯•ç›¸å…³çš„æ‰€æœ‰æ–‡æ¡£
â”œâ”€â”€ evaluation/          # è¯„ä¼°ç›¸å…³çš„æ‰€æœ‰æ–‡æ¡£
â”œâ”€â”€ api/                 # APIæ–‡æ¡£
â””â”€â”€ deployment/          # éƒ¨ç½²æ–‡æ¡£
```

### 2ï¸âƒ£ **ä¸­å°å‹é¡¹ç›®ï¼šç”šè‡³ä¸åˆ†å­ç›®å½•**
```
docs/
â”œâ”€â”€ interview-spec.md
â”œâ”€â”€ evaluation-spec.md
â”œâ”€â”€ api-guide.md
â””â”€â”€ README.md
```

## ğŸ’¡ é’ˆå¯¹æ‚¨çš„é¡¹ç›®ï¼Œæˆ‘çš„æ–°å»ºè®®

çœ‹æ‚¨çš„æ–‡ä»¶ï¼Œä¸»è¦å°±æ˜¯ä¸¤å¤§åŠŸèƒ½ï¼š**é¢è¯•ï¼ˆinterviewï¼‰** å’Œ **è¯„ä¼°æŠ¥å‘Šï¼ˆevaluationï¼‰**

**æœ€ç®€å•ç›´æ¥çš„åšæ³•ï¼š**

```
specs/
â”œâ”€â”€ interview/                    # é¢è¯•åŠŸèƒ½ç›¸å…³
â”‚   â”œâ”€â”€ virtual-interview-spec.md
â”‚   â”œâ”€â”€ question-generation-spec.md
â”‚   â”œâ”€â”€ followup-mechanism.md
â”‚   â””â”€â”€ identity-protection.md
â”‚
â”œâ”€â”€ evaluation/                   # è¯„ä¼°æŠ¥å‘Šç›¸å…³
â”‚   â”œâ”€â”€ evaluation-report-spec.md
â”‚   â”œâ”€â”€ minimal-spec.md
â”‚   â”œâ”€â”€ ultra-simple-spec.md
â”‚   â””â”€â”€ ultra-simple-tasks.md
â”‚
â””â”€â”€ README.md                     # ç´¢å¼•
```

**åŸåˆ™ï¼š**
- âœ… æŒ‰**ä¸šåŠ¡åŠŸèƒ½**åˆ†ï¼ˆinterview / evaluationï¼‰
- âœ… ä¸ç®¡æ˜¯è§„æ ¼ã€ä¿®æ”¹è®°å½•ã€æµ‹è¯•æ–‡æ¡£ï¼Œåªè¦æ˜¯å…³äºé¢è¯•çš„ï¼Œéƒ½æ”¾ `interview/`
- âœ… ç®€å•ã€ç›´è§‚ã€æ˜“æ‰¾

è¿™æ ·æ˜¯ä¸æ˜¯æ›´ç¬¦åˆä¸»æµåšæ³•ï¼Ÿ**æŒ‰ä¸šåŠ¡åŠŸèƒ½åˆ†ç±»**ï¼Œè€Œä¸æ˜¯æŒ‰æ–‡æ¡£æ€§è´¨ï¼ˆspec vs implementationï¼‰åˆ†ç±»ã€‚

```plaintext
docs/
â”œâ”€â”€ interview/           # é¢è¯•ç›¸å…³çš„æ‰€æœ‰æ–‡æ¡£
â”œâ”€â”€ evaluation/          # è¯„ä¼°ç›¸å…³çš„æ‰€æœ‰æ–‡æ¡£
â”œâ”€â”€ api/                 # APIæ–‡æ¡£
â””â”€â”€ deployment/          # éƒ¨ç½²æ–‡æ¡£
```

```plaintext
docs/
â”œâ”€â”€ interview-spec.md
â”œâ”€â”€ evaluation-spec.md
â”œâ”€â”€ api-guide.md
â””â”€â”€ README.md
```

```plaintext
specs/
â”œâ”€â”€ interview/                    # é¢è¯•åŠŸèƒ½ç›¸å…³
â”‚   â”œâ”€â”€ virtual-interview-spec.md
â”‚   â”œâ”€â”€ question-generation-spec.md
â”‚   â”œâ”€â”€ followup-mechanism.md
â”‚   â””â”€â”€ identity-protection.md
â”‚
â”œâ”€â”€ evaluation/                   # è¯„ä¼°æŠ¥å‘Šç›¸å…³
â”‚   â”œâ”€â”€ evaluation-report-spec.md
â”‚   â”œâ”€â”€ minimal-spec.md
â”‚   â”œâ”€â”€ ultra-simple-spec.md
â”‚   â””â”€â”€ ultra-simple-tasks.md
â”‚
â””â”€â”€ README.md                     # ç´¢å¼•
```

---

**User**

æˆ‘å‘ç°Pythoné¡¹ç›®é‡Œé¢æœ‰çš„æ—¶å€™å‘½åæ˜¯å°å†™å­—æ¯åŠ _åˆ†å‰²ï¼Œæœ‰çš„æ—¶å€™æ˜¯å°å†™å­—æ¯åŠ ä¸­åˆ’çº¿åˆ†éš”å°±æˆ‘ä¸å¤ªæ˜ç™½å‘€ï¼Œå°±æ˜¯åƒä»£ç çš„è¯æ˜¯_åˆ†å‰²ï¼Œè€Œåƒæ–‡æ¡£ä¹‹ç±»æˆ–è€…æ˜¯å­˜æ”¾æ–‡æ¡£çš„æ–‡ä»¶å¤¹éƒ½æ˜¯ä¸­å‘ç°åˆ†å‰²å—ï¼Ÿæˆ‘è¿™æ¬¡æœ‰ç‚¹è¿·ç³Šå‘€ã€‚

---

**Cursor**

å¥½é—®é¢˜ï¼è¿™ç¡®å®å®¹æ˜“æ··æ·†ã€‚è®©æˆ‘ç»™ä½ æ¢³ç†ä¸€ä¸‹ Python é¡¹ç›®ä¸­çš„å‘½åè§„èŒƒï¼š

## ğŸ“ Python é¡¹ç›®å‘½åè§„èŒƒï¼ˆä¸šç•Œæ ‡å‡†ï¼‰

### 1ï¸âƒ£ **Python ä»£ç æ–‡ä»¶å’Œæ¨¡å—**
```python
# âœ… ä½¿ç”¨ä¸‹åˆ’çº¿ (snake_case)
user_service.py
virtual_interview.py
test_interview_flow.py
my_utils.py
```
**åŸå› **ï¼šPython å®˜æ–¹é£æ ¼æŒ‡å— PEP 8 è§„å®šï¼Œæ¨¡å—ååº”è¯¥ç”¨å°å†™å­—æ¯+ä¸‹åˆ’çº¿

### 2ï¸âƒ£ **æ–‡æ¡£æ–‡ä»¶ï¼ˆMarkdown ç­‰ï¼‰**
```markdown
# âœ… ä½¿ç”¨ä¸­åˆ’çº¿ (kebab-case) - æ›´å¸¸è§
interview-spec.md
user-guide.md
api-reference.md

# âš ï¸ ä¹Ÿå¯ä»¥ç”¨ä¸‹åˆ’çº¿ï¼Œä½†ä¸å¤ªä¸»æµ
interview_spec.md
```
**åŸå› **ï¼š
- ä¸­åˆ’çº¿åœ¨ URL ä¸­æ›´å‹å¥½ï¼ˆå¦‚ GitHubã€æ–‡æ¡£ç½‘ç«™ï¼‰
- è§†è§‰ä¸Šæ›´æ¸…æ™°ï¼ˆé¿å…ä¸‹åˆ’çº¿è¢«æŸäº›ç¼–è¾‘å™¨ä¸‹åˆ’çº¿éšè—ï¼‰
- ä¸šç•Œæ–‡æ¡£çš„ä¸»æµåšæ³•

### 3ï¸âƒ£ **æ–‡ä»¶å¤¹/ç›®å½•å**
```bash
# Python åŒ…ç›®å½• - ç”¨ä¸‹åˆ’çº¿
project_code/
user_service/
test_cases/

# æ–‡æ¡£ç›®å½• - ä¸¤ç§éƒ½å¸¸è§ï¼Œä½†ä¸­åˆ’çº¿æ›´æµè¡Œ
docs/
api-reference/     # âœ… æ¨è
user-guide/        # âœ… æ¨è

# æˆ–è€…
api_reference/     # âœ… ä¹Ÿå¯ä»¥ï¼Œä½†ä¸å¦‚ä¸­åˆ’çº¿æµè¡Œ
```

## ğŸ¯ **æ€»ç»“è§„åˆ™**

| ç±»å‹ | å‘½åé£æ ¼ | ç¤ºä¾‹ |
|------|---------|------|
| **Python ä»£ç ** | `snake_case` (ä¸‹åˆ’çº¿) | `user_service.py` |
| **Python åŒ…/æ¨¡å—ç›®å½•** | `snake_case` (ä¸‹åˆ’çº¿) | `project_code/` |
| **Markdown æ–‡æ¡£** | `kebab-case` (ä¸­åˆ’çº¿) | `user-guide.md` |
| **æ–‡æ¡£ç›®å½•** | `kebab-case` (ä¸­åˆ’çº¿) âœ… æ¨è | `api-reference/` |
| **æ–‡æ¡£ç›®å½•** | `snake_case` (ä¸‹åˆ’çº¿) âš ï¸ ä¹Ÿè¡Œ | `api_reference/` |

## ğŸ’¡ **ä¸ºä»€ä¹ˆä¼šæ··ç”¨ï¼Ÿ**

```
é¡¹ç›®ç»“æ„ç¤ºä¾‹ï¼š
cv-project/                    # ä¸­åˆ’çº¿ï¼ˆé¡¹ç›®åï¼‰
â”œâ”€â”€ project_code/              # ä¸‹åˆ’çº¿ï¼ˆPython ä»£ç ç›®å½•ï¼‰
â”‚   â”œâ”€â”€ user_service.py        # ä¸‹åˆ’çº¿ï¼ˆPython æ–‡ä»¶ï¼‰
â”‚   â””â”€â”€ virtual_interview.py   # ä¸‹åˆ’çº¿ï¼ˆPython æ–‡ä»¶ï¼‰
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ specs/
    â”‚   â”œâ”€â”€ interview/         # ä¸­åˆ’çº¿æˆ–ä¸ç”¨éƒ½è¡Œï¼ˆçº¯æ–‡æ¡£ç›®å½•ï¼‰
    â”‚   â”‚   â”œâ”€â”€ virtual-interview-spec.md    # ä¸­åˆ’çº¿ï¼ˆæ–‡æ¡£æ–‡ä»¶ï¼‰âœ…
    â”‚   â”‚   â””â”€â”€ identity-protection-test.md  # ä¸­åˆ’çº¿ï¼ˆæ–‡æ¡£æ–‡ä»¶ï¼‰âœ…
```

## ğŸ¯ **ä½ çš„é¡¹ç›®å»ºè®®**

åŸºäºä½ ç°åœ¨çš„ç»“æ„ï¼š

```
specs/
â”œâ”€â”€ interview/                              # æ–‡æ¡£ç›®å½•ï¼Œå¯ä»¥ä¸ç”¨åˆ†éš”ç¬¦
â”‚   â”œâ”€â”€ virtual-interview-spec.md          # âœ… æ–‡æ¡£ç”¨ä¸­åˆ’çº¿
â”‚   â”œâ”€â”€ question-generation-spec.md        # âœ… æ–‡æ¡£ç”¨ä¸­åˆ’çº¿
â”‚   â”œâ”€â”€ identity-protection-test.md        # âœ… æ–‡æ¡£ç”¨ä¸­åˆ’çº¿
â”‚   â””â”€â”€ followup-modification-summary.md   # âœ… æ–‡æ¡£ç”¨ä¸­åˆ’çº¿
â”‚
â””â”€â”€ evaluation/
    â”œâ”€â”€ evaluation-report-spec.md          # âœ… æ–‡æ¡£ç”¨ä¸­åˆ’çº¿
    â”œâ”€â”€ minimal-spec.md                    # âœ… æ–‡æ¡£ç”¨ä¸­åˆ’çº¿
    â””â”€â”€ ultra-simple-spec.md               # âœ… æ–‡æ¡£ç”¨ä¸­åˆ’çº¿
```

## ğŸ“Œ **è®°å¿†å£è¯€**

- **ä»£ç ç”¨ä¸‹åˆ’çº¿** `_`ï¼ˆPython è§„å®šï¼‰
- **æ–‡æ¡£ç”¨ä¸­åˆ’çº¿** `-`ï¼ˆä¸šç•Œä¹ æƒ¯ï¼‰
- **æ··ç”¨æ²¡æ¯›ç—…**ï¼ˆåªè¦åŒç±»å‹ä¿æŒä¸€è‡´å³å¯ï¼‰

ä½ ç°åœ¨æ˜ç™½äº†å—ï¼Ÿç®€å•è¯´å°±æ˜¯ï¼š**Python ä»£ç  = ä¸‹åˆ’çº¿ï¼Œæ–‡æ¡£ = ä¸­åˆ’çº¿**ã€‚

```python
# âœ… ä½¿ç”¨ä¸‹åˆ’çº¿ (snake_case)
user_service.py
virtual_interview.py
test_interview_flow.py
my_utils.py
```

```markdown
# âœ… ä½¿ç”¨ä¸­åˆ’çº¿ (kebab-case) - æ›´å¸¸è§
interview-spec.md
user-guide.md
api-reference.md

# âš ï¸ ä¹Ÿå¯ä»¥ç”¨ä¸‹åˆ’çº¿ï¼Œä½†ä¸å¤ªä¸»æµ
interview_spec.md
```

```shellscript
# Python åŒ…ç›®å½• - ç”¨ä¸‹åˆ’çº¿
project_code/
user_service/
test_cases/

# æ–‡æ¡£ç›®å½• - ä¸¤ç§éƒ½å¸¸è§ï¼Œä½†ä¸­åˆ’çº¿æ›´æµè¡Œ
docs/
api-reference/     # âœ… æ¨è
user-guide/        # âœ… æ¨è

# æˆ–è€…
api_reference/     # âœ… ä¹Ÿå¯ä»¥ï¼Œä½†ä¸å¦‚ä¸­åˆ’çº¿æµè¡Œ
```

```plaintext
é¡¹ç›®ç»“æ„ç¤ºä¾‹ï¼š
cv-project/                    # ä¸­åˆ’çº¿ï¼ˆé¡¹ç›®åï¼‰
â”œâ”€â”€ project_code/              # ä¸‹åˆ’çº¿ï¼ˆPython ä»£ç ç›®å½•ï¼‰
â”‚   â”œâ”€â”€ user_service.py        # ä¸‹åˆ’çº¿ï¼ˆPython æ–‡ä»¶ï¼‰
â”‚   â””â”€â”€ virtual_interview.py   # ä¸‹åˆ’çº¿ï¼ˆPython æ–‡ä»¶ï¼‰
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ specs/
    â”‚   â”œâ”€â”€ interview/         # ä¸­åˆ’çº¿æˆ–ä¸ç”¨éƒ½è¡Œï¼ˆçº¯æ–‡æ¡£ç›®å½•ï¼‰
    â”‚   â”‚   â”œâ”€â”€ virtual-interview-spec.md    # ä¸­åˆ’çº¿ï¼ˆæ–‡æ¡£æ–‡ä»¶ï¼‰âœ…
    â”‚   â”‚   â””â”€â”€ identity-protection-test.md  # ä¸­åˆ’çº¿ï¼ˆæ–‡æ¡£æ–‡ä»¶ï¼‰âœ…
```

```plaintext
specs/
â”œâ”€â”€ interview/                              # æ–‡æ¡£ç›®å½•ï¼Œå¯ä»¥ä¸ç”¨åˆ†éš”ç¬¦
â”‚   â”œâ”€â”€ virtual-interview-spec.md          # âœ… æ–‡æ¡£ç”¨ä¸­åˆ’çº¿
â”‚   â”œâ”€â”€ question-generation-spec.md        # âœ… æ–‡æ¡£ç”¨ä¸­åˆ’çº¿
â”‚   â”œâ”€â”€ identity-protection-test.md        # âœ… æ–‡æ¡£ç”¨ä¸­åˆ’çº¿
â”‚   â””â”€â”€ followup-modification-summary.md   # âœ… æ–‡æ¡£ç”¨ä¸­åˆ’çº¿
â”‚
â””â”€â”€ evaluation/
    â”œâ”€â”€ evaluation-report-spec.md          # âœ… æ–‡æ¡£ç”¨ä¸­åˆ’çº¿
    â”œâ”€â”€ minimal-spec.md                    # âœ… æ–‡æ¡£ç”¨ä¸­åˆ’çº¿
    â””â”€â”€ ultra-simple-spec.md               # âœ… æ–‡æ¡£ç”¨ä¸­åˆ’çº¿
```

---

**User**

@evaluation-report-sepc.md è¿™ä¸ªæ–‡æ¡£æ˜¯æˆ‘çš„æ–°çš„éœ€æ±‚ã€‚@evaluation-report-ultra-simple-spec.md è¿™ä¸ªæ–‡æ¡£å‘¢ï¼Œæ˜¯æˆ‘ç°æœ‰çš„ä»£ç çš„å†…å®¹ï¼Œå¯¹æ­¤ä½ èƒ½ä¸èƒ½å¸®æˆ‘çœ‹ä¸€ä¸‹è¿™ä¸ªæ–°éœ€æ±‚ç›¸å¯¹äºåŸæœ‰çš„ä»£ç çš„éœ€æ±‚æœ‰ä»€ä¹ˆå˜åŒ–å—ï¼Ÿå¸®æˆ‘æ¢³ç†ä¸€ä¸‹å¯ä»¥å—ï¼Ÿ

---

**Cursor**

å¥½çš„ï¼Œè®©æˆ‘å¸®ä½ å¯¹æ¯”åˆ†æä¸€ä¸‹æ–°éœ€æ±‚å’Œç°æœ‰åŠŸèƒ½çš„å·®å¼‚ã€‚

## ğŸ“Š éœ€æ±‚å¯¹æ¯”åˆ†æ

### ğŸ” **ç°æœ‰åŠŸèƒ½** (`evaluation-report-ultra-simple-spec.md`)

**æ ¸å¿ƒå®šä½**ï¼šé¢è¯•åçš„ç»¼åˆèƒ½åŠ›è¯„ä¼°
- âœ… è‡ªé€‚åº”æŠ½å–è€ƒæ ¸ç»´åº¦ï¼ˆæŠ€æœ¯èƒ½åŠ›ã€è½¯æŠ€èƒ½ã€æ–‡åŒ–åŒ¹é…ï¼‰
- âœ… é€é¡¹æ‰“åˆ†è¯„ä¼°ï¼ˆæ¯ä¸ªç»´åº¦ç‹¬ç«‹åˆ†æï¼‰
- âœ… HRè§†è§’æŠ¥å‘Šï¼ˆè¯„çº§T0-T4ã€äº®ç‚¹ã€é£é™©ï¼‰
- âœ… å€™é€‰äººè§†è§’æŠ¥å‘Šï¼ˆä¼˜åŠ¿ã€ä¸è¶³ã€æ”¹è¿›å»ºè®®ï¼‰
- âœ… å¤šæ¨¡æ€åˆ†æï¼ˆå¤–è¡¨ã€é£æ ¼ã€è¡Œä¸ºï¼‰

**å·¥ä½œæµç¨‹**ï¼š
```
é¢è¯•å¯¹è¯ â†’ æŠ½å–ç»´åº¦ â†’ é€é¡¹è¯„åˆ† â†’ HRæ€»ç»“ â†’ å¤šæ¨¡æ€ â†’ å€™é€‰äººæŠ¥å‘Š
```

---

### ğŸ†• **æ–°éœ€æ±‚** (`evaluation-report-sepc.md`)

**æ ¸å¿ƒå®šä½**ï¼šèŒä¸šå‘å±•å’¨è¯¢ + å¸‚åœºåŒ¹é…åˆ†æ
- ğŸ†• **å²—ä½é€‚é…åº¦è¯„åˆ†**ï¼ˆå½“å‰å²—ä½çš„åŒ¹é…åº¦ï¼‰
- ğŸ†• **å…¶ä»–å²—ä½æ¨è**ï¼ˆæ¨ªå‘/çºµå‘å‘å±• + æ¨èç™¾åˆ†æ¯” + ç†ç”±ï¼‰
- ğŸ†• **è–ªé…¬è¯„ä¼°ç³»ç»Ÿ**ï¼ˆéœ€è¦è”ç½‘æ£€ç´¢å¸‚åœºæ•°æ®ï¼‰
  - å¸‚åœºè¡Œæƒ…åˆ†æ
  - ä¸åŒè§„æ¨¡ä¼ä¸šè–ªé…¬èŒƒå›´
  - å€™é€‰äººå½“å‰è–ªé…¬è¯„ä¼°
  - è–ªé…¬æå‡è·¯å¾„
- ğŸ†• **é¢„æœŸç®¡ç†ç³»ç»Ÿ**
  - è¯†åˆ«ä¸åˆç†é¢„æœŸ
  - æ¨èåˆé€‚çš„èµ·å§‹å²—ä½çº§åˆ«
  - ç‰¹å®šè–ªèµ„æ‰€éœ€ç»éªŒå¹´é™
- ğŸ†• **æ€§æ ¼æ·±åº¦åˆ†æ**ï¼ˆæ›´å…·è±¡åŒ–ï¼‰
  - å²—ä½å¯¹æ€§æ ¼çš„è¦æ±‚
  - å€™é€‰äººæ€§æ ¼ç‰¹å¾
  - å…·è±¡åŒ–çš„æ€§æ ¼å¡‘é€ å»ºè®®
- ğŸ†• **æˆé•¿å»ºè®®**ï¼ˆæ›´ç³»ç»ŸåŒ–ï¼‰
  - å¿ƒæ€å»ºè®¾
  - å¿…å¤‡æŠ€èƒ½æ¸…å•
  - ä¸åŒä¼ä¸šè§„æ¨¡çš„è¦æ±‚åˆ†æ

---

## ğŸ”„ **æ ¸å¿ƒå˜åŒ–æ€»ç»“**

### âœ¨ **æ–°å¢çš„é‡ç‚¹åŠŸèƒ½**

#### 1. **èŒä¸šè§„åˆ’å¯¼å‘** â­â­â­
```
ç°æœ‰ï¼šä¸»è¦è¯„ä¼°"è¿™ä¸ªå²—ä½åˆä¸åˆé€‚"
æ–°éœ€æ±‚ï¼šä¸ä»…è¯„ä¼°å½“å‰å²—ä½ï¼Œè¿˜è¦æ¨è"ä½ è¿˜å¯ä»¥åšä»€ä¹ˆ"
```

#### 2. **è–ªé…¬å¸‚åœºåˆ†æ** â­â­â­ï¼ˆæœ€å¤§å˜åŒ–ï¼‰
```
ç°æœ‰ï¼šæ— è–ªé…¬ç›¸å…³åŠŸèƒ½
æ–°éœ€æ±‚ï¼š
  - éœ€è¦è”ç½‘æ£€ç´¢å¸‚åœºæ•°æ®
  - åˆ†æä¸åŒè§„æ¨¡ä¼ä¸šï¼ˆ500å¼º/æ™®é€š/åˆåˆ›ï¼‰çš„è–ªé…¬
  - ç»™å‡ºè–ªé…¬æå‡è·¯å¾„
  - ç®¡ç†å€™é€‰äººè–ªé…¬é¢„æœŸ
```

#### 3. **é¢„æœŸç®¡ç†ç³»ç»Ÿ** â­â­â­
```
ç°æœ‰ï¼šæ— 
æ–°éœ€æ±‚ï¼šè¯†åˆ«å€™é€‰äººçš„"ä¸åˆç†é¢„æœŸ"ï¼Œå¸®åŠ©å…¶è®¤æ¸…ç°å®
  ä¾‹å¦‚ï¼šåº”å±Šç”ŸæœŸæœ›30K â†’ åˆ†æå¸‚åœºç°å® â†’ å»ºè®®åˆç†é¢„æœŸ
```

#### 4. **å²—ä½æ¨èç®—æ³•** â­â­
```
ç°æœ‰ï¼šæ— 
æ–°éœ€æ±‚ï¼šåŸºäºå€™é€‰äººèƒ½åŠ›ï¼Œæ¨èå…¶ä»–é€‚åˆçš„å²—ä½
  - æ¨ªå‘å‘å±•ï¼ˆåŒçº§åˆ«å…¶ä»–å²—ä½ï¼‰
  - çºµå‘å‘å±•ï¼ˆæ™‹å‡è·¯å¾„ï¼‰
  - ç»™å‡ºæ¨èç™¾åˆ†æ¯”å’Œç†ç”±
```

---

## ğŸ“‹ **åŠŸèƒ½å¯¹æ¯”è¡¨**

| åŠŸèƒ½æ¨¡å— | ç°æœ‰åŠŸèƒ½ | æ–°éœ€æ±‚ | å˜åŒ–ç¨‹åº¦ |
|---------|---------|--------|---------|
| **èƒ½åŠ›è¯„ä¼°** | âœ… æœ‰ï¼ˆç¡¬æŠ€èƒ½+è½¯æŠ€èƒ½+æ–‡åŒ–åŒ¹é…ï¼‰ | âœ… ä¿ç•™ + æ‰©å±• | ğŸ”µ å¢å¼º |
| **HRæŠ¥å‘Š** | âœ… æœ‰ï¼ˆäº®ç‚¹ã€é£é™©ã€è¯„çº§ï¼‰ | âœ… ä¿ç•™ | âœ… ä¸å˜ |
| **å€™é€‰äººæŠ¥å‘Š** | âœ… æœ‰ï¼ˆä¼˜åŠ¿ã€ä¸è¶³ã€å»ºè®®ï¼‰ | âœ… ä¿ç•™ + æ‰©å±• | ğŸ”µ å¢å¼º |
| **å²—ä½é€‚é…åº¦** | âš ï¸ éƒ¨åˆ†ï¼ˆåªæœ‰è¯„çº§ï¼‰ | ğŸ†• æ˜ç¡®è¯„åˆ† | ğŸŸ¢ æ–°å¢ |
| **å…¶ä»–å²—ä½æ¨è** | âŒ æ—  | ğŸ†• æ¨ªå‘/çºµå‘æ¨è | ğŸŸ¢ æ–°å¢ |
| **è–ªé…¬è¯„ä¼°** | âŒ æ—  | ğŸ†• å¸‚åœºåˆ†æ+è”ç½‘æ£€ç´¢ | ğŸŸ¢ æ–°å¢ |
| **é¢„æœŸç®¡ç†** | âŒ æ—  | ğŸ†• è¯†åˆ«ä¸åˆç†é¢„æœŸ | ğŸŸ¢ æ–°å¢ |
| **æ€§æ ¼åˆ†æ** | âš ï¸ éƒ¨åˆ†ï¼ˆåœ¨è½¯æŠ€èƒ½ä¸­ï¼‰ | ğŸ†• ç‹¬ç«‹æ¨¡å—+å…·è±¡åŒ– | ğŸ”µ å¢å¼º |
| **æˆé•¿å»ºè®®** | âœ… æœ‰ï¼ˆçŸ­æœŸ/é•¿æœŸè¡ŒåŠ¨ï¼‰ | ğŸ†• æ›´ç³»ç»ŸåŒ–ï¼ˆå¿ƒæ€+æŠ€èƒ½+è·¯å¾„ï¼‰ | ğŸ”µ å¢å¼º |
| **å¤šæ¨¡æ€åˆ†æ** | âœ… æœ‰ï¼ˆå¤–è¡¨ã€é£æ ¼ï¼‰ | â“ æœªæåŠ | âš ï¸ å¾…ç¡®è®¤ |

---

## ğŸ¯ **æŠ€æœ¯å®ç°å±‚é¢çš„å˜åŒ–**

### 1. **éœ€è¦æ–°å¢å¤–éƒ¨APIè°ƒç”¨** ğŸ”´ é‡è¦
```python
# ç°æœ‰ï¼šåªè°ƒç”¨å†…éƒ¨LLM
model = "qwen-plus"

# æ–°éœ€æ±‚ï¼šéœ€è¦è”ç½‘æ£€ç´¢è–ªé…¬æ•°æ®
- è–ªé…¬æ•°æ®APIï¼ˆæ™ºè”æ‹›è˜/å‰ç¨‹æ— å¿§/ç¬¬ä¸‰æ–¹æ•°æ®ï¼‰
- æˆ–è€…ä½¿ç”¨LLMçš„è”ç½‘æœç´¢èƒ½åŠ›ï¼ˆå¦‚Qwençš„searchå·¥å…·ï¼‰
```

### 2. **LLMè°ƒç”¨æ¬¡æ•°å¢åŠ **
```python
# ç°æœ‰ï¼š3+Næ¬¡ï¼ˆN=5-10ä¸ªç»´åº¦ï¼‰
# æ–°éœ€æ±‚ï¼šå¯èƒ½éœ€è¦ 5+N+M æ¬¡
#   +1 å²—ä½æ¨èåˆ†æ
#   +1 è–ªé…¬å¸‚åœºåˆ†æ
#   +M æ¯ä¸ªæ¨èå²—ä½çš„é€‚é…åˆ†æ
```

### 3. **éœ€è¦æ–°çš„Promptæ¨¡æ¿**
```
æ–°å¢Promptï¼š
- å²—ä½æ¨èpromptï¼ˆæ¨ªå‘/çºµå‘åˆ†æï¼‰
- è–ªé…¬è¯„ä¼°promptï¼ˆå¸‚åœºè¡Œæƒ… + ä¸ªäººå®šä»·ï¼‰
- é¢„æœŸç®¡ç†promptï¼ˆè¯†åˆ«ä¸åˆç†é¢„æœŸï¼‰
- æ€§æ ¼å…·è±¡åŒ–åˆ†æprompt
```

### 4. **å¯èƒ½éœ€è¦æ–°çš„ç®—æ³•é€»è¾‘**
```python
# æ–°éœ€æ±‚ä¸­æåˆ°ï¼š
- å²—ä½åŒ¹é…ç®—æ³•
- é€‚é…åº¦è¯„åˆ†ç®—æ³•

# å¯èƒ½éœ€è¦å®ç°ï¼š
def calculate_job_match_score(candidate_skills, job_requirements):
    """è®¡ç®—å²—ä½é€‚é…åº¦"""
    
def recommend_alternative_jobs(candidate_profile, current_jd):
    """æ¨èå…¶ä»–å²—ä½"""
    
def analyze_salary_expectation(candidate_exp, market_data):
    """è–ªé…¬åˆç†æ€§åˆ†æ"""
```

---

## ğŸš§ **å®ç°éš¾ç‚¹å’ŒæŒ‘æˆ˜**

### 1. **è–ªé…¬æ•°æ®è·å–** ğŸ”´ æœ€å¤§æŒ‘æˆ˜
- éœ€è¦å¯é çš„è–ªé…¬æ•°æ®æº
- æ•°æ®å®æ—¶æ€§è¦æ±‚
- ä¸åŒåŸå¸‚/è¡Œä¸šçš„å·®å¼‚

### 2. **å²—ä½æ¨èçš„å‡†ç¡®æ€§**
- å¦‚ä½•åˆ¤æ–­"æ¨ªå‘/çºµå‘"å²—ä½ï¼Ÿ
- æ¨èç™¾åˆ†æ¯”çš„è®¡ç®—ä¾æ®ï¼Ÿ
- éœ€è¦å²—ä½çŸ¥è¯†åº“æ”¯æŒ

### 3. **é¢„æœŸç®¡ç†çš„åˆç†æ€§**
- å¦‚ä½•åˆ¤æ–­é¢„æœŸæ˜¯å¦"ä¸åˆç†"ï¼Ÿ
- å¦‚ä½•ç»™å‡ºå»ºè®¾æ€§å»ºè®®è€Œä¸æ‰“å‡»ç§¯ææ€§ï¼Ÿ

---

## ğŸ’¡ **æˆ‘çš„å»ºè®®**

### æ–¹æ¡ˆAï¼šåˆ†é˜¶æ®µå®ç° âœ… æ¨è
```
é˜¶æ®µ1ï¼šå¢å¼ºç°æœ‰åŠŸèƒ½
  - å²—ä½é€‚é…åº¦æ˜ç¡®è¯„åˆ†
  - æ€§æ ¼åˆ†æç‹¬ç«‹æ¨¡å—åŒ–
  - æˆé•¿å»ºè®®æ›´ç³»ç»ŸåŒ–

é˜¶æ®µ2ï¼šæ–°å¢èŒä¸šè§„åˆ’åŠŸèƒ½
  - å²—ä½æ¨èï¼ˆåŸºäºLLMæ¨ç†ï¼Œæ— éœ€å¤æ‚ç®—æ³•ï¼‰
  - é¢„æœŸç®¡ç†ï¼ˆåŸºäºå¸¸è¯†åˆ¤æ–­ï¼‰

é˜¶æ®µ3ï¼šé›†æˆå¸‚åœºæ•°æ®
  - è–ªé…¬åˆ†æï¼ˆéœ€è¦å¤–éƒ¨æ•°æ®æºï¼‰
  - å¸‚åœºè¡Œæƒ…å¯¹æ¯”
```

### æ–¹æ¡ˆBï¼šç®€åŒ–è–ªé…¬åŠŸèƒ½
```
ä¸è”ç½‘æ£€ç´¢çœŸå®æ•°æ®ï¼Œè€Œæ˜¯ï¼š
- åŸºäºLLMçš„å¸¸è¯†å’ŒçŸ¥è¯†åº“ç»™å‡º"å‚è€ƒèŒƒå›´"
- æ˜ç¡®æ ‡æ³¨"ä»…ä¾›å‚è€ƒï¼Œéå®æ—¶æ•°æ®"
- é™ä½å®ç°å¤æ‚åº¦ï¼Œä½†åŠŸèƒ½æ‰“æŠ˜æ‰£
```

---

ä½ è§‰å¾—è¿™ä¸ªåˆ†ææ€ä¹ˆæ ·ï¼Ÿéœ€è¦æˆ‘è¯¦ç»†å±•å¼€æŸä¸ªå…·ä½“çš„å˜åŒ–ç‚¹å—ï¼Ÿæˆ–è€…ä½ æƒ³å…ˆç¡®è®¤ä¸€ä¸‹æ–°éœ€æ±‚ä¸­å“ªäº›åŠŸèƒ½æ˜¯**å¿…é¡»è¦æœ‰çš„**ï¼Œå“ªäº›æ˜¯**å¯ä»¥åç»­è¿­ä»£çš„**ï¼Ÿ

```plaintext
é¢è¯•å¯¹è¯ â†’ æŠ½å–ç»´åº¦ â†’ é€é¡¹è¯„åˆ† â†’ HRæ€»ç»“ â†’ å¤šæ¨¡æ€ â†’ å€™é€‰äººæŠ¥å‘Š
```

```plaintext
ç°æœ‰ï¼šä¸»è¦è¯„ä¼°"è¿™ä¸ªå²—ä½åˆä¸åˆé€‚"
æ–°éœ€æ±‚ï¼šä¸ä»…è¯„ä¼°å½“å‰å²—ä½ï¼Œè¿˜è¦æ¨è"ä½ è¿˜å¯ä»¥åšä»€ä¹ˆ"
```

```plaintext
ç°æœ‰ï¼šæ— è–ªé…¬ç›¸å…³åŠŸèƒ½
æ–°éœ€æ±‚ï¼š
  - éœ€è¦è”ç½‘æ£€ç´¢å¸‚åœºæ•°æ®
  - åˆ†æä¸åŒè§„æ¨¡ä¼ä¸šï¼ˆ500å¼º/æ™®é€š/åˆåˆ›ï¼‰çš„è–ªé…¬
  - ç»™å‡ºè–ªé…¬æå‡è·¯å¾„
  - ç®¡ç†å€™é€‰äººè–ªé…¬é¢„æœŸ
```

```plaintext
ç°æœ‰ï¼šæ— 
æ–°éœ€æ±‚ï¼šè¯†åˆ«å€™é€‰äººçš„"ä¸åˆç†é¢„æœŸ"ï¼Œå¸®åŠ©å…¶è®¤æ¸…ç°å®
  ä¾‹å¦‚ï¼šåº”å±Šç”ŸæœŸæœ›30K â†’ åˆ†æå¸‚åœºç°å® â†’ å»ºè®®åˆç†é¢„æœŸ
```

```plaintext
ç°æœ‰ï¼šæ— 
æ–°éœ€æ±‚ï¼šåŸºäºå€™é€‰äººèƒ½åŠ›ï¼Œæ¨èå…¶ä»–é€‚åˆçš„å²—ä½
  - æ¨ªå‘å‘å±•ï¼ˆåŒçº§åˆ«å…¶ä»–å²—ä½ï¼‰
  - çºµå‘å‘å±•ï¼ˆæ™‹å‡è·¯å¾„ï¼‰
  - ç»™å‡ºæ¨èç™¾åˆ†æ¯”å’Œç†ç”±
```

```python
# ç°æœ‰ï¼šåªè°ƒç”¨å†…éƒ¨LLM
model = "qwen-plus"

# æ–°éœ€æ±‚ï¼šéœ€è¦è”ç½‘æ£€ç´¢è–ªé…¬æ•°æ®
- è–ªé…¬æ•°æ®APIï¼ˆæ™ºè”æ‹›è˜/å‰ç¨‹æ— å¿§/ç¬¬ä¸‰æ–¹æ•°æ®ï¼‰
- æˆ–è€…ä½¿ç”¨LLMçš„è”ç½‘æœç´¢èƒ½åŠ›ï¼ˆå¦‚Qwençš„searchå·¥å…·ï¼‰
```

```python
# ç°æœ‰ï¼š3+Næ¬¡ï¼ˆN=5-10ä¸ªç»´åº¦ï¼‰
# æ–°éœ€æ±‚ï¼šå¯èƒ½éœ€è¦ 5+N+M æ¬¡
#   +1 å²—ä½æ¨èåˆ†æ
#   +1 è–ªé…¬å¸‚åœºåˆ†æ
#   +M æ¯ä¸ªæ¨èå²—ä½çš„é€‚é…åˆ†æ
```

```plaintext
æ–°å¢Promptï¼š
- å²—ä½æ¨èpromptï¼ˆæ¨ªå‘/çºµå‘åˆ†æï¼‰
- è–ªé…¬è¯„ä¼°promptï¼ˆå¸‚åœºè¡Œæƒ… + ä¸ªäººå®šä»·ï¼‰
- é¢„æœŸç®¡ç†promptï¼ˆè¯†åˆ«ä¸åˆç†é¢„æœŸï¼‰
- æ€§æ ¼å…·è±¡åŒ–åˆ†æprompt
```

```python
# æ–°éœ€æ±‚ä¸­æåˆ°ï¼š
- å²—ä½åŒ¹é…ç®—æ³•
- é€‚é…åº¦è¯„åˆ†ç®—æ³•

# å¯èƒ½éœ€è¦å®ç°ï¼š
def calculate_job_match_score(candidate_skills, job_requirements):
    """è®¡ç®—å²—ä½é€‚é…åº¦"""
    
def recommend_alternative_jobs(candidate_profile, current_jd):
    """æ¨èå…¶ä»–å²—ä½"""
    
def analyze_salary_expectation(candidate_exp, market_data):
    """è–ªé…¬åˆç†æ€§åˆ†æ"""
```

```plaintext
é˜¶æ®µ1ï¼šå¢å¼ºç°æœ‰åŠŸèƒ½
  - å²—ä½é€‚é…åº¦æ˜ç¡®è¯„åˆ†
  - æ€§æ ¼åˆ†æç‹¬ç«‹æ¨¡å—åŒ–
  - æˆé•¿å»ºè®®æ›´ç³»ç»ŸåŒ–

é˜¶æ®µ2ï¼šæ–°å¢èŒä¸šè§„åˆ’åŠŸèƒ½
  - å²—ä½æ¨èï¼ˆåŸºäºLLMæ¨ç†ï¼Œæ— éœ€å¤æ‚ç®—æ³•ï¼‰
  - é¢„æœŸç®¡ç†ï¼ˆåŸºäºå¸¸è¯†åˆ¤æ–­ï¼‰

é˜¶æ®µ3ï¼šé›†æˆå¸‚åœºæ•°æ®
  - è–ªé…¬åˆ†æï¼ˆéœ€è¦å¤–éƒ¨æ•°æ®æºï¼‰
  - å¸‚åœºè¡Œæƒ…å¯¹æ¯”
```

```plaintext
ä¸è”ç½‘æ£€ç´¢çœŸå®æ•°æ®ï¼Œè€Œæ˜¯ï¼š
- åŸºäºLLMçš„å¸¸è¯†å’ŒçŸ¥è¯†åº“ç»™å‡º"å‚è€ƒèŒƒå›´"
- æ˜ç¡®æ ‡æ³¨"ä»…ä¾›å‚è€ƒï¼Œéå®æ—¶æ•°æ®"
- é™ä½å®ç°å¤æ‚åº¦ï¼Œä½†åŠŸèƒ½æ‰“æŠ˜æ‰£
```

---

**User**

æˆ‘è®¤ä¸ºæœç´¢è–ªé…¬çš„æ—¶å€™ç›´æ¥ä½¿ç”¨LLMçš„è”ç½‘æœç´¢èƒ½åŠ›ï¼ˆå¦‚Qwençš„searchå·¥å…·ï¼‰å°±è¡Œ



æ­¤å¤–ï¼Œæˆ‘è§‰å¾—ä½ çš„æ–¹æ¡ˆaé‡Œé¢çš„ç¬¬ä¸€é˜¶æ®µè·Ÿç¬¬äºŒé˜¶æ®µéå¸¸ä¸é”™ï¼Œæˆ‘ä»¬ç°åœ¨å°±æŒ‰ç…§ç¬¬ä¸€é˜¶æ®µè·Ÿç¬¬äºŒé˜¶æ®µæ¥è¿›è¡Œæˆ‘ä»¬æ¥ä¸‹æ¥çš„æ–¹æ¡ˆå¯ä»¥å—ï¼Ÿ



å› æ­¤çš„è¯ï¼ŒåŸºäºæˆ‘ä»¬ä¹‹å‰å¯¹è¯ä½ å¾—åˆ°çš„ä¿¡æ¯æ¥å¸®æˆ‘åœ¨è¿™ä¸ªspec@evaluation-report-ultra-simple-spec.md ä¸Šé¢è¿›è¡Œä¿®æ”¹å¯ä»¥å—ï¼Ÿå°±æ˜¯èå…¥æˆ‘ä»¬æå‡ºçš„æ–°çš„åŠŸèƒ½å¹¶ä¸”å¢å¼ºå·²æœ‰çš„åŠŸèƒ½ã€‚é£æ ¼å’Œå†…å®¹ ä»¥åŠè¦æ±‚ ä¾ç„¶ å’Œ@evaluation-report-ultra-simple-spec.md ä¿æŒä¸€è‡´ã€‚ 

é‚£ä¹ˆç°åœ¨å‘¢ï¼Ÿä½ å°±å¯ä»¥å¼€å§‹å¸®æˆ‘ä¿®æ”¹äº†ã€‚å¹¶ä¸”ä¿®æ”¹å®Œä»¥åå‘Šè¯‰æˆ‘ä½ ä¿®æ”¹äº†å“ªäº›ç‚¹æ–¹ä¾¿æˆ‘double checkã€‚ 

---

**Cursor**

å¥½çš„ï¼æˆ‘ç°åœ¨å¼€å§‹ä¿®æ”¹ `evaluation-report-ultra-simple-spec.md`ï¼Œèå…¥é˜¶æ®µ1å’Œé˜¶æ®µ2çš„æ–°åŠŸèƒ½ã€‚

è®©æˆ‘å…ˆä»”ç»†çœ‹ä¸€ä¸‹ç°æœ‰æ–‡æ¡£çš„å®Œæ•´å†…å®¹ï¼Œç„¶åè¿›è¡Œä¿®æ”¹ã€‚

ç°åœ¨å¼€å§‹ä¿®æ”¹æ–‡æ¡£ï¼Œèå…¥æ–°åŠŸèƒ½ï¼š

```markdown
# AIé¢è¯•è¯„ä¼°æŠ¥å‘Šç³»ç»Ÿè§„èŒƒï¼ˆåŸºäºGoldenä»£ç ï¼‰

## ğŸ¯ æ ¸å¿ƒæ€è·¯

**å¤šæ­¥éª¤æ·±åº¦åˆ†æ**ï¼šè‡ªé€‚åº”æŠ½å–è€ƒæ ¸ç»´åº¦ â†’ é€é¡¹æ‰“åˆ†è¯„ä¼° â†’ å²—ä½é€‚é…åº¦åˆ†æ â†’ æ€§æ ¼æ·±åº¦åˆ†æ â†’ èŒä¸šå‘å±•è§„åˆ’ â†’ è–ªé…¬å¸‚åœºè¯„ä¼° â†’ ç»¼åˆæ€»ç»“æŠ¥å‘Š â†’ å¤šæ¨¡æ€é£æ ¼åˆ†æ â†’ å€™é€‰äººåé¦ˆ

## ğŸ“‹ æ ¸å¿ƒåŠŸèƒ½

### è¾“å…¥
- é¢è¯•å¯¹è¯è®°å½•ï¼ˆtranscriptï¼‰
- å²—ä½æè¿°ï¼ˆJDï¼‰
- è§†é¢‘/å›¾ç‰‡URLï¼ˆurl_listï¼‰
- é¢è¯•è¯­è¨€ï¼ˆinterview_languageï¼‰

### è¾“å‡º
- HRè§†è§’ï¼šç»¼åˆè¯„åˆ†ã€äº®ç‚¹ã€é£é™©ã€è¯„çº§ï¼ˆT0~T4ï¼‰
- å€™é€‰äººè§†è§’ï¼šä¼˜åŠ¿ã€ä¸è¶³ã€çŸ­æœŸ/é•¿æœŸæ”¹è¿›å»ºè®®
- å¤šæ¨¡æ€ï¼šé£æ ¼æ ‡ç­¾ã€å½¢è±¡è¯„åˆ†ã€è¡Œä¸ºæ£€æµ‹

### å¤„ç†æ–¹å¼
- **3+Næ¬¡AIè°ƒç”¨**ï¼ˆN=è€ƒæ ¸ç»´åº¦æ•°é‡ï¼Œé€šå¸¸5-10ä¸ªï¼‰
- è‡ªé€‚åº”æŠ½å–ç»´åº¦ï¼Œé€é¡¹ç‹¬ç«‹è¯„åˆ†
- å¤šæ¨¡æ€åˆ†æï¼ˆæ”¯æŒè§†é¢‘/å›¾ç‰‡ï¼‰

## ğŸ’» æ ¸å¿ƒå®ç°

### æ–‡ä»¶ç»“æ„
```
service/
â”œâ”€â”€ AIInterviewAssessor.py    # æ ¸å¿ƒæœåŠ¡ï¼ˆ327è¡Œï¼‰
â””â”€â”€ multimodal_report.py       # å¤šæ¨¡æ€åˆ†æï¼ˆ100è¡Œï¼‰
routers/
â””â”€â”€ interview_report_router.py # APIè·¯ç”±ï¼ˆ97è¡Œï¼‰
```

### æ ¸å¿ƒæµç¨‹ï¼ˆ5æ­¥ï¼‰
```python
def generate_report(transcript, jd, interview_id, url_list, is_mp4, language):
    # æ­¥éª¤1: æŠ½å–è€ƒæ ¸ç»´åº¦ (1æ¬¡AIè°ƒç”¨)
    competencies = _extract_competencies(jd, transcript)
    # è¾“å‡º: {hard_skills: [...], soft_skills: [...], cultural_fit: [...]}
    
    # æ­¥éª¤2: é€é¡¹èƒ½åŠ›è¯„ä¼° (Næ¬¡AIè°ƒç”¨)
    for competency in all_competency_keys:
        result = _analyze_single_competency(competency, transcript)
        # è¾“å‡º: {score: 85, rationale: "...", evidence_quotes: [...]}
    
    # æ­¥éª¤3: ç”ŸæˆHRæ€»ç»“ (1æ¬¡AIè°ƒç”¨)
    summary = _generate_final_summary(detailed_analysis)
    # è¾“å‡º: {highlights: "...", risks: "...", conclusion: "T2-èƒœä»»..."}
    
    # æ­¥éª¤4: å¤šæ¨¡æ€åˆ†æ (1æ¬¡AIè°ƒç”¨, qwen-vl-max-latest)
    style = style_report(url_list, interview_id, is_mp4, language)
    # è¾“å‡º: {style: "èŒä¸šå¹²ç»ƒ", description: "...", appearance: "82åˆ†..."}
    
    # æ­¥éª¤5: ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š (1æ¬¡AIè°ƒç”¨)
    user_report = _user_report(jd, transcript, hr_report)
    # è¾“å‡º: {highlights, insufficient, short_term_actions, long_term_actions, ...}
    
    # èšåˆæœ€ç»ˆæŠ¥å‘Š â†’ å­˜å…¥æ•°æ®åº“
    return final_report
```

## ğŸŒ APIæ¥å£

**POST** `/interviewReport`

### è¯·æ±‚
```json
{
  "interview_id": "123456",
  "transcript": [
    {"role": "interviewer", "content": "ä»‹ç»ä½ çš„Pythonç»éªŒ", "timestamp": 1},
    {"role": "candidate", "content": "æˆ‘æœ‰3å¹´Pythonå¼€å‘ç»éªŒ...", "timestamp": 2}
  ],
  "jd": "å²—ä½èŒè´£ï¼š\n1. åç«¯å¼€å‘\nä»»èŒè¦æ±‚ï¼š\n1. 3å¹´Pythonç»éªŒ",
  "interview_language": "zhongwen",
  "p_url": ["http://example.com/img1.png"],  // å›¾ç‰‡URL
  "v_url": ["http://example.com/video.mp4"]   // è§†é¢‘URL
}
```

### å“åº”ï¼ˆç«‹å³è¿”å›ï¼Œåå°å¼‚æ­¥ç”Ÿæˆï¼‰
```json
{
  "code": 0,
  "message": "success",
  "data": ""
}
```

### æœ€ç»ˆæŠ¥å‘Šç»“æ„ï¼ˆå­˜å…¥æ•°æ®åº“ï¼‰
```json
{
  "overall_assessment": {
    "match_score": 78.5,
    "conclusion": "T2-èƒœä»»ï¼Œå®šä¹‰ï¼šç¬¦åˆé¢„æœŸã€‚å»ºè®®å½•ç”¨ã€‚",
    "highlights": "æŠ€æœ¯åŸºç¡€æ‰å®ï¼Œæ²Ÿé€šæ¸…æ™°",
    "potential_risks": "ç¼ºä¹æ¶æ„ç»éªŒ"
  },
  "detailed_analysis": [
    {
      "competency": "Pythonå¼€å‘èƒ½åŠ›",
      "score": 85,
      "rationale": "æ‰å®çš„å¼€å‘åŸºç¡€ï¼Œç†Ÿæ‚‰Djangoæ¡†æ¶",
      "evidence_quotes": ["æˆ‘ä¸»å¯¼äº†è®¢å•ç³»ç»Ÿå¼€å‘", "æ—¥å‡100ä¸‡è¯·æ±‚é‡"]
    }
  ],
  "competency_model_used": {
    "hard_skills": ["Pythonå¼€å‘", "æ•°æ®åº“è®¾è®¡"],
    "soft_skills": ["æ²Ÿé€šèƒ½åŠ›"],
    "cultural_fit": ["å­¦ä¹ æ€åº¦"]
  },
  "style_report": {
    "style": "èŒä¸šå¹²ç»ƒ",
    "description": "çœ¼ç¥è‡ªä¿¡ï¼Œç€è£…å¾—ä½“",
    "behavior": "æœªå‘ç°å¼‚å¸¸",
    "appearance": "82åˆ†ã€‚äº”å®˜ç«¯æ­£ï¼Œæ­£è£…æ•´æ´"
  },
  "user_report": {
    "highlights": "ä½ çš„æŠ€æœ¯è¡¨è¾¾æ¸…æ™°...",
    "insufficient": "æ¶æ„è®¾è®¡å¯ä»¥æ›´æœ‰æ¡ç†...",
    "short_term_actions": ["æ¯å¤©ç»ƒä¹ 1ä¸ªç®—æ³•é¢˜", "å‡†å¤‡3ä¸ªSTARè¯æœ¯"],
    "long_term_actions": ["å­¦ä¹ åˆ†å¸ƒå¼ç³»ç»Ÿ", "å‚ä¸å¼€æºé¡¹ç›®"],
    "Quantitative": "æ¯å‘¨2æ¬¡æ¨¡æ‹Ÿé¢è¯•ï¼Œè®°å½•æ”¹è¿›ç‚¹",
    "career_advice": "å‘é«˜çº§å·¥ç¨‹å¸ˆå‘å±•ï¼Œè¡¥å……æ¶æ„èƒ½åŠ›",
    "other": "ä¿æŒå­¦ä¹ èŠ‚å¥ï¼Œ3å¹´å†…å¯æˆé•¿ä¸ºæ¶æ„å¸ˆ"
  }
}
```

## ğŸ”§ æŠ€æœ¯ç»†èŠ‚

### LLMé…ç½®
```python
# æ–‡æœ¬åˆ†ææ¨¡å‹
model = "qwen-plus"
temperature = 0.3
seed = 6
response_format = {"type": "json_object"}

# å¤šæ¨¡æ€æ¨¡å‹
multimodal_model = "qwen-vl-max-latest"
```

### é‡è¦æœºåˆ¶
- **é‡è¯•æœºåˆ¶**ï¼šå…³é”®AIè°ƒç”¨å¤±è´¥è‡ªåŠ¨é‡è¯•1æ¬¡
- **å¤šæ¨¡æ€ä¿åº•**ï¼šè§†é¢‘åˆ†æå¤±è´¥é™çº§ä¸ºæ–‡æœ¬åˆ†æ
- **å¼‚æ­¥å¤„ç†**ï¼šFastAPI BackgroundTasksåå°ç”Ÿæˆ
- **é˜²é‡å¤**ï¼š10åˆ†é’Ÿå†…åŒinterview_idä¸é‡å¤ç”Ÿæˆ

### æ”¯æŒçš„è¯­è¨€
zhongwenã€yingwenã€riyuã€hanyuã€xibanyayuã€yinniyuã€fayuã€deyuã€taiyu

## ğŸ“Š å…³é”®æŒ‡æ ‡

- **AIè°ƒç”¨æ¬¡æ•°**ï¼šé€šå¸¸8-15æ¬¡ï¼ˆ3å›ºå®š + 5-10ç»´åº¦è¯„ä¼°ï¼‰
- **ç”Ÿæˆè€—æ—¶**ï¼š3-5åˆ†é’Ÿ
- **æˆåŠŸç‡**ï¼š>95%ï¼ˆå¤šå±‚é‡è¯•ä¿éšœï¼‰
- **è¯„çº§ä½“ç³»**ï¼šT0å“è¶Š / T1å¨´ç†Ÿ / T2èƒœä»» / T3å¾…åŸ¹å…» / T4å·®è·è¾ƒå¤§

---

**æ ¸å¿ƒåŸåˆ™**ï¼šè‡ªé€‚åº”ç»´åº¦æŠ½å– + é€é¡¹ç‹¬ç«‹è¯„ä¼° + åŒè§†è§’æŠ¥å‘Š + å¤šæ¨¡æ€å¢å¼º
```

```markdown
# AIé¢è¯•è¯„ä¼°æŠ¥å‘Šç³»ç»Ÿè§„èŒƒï¼ˆåŸºäºGoldenä»£ç ï¼‰

## ğŸ¯ æ ¸å¿ƒæ€è·¯

**å¤šæ­¥éª¤æ·±åº¦åˆ†æ**ï¼šè‡ªé€‚åº”æŠ½å–è€ƒæ ¸ç»´åº¦ â†’ é€é¡¹æ‰“åˆ†è¯„ä¼° â†’ å²—ä½é€‚é…åº¦åˆ†æ â†’ æ€§æ ¼æ·±åº¦åˆ†æ â†’ èŒä¸šå‘å±•è§„åˆ’ â†’ è–ªé…¬å¸‚åœºè¯„ä¼° â†’ ç»¼åˆæ€»ç»“æŠ¥å‘Š â†’ å¤šæ¨¡æ€é£æ ¼åˆ†æ â†’ å€™é€‰äººåé¦ˆ

## ğŸ“‹ æ ¸å¿ƒåŠŸèƒ½

### è¾“å…¥
- é¢è¯•å¯¹è¯è®°å½•ï¼ˆtranscriptï¼‰
- å²—ä½æè¿°ï¼ˆJDï¼‰
- è§†é¢‘/å›¾ç‰‡URLï¼ˆurl_listï¼‰
- é¢è¯•è¯­è¨€ï¼ˆinterview_languageï¼‰

### è¾“å‡º
- **HRè§†è§’**ï¼šç»¼åˆè¯„åˆ†ã€äº®ç‚¹ã€é£é™©ã€è¯„çº§ï¼ˆT0~T4ï¼‰
- **å€™é€‰äººè§†è§’**ï¼šä¼˜åŠ¿ã€ä¸è¶³ã€çŸ­æœŸ/é•¿æœŸæ”¹è¿›å»ºè®®
- **å²—ä½é€‚é…åº¦**ï¼šå½“å‰å²—ä½åŒ¹é…åˆ†å€¼ã€èƒ½åŠ›å·®è·åˆ†æ
- **èŒä¸šå‘å±•**ï¼šæ¨ªå‘/çºµå‘å²—ä½æ¨è + æ¨èç™¾åˆ†æ¯” + æ¨èç†ç”±
- **æ€§æ ¼åˆ†æ**ï¼šå²—ä½æ€§æ ¼è¦æ±‚ã€å€™é€‰äººæ€§æ ¼ç‰¹å¾ã€å…·è±¡åŒ–å¡‘é€ å»ºè®®
- **è–ªé…¬è¯„ä¼°**ï¼šå¸‚åœºè¡Œæƒ…åˆ†æã€ä¸åŒè§„æ¨¡ä¼ä¸šè–ªé…¬èŒƒå›´ã€å€™é€‰äººå½“å‰è–ªé…¬è¯„ä¼°ã€è–ªé…¬æå‡è·¯å¾„
- **é¢„æœŸç®¡ç†**ï¼šè¯†åˆ«ä¸åˆç†é¢„æœŸã€æ¨èåˆé€‚èµ·å§‹å²—ä½çº§åˆ«ã€ç‰¹å®šè–ªèµ„æ‰€éœ€ç»éªŒå¹´é™
- **æˆé•¿å»ºè®®**ï¼šå¿ƒæ€å»ºè®¾ã€å¿…å¤‡æŠ€èƒ½æ¸…å•ã€ä¸åŒä¼ä¸šè§„æ¨¡è¦æ±‚åˆ†æã€å­¦ä¹ æå‡æ–¹å‘
- **å¤šæ¨¡æ€**ï¼šé£æ ¼æ ‡ç­¾ã€å½¢è±¡è¯„åˆ†ã€è¡Œä¸ºæ£€æµ‹

### å¤„ç†æ–¹å¼
- **3+Næ¬¡AIè°ƒç”¨**ï¼ˆN=è€ƒæ ¸ç»´åº¦æ•°é‡ï¼Œé€šå¸¸5-10ä¸ªï¼‰
- è‡ªé€‚åº”æŠ½å–ç»´åº¦ï¼Œé€é¡¹ç‹¬ç«‹è¯„åˆ†
- å¤šæ¨¡æ€åˆ†æï¼ˆæ”¯æŒè§†é¢‘/å›¾ç‰‡ï¼‰

## ğŸ’» æ ¸å¿ƒå®ç°

### æ–‡ä»¶ç»“æ„
```
service/
â”œâ”€â”€ AIInterviewAssessor.py    # æ ¸å¿ƒæœåŠ¡ï¼ˆ327è¡Œï¼‰
â””â”€â”€ multimodal_report.py       # å¤šæ¨¡æ€åˆ†æï¼ˆ100è¡Œï¼‰
routers/
â””â”€â”€ interview_report_router.py # APIè·¯ç”±ï¼ˆ97è¡Œï¼‰
```

### æ ¸å¿ƒæµç¨‹ï¼ˆ5æ­¥ï¼‰
```python
def generate_report(transcript, jd, interview_id, url_list, is_mp4, language):
    # æ­¥éª¤1: æŠ½å–è€ƒæ ¸ç»´åº¦ (1æ¬¡AIè°ƒç”¨)
    competencies = _extract_competencies(jd, transcript)
    # è¾“å‡º: {hard_skills: [...], soft_skills: [...], cultural_fit: [...]}
    
    # æ­¥éª¤2: é€é¡¹èƒ½åŠ›è¯„ä¼° (Næ¬¡AIè°ƒç”¨)
    for competency in all_competency_keys:
        result = _analyze_single_competency(competency, transcript)
        # è¾“å‡º: {score: 85, rationale: "...", evidence_quotes: [...]}
    
    # æ­¥éª¤3: ç”ŸæˆHRæ€»ç»“ (1æ¬¡AIè°ƒç”¨)
    summary = _generate_final_summary(detailed_analysis)
    # è¾“å‡º: {highlights: "...", risks: "...", conclusion: "T2-èƒœä»»..."}
    
    # æ­¥éª¤4: å¤šæ¨¡æ€åˆ†æ (1æ¬¡AIè°ƒç”¨, qwen-vl-max-latest)
    style = style_report(url_list, interview_id, is_mp4, language)
    # è¾“å‡º: {style: "èŒä¸šå¹²ç»ƒ", description: "...", appearance: "82åˆ†..."}
    
    # æ­¥éª¤5: ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š (1æ¬¡AIè°ƒç”¨)
    user_report = _user_report(jd, transcript, hr_report)
    # è¾“å‡º: {highlights, insufficient, short_term_actions, long_term_actions, ...}
    
    # èšåˆæœ€ç»ˆæŠ¥å‘Š â†’ å­˜å…¥æ•°æ®åº“
    return final_report
```

## ğŸŒ APIæ¥å£

**POST** `/interviewReport`

### è¯·æ±‚
```json
{
  "interview_id": "123456",
  "transcript": [
    {"role": "interviewer", "content": "ä»‹ç»ä½ çš„Pythonç»éªŒ", "timestamp": 1},
    {"role": "candidate", "content": "æˆ‘æœ‰3å¹´Pythonå¼€å‘ç»éªŒ...", "timestamp": 2}
  ],
  "jd": "å²—ä½èŒè´£ï¼š\n1. åç«¯å¼€å‘\nä»»èŒè¦æ±‚ï¼š\n1. 3å¹´Pythonç»éªŒ",
  "interview_language": "zhongwen",
  "p_url": ["http://example.com/img1.png"],  // å›¾ç‰‡URL
  "v_url": ["http://example.com/video.mp4"]   // è§†é¢‘URL
}
```

### å“åº”ï¼ˆç«‹å³è¿”å›ï¼Œåå°å¼‚æ­¥ç”Ÿæˆï¼‰
```json
{
  "code": 0,
  "message": "success",
  "data": ""
}
```

### æœ€ç»ˆæŠ¥å‘Šç»“æ„ï¼ˆå­˜å…¥æ•°æ®åº“ï¼‰
```json
{
  "overall_assessment": {
    "match_score": 78.5,
    "conclusion": "T2-èƒœä»»ï¼Œå®šä¹‰ï¼šç¬¦åˆé¢„æœŸã€‚å»ºè®®å½•ç”¨ã€‚",
    "highlights": "æŠ€æœ¯åŸºç¡€æ‰å®ï¼Œæ²Ÿé€šæ¸…æ™°",
    "potential_risks": "ç¼ºä¹æ¶æ„ç»éªŒ"
  },
  "detailed_analysis": [
    {
      "competency": "Pythonå¼€å‘èƒ½åŠ›",
      "score": 85,
      "rationale": "æ‰å®çš„å¼€å‘åŸºç¡€ï¼Œç†Ÿæ‚‰Djangoæ¡†æ¶",
      "evidence_quotes": ["æˆ‘ä¸»å¯¼äº†è®¢å•ç³»ç»Ÿå¼€å‘", "æ—¥å‡100ä¸‡è¯·æ±‚é‡"]
    }
  ],
  "competency_model_used": {
    "hard_skills": ["Pythonå¼€å‘", "æ•°æ®åº“è®¾è®¡"],
    "soft_skills": ["æ²Ÿé€šèƒ½åŠ›"],
    "cultural_fit": ["å­¦ä¹ æ€åº¦"]
  },
  "style_report": {
    "style": "èŒä¸šå¹²ç»ƒ",
    "description": "çœ¼ç¥è‡ªä¿¡ï¼Œç€è£…å¾—ä½“",
    "behavior": "æœªå‘ç°å¼‚å¸¸",
    "appearance": "82åˆ†ã€‚äº”å®˜ç«¯æ­£ï¼Œæ­£è£…æ•´æ´"
  },
  "user_report": {
    "highlights": "ä½ çš„æŠ€æœ¯è¡¨è¾¾æ¸…æ™°...",
    "insufficient": "æ¶æ„è®¾è®¡å¯ä»¥æ›´æœ‰æ¡ç†...",
    "short_term_actions": ["æ¯å¤©ç»ƒä¹ 1ä¸ªç®—æ³•é¢˜", "å‡†å¤‡3ä¸ªSTARè¯æœ¯"],
    "long_term_actions": ["å­¦ä¹ åˆ†å¸ƒå¼ç³»ç»Ÿ", "å‚ä¸å¼€æºé¡¹ç›®"],
    "Quantitative": "æ¯å‘¨2æ¬¡æ¨¡æ‹Ÿé¢è¯•ï¼Œè®°å½•æ”¹è¿›ç‚¹",
    "career_advice": "å‘é«˜çº§å·¥ç¨‹å¸ˆå‘å±•ï¼Œè¡¥å……æ¶æ„èƒ½åŠ›",
    "other": "ä¿æŒå­¦ä¹ èŠ‚å¥ï¼Œ3å¹´å†…å¯æˆé•¿ä¸ºæ¶æ„å¸ˆ"
  }
}
```

## ğŸ”§ æŠ€æœ¯ç»†èŠ‚

### LLMé…ç½®
```python
# æ–‡æœ¬åˆ†ææ¨¡å‹
model = "qwen-plus"
temperature = 0.3
seed = 6
response_format = {"type": "json_object"}

# å¤šæ¨¡æ€æ¨¡å‹
multimodal_model = "qwen-vl-max-latest"
```

### é‡è¦æœºåˆ¶
- **é‡è¯•æœºåˆ¶**ï¼šå…³é”®AIè°ƒç”¨å¤±è´¥è‡ªåŠ¨é‡è¯•1æ¬¡
- **å¤šæ¨¡æ€ä¿åº•**ï¼šè§†é¢‘åˆ†æå¤±è´¥é™çº§ä¸ºæ–‡æœ¬åˆ†æ
- **å¼‚æ­¥å¤„ç†**ï¼šFastAPI BackgroundTasksåå°ç”Ÿæˆ
- **é˜²é‡å¤**ï¼š10åˆ†é’Ÿå†…åŒinterview_idä¸é‡å¤ç”Ÿæˆ

### æ”¯æŒçš„è¯­è¨€
zhongwenã€yingwenã€riyuã€hanyuã€xibanyayuã€yinniyuã€fayuã€deyuã€taiyu

## ğŸ“Š å…³é”®æŒ‡æ ‡

- **AIè°ƒç”¨æ¬¡æ•°**ï¼šé€šå¸¸8-15æ¬¡ï¼ˆ3å›ºå®š + 5-10ç»´åº¦è¯„ä¼°ï¼‰
- **ç”Ÿæˆè€—æ—¶**ï¼š3-5åˆ†é’Ÿ
- **æˆåŠŸç‡**ï¼š>95%ï¼ˆå¤šå±‚é‡è¯•ä¿éšœï¼‰
- **è¯„çº§ä½“ç³»**ï¼šT0å“è¶Š / T1å¨´ç†Ÿ / T2èƒœä»» / T3å¾…åŸ¹å…» / T4å·®è·è¾ƒå¤§

---

**æ ¸å¿ƒåŸåˆ™**ï¼šè‡ªé€‚åº”ç»´åº¦æŠ½å– + é€é¡¹ç‹¬ç«‹è¯„ä¼° + åŒè§†è§’æŠ¥å‘Š + å¤šæ¨¡æ€å¢å¼º
```

```markdown
# AIé¢è¯•è¯„ä¼°æŠ¥å‘Šç³»ç»Ÿè§„èŒƒï¼ˆåŸºäºGoldenä»£ç ï¼‰

## ğŸ¯ æ ¸å¿ƒæ€è·¯

**å¤šæ­¥éª¤æ·±åº¦åˆ†æ**ï¼šè‡ªé€‚åº”æŠ½å–è€ƒæ ¸ç»´åº¦ â†’ é€é¡¹æ‰“åˆ†è¯„ä¼° â†’ å²—ä½é€‚é…åº¦åˆ†æ â†’ æ€§æ ¼æ·±åº¦åˆ†æ â†’ èŒä¸šå‘å±•è§„åˆ’ â†’ è–ªé…¬å¸‚åœºè¯„ä¼° â†’ ç»¼åˆæ€»ç»“æŠ¥å‘Š â†’ å¤šæ¨¡æ€é£æ ¼åˆ†æ â†’ å€™é€‰äººåé¦ˆ

## ğŸ“‹ æ ¸å¿ƒåŠŸèƒ½

### è¾“å…¥
- é¢è¯•å¯¹è¯è®°å½•ï¼ˆtranscriptï¼‰
- å²—ä½æè¿°ï¼ˆJDï¼‰
- è§†é¢‘/å›¾ç‰‡URLï¼ˆurl_listï¼‰
- é¢è¯•è¯­è¨€ï¼ˆinterview_languageï¼‰

### è¾“å‡º
- **HRè§†è§’**ï¼šç»¼åˆè¯„åˆ†ã€äº®ç‚¹ã€é£é™©ã€è¯„çº§ï¼ˆT0~T4ï¼‰
- **å€™é€‰äººè§†è§’**ï¼šä¼˜åŠ¿ã€ä¸è¶³ã€çŸ­æœŸ/é•¿æœŸæ”¹è¿›å»ºè®®
- **å²—ä½é€‚é…åº¦**ï¼šå½“å‰å²—ä½åŒ¹é…åˆ†å€¼ã€èƒ½åŠ›å·®è·åˆ†æ
- **èŒä¸šå‘å±•**ï¼šæ¨ªå‘/çºµå‘å²—ä½æ¨è + æ¨èç™¾åˆ†æ¯” + æ¨èç†ç”±
- **æ€§æ ¼åˆ†æ**ï¼šå²—ä½æ€§æ ¼è¦æ±‚ã€å€™é€‰äººæ€§æ ¼ç‰¹å¾ã€å…·è±¡åŒ–å¡‘é€ å»ºè®®
- **è–ªé…¬è¯„ä¼°**ï¼šå¸‚åœºè¡Œæƒ…åˆ†æã€ä¸åŒè§„æ¨¡ä¼ä¸šè–ªé…¬èŒƒå›´ã€å€™é€‰äººå½“å‰è–ªé…¬è¯„ä¼°ã€è–ªé…¬æå‡è·¯å¾„
- **é¢„æœŸç®¡ç†**ï¼šè¯†åˆ«ä¸åˆç†é¢„æœŸã€æ¨èåˆé€‚èµ·å§‹å²—ä½çº§åˆ«ã€ç‰¹å®šè–ªèµ„æ‰€éœ€ç»éªŒå¹´é™
- **æˆé•¿å»ºè®®**ï¼šå¿ƒæ€å»ºè®¾ã€å¿…å¤‡æŠ€èƒ½æ¸…å•ã€ä¸åŒä¼ä¸šè§„æ¨¡è¦æ±‚åˆ†æã€å­¦ä¹ æå‡æ–¹å‘
- **å¤šæ¨¡æ€**ï¼šé£æ ¼æ ‡ç­¾ã€å½¢è±¡è¯„åˆ†ã€è¡Œä¸ºæ£€æµ‹

### å¤„ç†æ–¹å¼
- **7+Næ¬¡AIè°ƒç”¨**ï¼ˆN=è€ƒæ ¸ç»´åº¦æ•°é‡ï¼Œé€šå¸¸5-10ä¸ªï¼‰
- è‡ªé€‚åº”æŠ½å–ç»´åº¦ï¼Œé€é¡¹ç‹¬ç«‹è¯„åˆ†
- å²—ä½é€‚é…åº¦åˆ†æ + èŒä¸šå‘å±•è§„åˆ’ï¼ˆ1æ¬¡AIè°ƒç”¨ï¼‰
- æ€§æ ¼æ·±åº¦åˆ†æï¼ˆ1æ¬¡AIè°ƒç”¨ï¼‰
- è–ªé…¬å¸‚åœºè¯„ä¼°ï¼ˆ1æ¬¡AIè°ƒç”¨ï¼Œä½¿ç”¨Qwenè”ç½‘æœç´¢èƒ½åŠ›ï¼‰
- é¢„æœŸç®¡ç†åˆ†æï¼ˆèå…¥è–ªé…¬è¯„ä¼°ä¸­ï¼‰
- å¤šæ¨¡æ€åˆ†æï¼ˆæ”¯æŒè§†é¢‘/å›¾ç‰‡ï¼‰

## ğŸ’» æ ¸å¿ƒå®ç°

### æ–‡ä»¶ç»“æ„
```
service/
â”œâ”€â”€ AIInterviewAssessor.py    # æ ¸å¿ƒæœåŠ¡ï¼ˆ327è¡Œï¼‰
â””â”€â”€ multimodal_report.py       # å¤šæ¨¡æ€åˆ†æï¼ˆ100è¡Œï¼‰
routers/
â””â”€â”€ interview_report_router.py # APIè·¯ç”±ï¼ˆ97è¡Œï¼‰
```

### æ ¸å¿ƒæµç¨‹ï¼ˆ5æ­¥ï¼‰
```python
def generate_report(transcript, jd, interview_id, url_list, is_mp4, language):
    # æ­¥éª¤1: æŠ½å–è€ƒæ ¸ç»´åº¦ (1æ¬¡AIè°ƒç”¨)
    competencies = _extract_competencies(jd, transcript)
    # è¾“å‡º: {hard_skills: [...], soft_skills: [...], cultural_fit: [...]}
    
    # æ­¥éª¤2: é€é¡¹èƒ½åŠ›è¯„ä¼° (Næ¬¡AIè°ƒç”¨)
    for competency in all_competency_keys:
        result = _analyze_single_competency(competency, transcript)
        # è¾“å‡º: {score: 85, rationale: "...", evidence_quotes: [...]}
    
    # æ­¥éª¤3: ç”ŸæˆHRæ€»ç»“ (1æ¬¡AIè°ƒç”¨)
    summary = _generate_final_summary(detailed_analysis)
    # è¾“å‡º: {highlights: "...", risks: "...", conclusion: "T2-èƒœä»»..."}
    
    # æ­¥éª¤4: å¤šæ¨¡æ€åˆ†æ (1æ¬¡AIè°ƒç”¨, qwen-vl-max-latest)
    style = style_report(url_list, interview_id, is_mp4, language)
    # è¾“å‡º: {style: "èŒä¸šå¹²ç»ƒ", description: "...", appearance: "82åˆ†..."}
    
    # æ­¥éª¤5: ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š (1æ¬¡AIè°ƒç”¨)
    user_report = _user_report(jd, transcript, hr_report)
    # è¾“å‡º: {highlights, insufficient, short_term_actions, long_term_actions, ...}
    
    # èšåˆæœ€ç»ˆæŠ¥å‘Š â†’ å­˜å…¥æ•°æ®åº“
    return final_report
```

## ğŸŒ APIæ¥å£

**POST** `/interviewReport`

### è¯·æ±‚
```json
{
  "interview_id": "123456",
  "transcript": [
    {"role": "interviewer", "content": "ä»‹ç»ä½ çš„Pythonç»éªŒ", "timestamp": 1},
    {"role": "candidate", "content": "æˆ‘æœ‰3å¹´Pythonå¼€å‘ç»éªŒ...", "timestamp": 2}
  ],
  "jd": "å²—ä½èŒè´£ï¼š\n1. åç«¯å¼€å‘\nä»»èŒè¦æ±‚ï¼š\n1. 3å¹´Pythonç»éªŒ",
  "interview_language": "zhongwen",
  "p_url": ["http://example.com/img1.png"],  // å›¾ç‰‡URL
  "v_url": ["http://example.com/video.mp4"]   // è§†é¢‘URL
}
```

### å“åº”ï¼ˆç«‹å³è¿”å›ï¼Œåå°å¼‚æ­¥ç”Ÿæˆï¼‰
```json
{
  "code": 0,
  "message": "success",
  "data": ""
}
```

### æœ€ç»ˆæŠ¥å‘Šç»“æ„ï¼ˆå­˜å…¥æ•°æ®åº“ï¼‰
```json
{
  "overall_assessment": {
    "match_score": 78.5,
    "conclusion": "T2-èƒœä»»ï¼Œå®šä¹‰ï¼šç¬¦åˆé¢„æœŸã€‚å»ºè®®å½•ç”¨ã€‚",
    "highlights": "æŠ€æœ¯åŸºç¡€æ‰å®ï¼Œæ²Ÿé€šæ¸…æ™°",
    "potential_risks": "ç¼ºä¹æ¶æ„ç»éªŒ"
  },
  "detailed_analysis": [
    {
      "competency": "Pythonå¼€å‘èƒ½åŠ›",
      "score": 85,
      "rationale": "æ‰å®çš„å¼€å‘åŸºç¡€ï¼Œç†Ÿæ‚‰Djangoæ¡†æ¶",
      "evidence_quotes": ["æˆ‘ä¸»å¯¼äº†è®¢å•ç³»ç»Ÿå¼€å‘", "æ—¥å‡100ä¸‡è¯·æ±‚é‡"]
    }
  ],
  "competency_model_used": {
    "hard_skills": ["Pythonå¼€å‘", "æ•°æ®åº“è®¾è®¡"],
    "soft_skills": ["æ²Ÿé€šèƒ½åŠ›"],
    "cultural_fit": ["å­¦ä¹ æ€åº¦"]
  },
  "style_report": {
    "style": "èŒä¸šå¹²ç»ƒ",
    "description": "çœ¼ç¥è‡ªä¿¡ï¼Œç€è£…å¾—ä½“",
    "behavior": "æœªå‘ç°å¼‚å¸¸",
    "appearance": "82åˆ†ã€‚äº”å®˜ç«¯æ­£ï¼Œæ­£è£…æ•´æ´"
  },
  "user_report": {
    "highlights": "ä½ çš„æŠ€æœ¯è¡¨è¾¾æ¸…æ™°...",
    "insufficient": "æ¶æ„è®¾è®¡å¯ä»¥æ›´æœ‰æ¡ç†...",
    "short_term_actions": ["æ¯å¤©ç»ƒä¹ 1ä¸ªç®—æ³•é¢˜", "å‡†å¤‡3ä¸ªSTARè¯æœ¯"],
    "long_term_actions": ["å­¦ä¹ åˆ†å¸ƒå¼ç³»ç»Ÿ", "å‚ä¸å¼€æºé¡¹ç›®"],
    "Quantitative": "æ¯å‘¨2æ¬¡æ¨¡æ‹Ÿé¢è¯•ï¼Œè®°å½•æ”¹è¿›ç‚¹",
    "career_advice": "å‘é«˜çº§å·¥ç¨‹å¸ˆå‘å±•ï¼Œè¡¥å……æ¶æ„èƒ½åŠ›",
    "other": "ä¿æŒå­¦ä¹ èŠ‚å¥ï¼Œ3å¹´å†…å¯æˆé•¿ä¸ºæ¶æ„å¸ˆ"
  }
}
```

## ğŸ”§ æŠ€æœ¯ç»†èŠ‚

### LLMé…ç½®
```python
# æ–‡æœ¬åˆ†ææ¨¡å‹
model = "qwen-plus"
temperature = 0.3
seed = 6
response_format = {"type": "json_object"}

# å¤šæ¨¡æ€æ¨¡å‹
multimodal_model = "qwen-vl-max-latest"
```

### é‡è¦æœºåˆ¶
- **é‡è¯•æœºåˆ¶**ï¼šå…³é”®AIè°ƒç”¨å¤±è´¥è‡ªåŠ¨é‡è¯•1æ¬¡
- **å¤šæ¨¡æ€ä¿åº•**ï¼šè§†é¢‘åˆ†æå¤±è´¥é™çº§ä¸ºæ–‡æœ¬åˆ†æ
- **å¼‚æ­¥å¤„ç†**ï¼šFastAPI BackgroundTasksåå°ç”Ÿæˆ
- **é˜²é‡å¤**ï¼š10åˆ†é’Ÿå†…åŒinterview_idä¸é‡å¤ç”Ÿæˆ

### æ”¯æŒçš„è¯­è¨€
zhongwenã€yingwenã€riyuã€hanyuã€xibanyayuã€yinniyuã€fayuã€deyuã€taiyu

## ğŸ“Š å…³é”®æŒ‡æ ‡

- **AIè°ƒç”¨æ¬¡æ•°**ï¼šé€šå¸¸8-15æ¬¡ï¼ˆ3å›ºå®š + 5-10ç»´åº¦è¯„ä¼°ï¼‰
- **ç”Ÿæˆè€—æ—¶**ï¼š3-5åˆ†é’Ÿ
- **æˆåŠŸç‡**ï¼š>95%ï¼ˆå¤šå±‚é‡è¯•ä¿éšœï¼‰
- **è¯„çº§ä½“ç³»**ï¼šT0å“è¶Š / T1å¨´ç†Ÿ / T2èƒœä»» / T3å¾…åŸ¹å…» / T4å·®è·è¾ƒå¤§

---

**æ ¸å¿ƒåŸåˆ™**ï¼šè‡ªé€‚åº”ç»´åº¦æŠ½å– + é€é¡¹ç‹¬ç«‹è¯„ä¼° + åŒè§†è§’æŠ¥å‘Š + å¤šæ¨¡æ€å¢å¼º
```

```markdown
# AIé¢è¯•è¯„ä¼°æŠ¥å‘Šç³»ç»Ÿè§„èŒƒï¼ˆåŸºäºGoldenä»£ç ï¼‰

## ğŸ¯ æ ¸å¿ƒæ€è·¯

**å¤šæ­¥éª¤æ·±åº¦åˆ†æ**ï¼šè‡ªé€‚åº”æŠ½å–è€ƒæ ¸ç»´åº¦ â†’ é€é¡¹æ‰“åˆ†è¯„ä¼° â†’ å²—ä½é€‚é…åº¦åˆ†æ â†’ æ€§æ ¼æ·±åº¦åˆ†æ â†’ èŒä¸šå‘å±•è§„åˆ’ â†’ è–ªé…¬å¸‚åœºè¯„ä¼° â†’ ç»¼åˆæ€»ç»“æŠ¥å‘Š â†’ å¤šæ¨¡æ€é£æ ¼åˆ†æ â†’ å€™é€‰äººåé¦ˆ

## ğŸ“‹ æ ¸å¿ƒåŠŸèƒ½

### è¾“å…¥
- é¢è¯•å¯¹è¯è®°å½•ï¼ˆtranscriptï¼‰
- å²—ä½æè¿°ï¼ˆJDï¼‰
- è§†é¢‘/å›¾ç‰‡URLï¼ˆurl_listï¼‰
- é¢è¯•è¯­è¨€ï¼ˆinterview_languageï¼‰

### è¾“å‡º
- **HRè§†è§’**ï¼šç»¼åˆè¯„åˆ†ã€äº®ç‚¹ã€é£é™©ã€è¯„çº§ï¼ˆT0~T4ï¼‰
- **å€™é€‰äººè§†è§’**ï¼šä¼˜åŠ¿ã€ä¸è¶³ã€çŸ­æœŸ/é•¿æœŸæ”¹è¿›å»ºè®®
- **å²—ä½é€‚é…åº¦**ï¼šå½“å‰å²—ä½åŒ¹é…åˆ†å€¼ã€èƒ½åŠ›å·®è·åˆ†æ
- **èŒä¸šå‘å±•**ï¼šæ¨ªå‘/çºµå‘å²—ä½æ¨è + æ¨èç™¾åˆ†æ¯” + æ¨èç†ç”±
- **æ€§æ ¼åˆ†æ**ï¼šå²—ä½æ€§æ ¼è¦æ±‚ã€å€™é€‰äººæ€§æ ¼ç‰¹å¾ã€å…·è±¡åŒ–å¡‘é€ å»ºè®®
- **è–ªé…¬è¯„ä¼°**ï¼šå¸‚åœºè¡Œæƒ…åˆ†æã€ä¸åŒè§„æ¨¡ä¼ä¸šè–ªé…¬èŒƒå›´ã€å€™é€‰äººå½“å‰è–ªé…¬è¯„ä¼°ã€è–ªé…¬æå‡è·¯å¾„
- **é¢„æœŸç®¡ç†**ï¼šè¯†åˆ«ä¸åˆç†é¢„æœŸã€æ¨èåˆé€‚èµ·å§‹å²—ä½çº§åˆ«ã€ç‰¹å®šè–ªèµ„æ‰€éœ€ç»éªŒå¹´é™
- **æˆé•¿å»ºè®®**ï¼šå¿ƒæ€å»ºè®¾ã€å¿…å¤‡æŠ€èƒ½æ¸…å•ã€ä¸åŒä¼ä¸šè§„æ¨¡è¦æ±‚åˆ†æã€å­¦ä¹ æå‡æ–¹å‘
- **å¤šæ¨¡æ€**ï¼šé£æ ¼æ ‡ç­¾ã€å½¢è±¡è¯„åˆ†ã€è¡Œä¸ºæ£€æµ‹

### å¤„ç†æ–¹å¼
- **7+Næ¬¡AIè°ƒç”¨**ï¼ˆN=è€ƒæ ¸ç»´åº¦æ•°é‡ï¼Œé€šå¸¸5-10ä¸ªï¼‰
- è‡ªé€‚åº”æŠ½å–ç»´åº¦ï¼Œé€é¡¹ç‹¬ç«‹è¯„åˆ†
- å²—ä½é€‚é…åº¦åˆ†æ + èŒä¸šå‘å±•è§„åˆ’ï¼ˆ1æ¬¡AIè°ƒç”¨ï¼‰
- æ€§æ ¼æ·±åº¦åˆ†æï¼ˆ1æ¬¡AIè°ƒç”¨ï¼‰
- è–ªé…¬å¸‚åœºè¯„ä¼°ï¼ˆ1æ¬¡AIè°ƒç”¨ï¼Œä½¿ç”¨Qwenè”ç½‘æœç´¢èƒ½åŠ›ï¼‰
- é¢„æœŸç®¡ç†åˆ†æï¼ˆèå…¥è–ªé…¬è¯„ä¼°ä¸­ï¼‰
- å¤šæ¨¡æ€åˆ†æï¼ˆæ”¯æŒè§†é¢‘/å›¾ç‰‡ï¼‰

## ğŸ’» æ ¸å¿ƒå®ç°

### æ–‡ä»¶ç»“æ„
```
service/
â”œâ”€â”€ AIInterviewAssessor.py    # æ ¸å¿ƒæœåŠ¡ï¼ˆ327è¡Œï¼‰
â””â”€â”€ multimodal_report.py       # å¤šæ¨¡æ€åˆ†æï¼ˆ100è¡Œï¼‰
routers/
â””â”€â”€ interview_report_router.py # APIè·¯ç”±ï¼ˆ97è¡Œï¼‰
```

### æ ¸å¿ƒæµç¨‹ï¼ˆ9æ­¥ï¼‰
```python
def generate_report(transcript, jd, interview_id, url_list, is_mp4, language):
    # æ­¥éª¤1: æŠ½å–è€ƒæ ¸ç»´åº¦ (1æ¬¡AIè°ƒç”¨)
    competencies = _extract_competencies(jd, transcript)
    # è¾“å‡º: {hard_skills: [...], soft_skills: [...], cultural_fit: [...]}
    
    # æ­¥éª¤2: é€é¡¹èƒ½åŠ›è¯„ä¼° (Næ¬¡AIè°ƒç”¨)
    for competency in all_competency_keys:
        result = _analyze_single_competency(competency, transcript)
        # è¾“å‡º: {score: 85, rationale: "...", evidence_quotes: [...]}
    
    # æ­¥éª¤3: å²—ä½é€‚é…åº¦åˆ†æ + èŒä¸šå‘å±•è§„åˆ’ (1æ¬¡AIè°ƒç”¨)
    job_match = _analyze_job_match_and_career(detailed_analysis, jd, transcript)
    # è¾“å‡º: {
    #   current_job_match_score: 78.5,
    #   capability_gaps: {hard_skills: [...], soft_skills: [...]},
    #   alternative_jobs: [
    #     {type: "æ¨ªå‘", job_title: "...", match_percentage: 85, reason: "..."},
    #     {type: "çºµå‘", job_title: "...", match_percentage: 70, reason: "..."}
    #   ]
    # }
    
    # æ­¥éª¤4: æ€§æ ¼æ·±åº¦åˆ†æ (1æ¬¡AIè°ƒç”¨)
    personality = _analyze_personality(jd, transcript)
    # è¾“å‡º: {
    #   job_personality_requirements: "...",
    #   candidate_personality_traits: "...",
    #   concrete_shaping_suggestions: [...]
    # }
    
    # æ­¥éª¤5: è–ªé…¬å¸‚åœºè¯„ä¼° (1æ¬¡AIè°ƒç”¨ï¼Œå¯ç”¨è”ç½‘æœç´¢)
    salary = _analyze_salary_market(jd, transcript, detailed_analysis)
    # è¾“å‡º: {
    #   market_analysis: "...",
    #   salary_ranges: {
    #     fortune_500: "20-30K",
    #     mid_size: "15-25K",
    #     startup: "12-20K"
    #   },
    #   candidate_salary_assessment: "18-22K",
    #   salary_growth_path: "...",
    #   expectation_management: {
    #     is_expectation_reasonable: true/false,
    #     recommended_starting_level: "...",
    #     experience_required_for_target_salary: "..."
    #   }
    # }
    
    # æ­¥éª¤6: ç”ŸæˆHRæ€»ç»“ (1æ¬¡AIè°ƒç”¨)
    summary = _generate_final_summary(detailed_analysis, job_match, personality, salary)
    # è¾“å‡º: {highlights: "...", risks: "...", conclusion: "T2-èƒœä»»..."}
    
    # æ­¥éª¤7: å¤šæ¨¡æ€åˆ†æ (1æ¬¡AIè°ƒç”¨, qwen-vl-max-latest)
    style = style_report(url_list, interview_id, is_mp4, language)
    # è¾“å‡º: {style: "èŒä¸šå¹²ç»ƒ", description: "...", appearance: "82åˆ†..."}
    
    # æ­¥éª¤8: ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š (1æ¬¡AIè°ƒç”¨)
    user_report = _user_report(jd, transcript, hr_report, personality, salary)
    # è¾“å‡º: {
    #   highlights, insufficient, 
    #   short_term_actions, long_term_actions,
    #   mindset_building: "...",
    #   essential_skills_checklist: [...],
    #   company_size_requirements: {...},
    #   learning_directions: [...]
    # }
    
    # æ­¥éª¤9: èšåˆæœ€ç»ˆæŠ¥å‘Š â†’ å­˜å…¥æ•°æ®åº“
    return final_report
```

## ğŸŒ APIæ¥å£

**POST** `/interviewReport`

### è¯·æ±‚
```json
{
  "interview_id": "123456",
  "transcript": [
    {"role": "interviewer", "content": "ä»‹ç»ä½ çš„Pythonç»éªŒ", "timestamp": 1},
    {"role": "candidate", "content": "æˆ‘æœ‰3å¹´Pythonå¼€å‘ç»éªŒ...", "timestamp": 2}
  ],
  "jd": "å²—ä½èŒè´£ï¼š\n1. åç«¯å¼€å‘\nä»»èŒè¦æ±‚ï¼š\n1. 3å¹´Pythonç»éªŒ",
  "interview_language": "zhongwen",
  "p_url": ["http://example.com/img1.png"],  // å›¾ç‰‡URL
  "v_url": ["http://example.com/video.mp4"]   // è§†é¢‘URL
}
```

### å“åº”ï¼ˆç«‹å³è¿”å›ï¼Œåå°å¼‚æ­¥ç”Ÿæˆï¼‰
```json
{
  "code": 0,
  "message": "success",
  "data": ""
}
```

### æœ€ç»ˆæŠ¥å‘Šç»“æ„ï¼ˆå­˜å…¥æ•°æ®åº“ï¼‰
```json
{
  "overall_assessment": {
    "match_score": 78.5,
    "conclusion": "T2-èƒœä»»ï¼Œå®šä¹‰ï¼šç¬¦åˆé¢„æœŸã€‚å»ºè®®å½•ç”¨ã€‚",
    "highlights": "æŠ€æœ¯åŸºç¡€æ‰å®ï¼Œæ²Ÿé€šæ¸…æ™°",
    "potential_risks": "ç¼ºä¹æ¶æ„ç»éªŒ"
  },
  "detailed_analysis": [
    {
      "competency": "Pythonå¼€å‘èƒ½åŠ›",
      "score": 85,
      "rationale": "æ‰å®çš„å¼€å‘åŸºç¡€ï¼Œç†Ÿæ‚‰Djangoæ¡†æ¶",
      "evidence_quotes": ["æˆ‘ä¸»å¯¼äº†è®¢å•ç³»ç»Ÿå¼€å‘", "æ—¥å‡100ä¸‡è¯·æ±‚é‡"]
    }
  ],
  "competency_model_used": {
    "hard_skills": ["Pythonå¼€å‘", "æ•°æ®åº“è®¾è®¡"],
    "soft_skills": ["æ²Ÿé€šèƒ½åŠ›"],
    "cultural_fit": ["å­¦ä¹ æ€åº¦"]
  },
  "style_report": {
    "style": "èŒä¸šå¹²ç»ƒ",
    "description": "çœ¼ç¥è‡ªä¿¡ï¼Œç€è£…å¾—ä½“",
    "behavior": "æœªå‘ç°å¼‚å¸¸",
    "appearance": "82åˆ†ã€‚äº”å®˜ç«¯æ­£ï¼Œæ­£è£…æ•´æ´"
  },
  "user_report": {
    "highlights": "ä½ çš„æŠ€æœ¯è¡¨è¾¾æ¸…æ™°...",
    "insufficient": "æ¶æ„è®¾è®¡å¯ä»¥æ›´æœ‰æ¡ç†...",
    "short_term_actions": ["æ¯å¤©ç»ƒä¹ 1ä¸ªç®—æ³•é¢˜", "å‡†å¤‡3ä¸ªSTARè¯æœ¯"],
    "long_term_actions": ["å­¦ä¹ åˆ†å¸ƒå¼ç³»ç»Ÿ", "å‚ä¸å¼€æºé¡¹ç›®"],
    "Quantitative": "æ¯å‘¨2æ¬¡æ¨¡æ‹Ÿé¢è¯•ï¼Œè®°å½•æ”¹è¿›ç‚¹",
    "career_advice": "å‘é«˜çº§å·¥ç¨‹å¸ˆå‘å±•ï¼Œè¡¥å……æ¶æ„èƒ½åŠ›",
    "other": "ä¿æŒå­¦ä¹ èŠ‚å¥ï¼Œ3å¹´å†…å¯æˆé•¿ä¸ºæ¶æ„å¸ˆ"
  }
}
```

## ğŸ”§ æŠ€æœ¯ç»†èŠ‚

### LLMé…ç½®
```python
# æ–‡æœ¬åˆ†ææ¨¡å‹
model = "qwen-plus"
temperature = 0.3
seed = 6
response_format = {"type": "json_object"}

# å¤šæ¨¡æ€æ¨¡å‹
multimodal_model = "qwen-vl-max-latest"
```

### é‡è¦æœºåˆ¶
- **é‡è¯•æœºåˆ¶**ï¼šå…³é”®AIè°ƒç”¨å¤±è´¥è‡ªåŠ¨é‡è¯•1æ¬¡
- **å¤šæ¨¡æ€ä¿åº•**ï¼šè§†é¢‘åˆ†æå¤±è´¥é™çº§ä¸ºæ–‡æœ¬åˆ†æ
- **å¼‚æ­¥å¤„ç†**ï¼šFastAPI BackgroundTasksåå°ç”Ÿæˆ
- **é˜²é‡å¤**ï¼š10åˆ†é’Ÿå†…åŒinterview_idä¸é‡å¤ç”Ÿæˆ

### æ”¯æŒçš„è¯­è¨€
zhongwenã€yingwenã€riyuã€hanyuã€xibanyayuã€yinniyuã€fayuã€deyuã€taiyu

## ğŸ“Š å…³é”®æŒ‡æ ‡

- **AIè°ƒç”¨æ¬¡æ•°**ï¼šé€šå¸¸8-15æ¬¡ï¼ˆ3å›ºå®š + 5-10ç»´åº¦è¯„ä¼°ï¼‰
- **ç”Ÿæˆè€—æ—¶**ï¼š3-5åˆ†é’Ÿ
- **æˆåŠŸç‡**ï¼š>95%ï¼ˆå¤šå±‚é‡è¯•ä¿éšœï¼‰
- **è¯„çº§ä½“ç³»**ï¼šT0å“è¶Š / T1å¨´ç†Ÿ / T2èƒœä»» / T3å¾…åŸ¹å…» / T4å·®è·è¾ƒå¤§

---

**æ ¸å¿ƒåŸåˆ™**ï¼šè‡ªé€‚åº”ç»´åº¦æŠ½å– + é€é¡¹ç‹¬ç«‹è¯„ä¼° + åŒè§†è§’æŠ¥å‘Š + å¤šæ¨¡æ€å¢å¼º
```

```markdown
# AIé¢è¯•è¯„ä¼°æŠ¥å‘Šç³»ç»Ÿè§„èŒƒï¼ˆåŸºäºGoldenä»£ç ï¼‰

## ğŸ¯ æ ¸å¿ƒæ€è·¯

**å¤šæ­¥éª¤æ·±åº¦åˆ†æ**ï¼šè‡ªé€‚åº”æŠ½å–è€ƒæ ¸ç»´åº¦ â†’ é€é¡¹æ‰“åˆ†è¯„ä¼° â†’ å²—ä½é€‚é…åº¦åˆ†æ â†’ æ€§æ ¼æ·±åº¦åˆ†æ â†’ èŒä¸šå‘å±•è§„åˆ’ â†’ è–ªé…¬å¸‚åœºè¯„ä¼° â†’ ç»¼åˆæ€»ç»“æŠ¥å‘Š â†’ å¤šæ¨¡æ€é£æ ¼åˆ†æ â†’ å€™é€‰äººåé¦ˆ

## ğŸ“‹ æ ¸å¿ƒåŠŸèƒ½

### è¾“å…¥
- é¢è¯•å¯¹è¯è®°å½•ï¼ˆtranscriptï¼‰
- å²—ä½æè¿°ï¼ˆJDï¼‰
- è§†é¢‘/å›¾ç‰‡URLï¼ˆurl_listï¼‰
- é¢è¯•è¯­è¨€ï¼ˆinterview_languageï¼‰

### è¾“å‡º
- **HRè§†è§’**ï¼šç»¼åˆè¯„åˆ†ã€äº®ç‚¹ã€é£é™©ã€è¯„çº§ï¼ˆT0~T4ï¼‰
- **å€™é€‰äººè§†è§’**ï¼šä¼˜åŠ¿ã€ä¸è¶³ã€çŸ­æœŸ/é•¿æœŸæ”¹è¿›å»ºè®®
- **å²—ä½é€‚é…åº¦**ï¼šå½“å‰å²—ä½åŒ¹é…åˆ†å€¼ã€èƒ½åŠ›å·®è·åˆ†æ
- **èŒä¸šå‘å±•**ï¼šæ¨ªå‘/çºµå‘å²—ä½æ¨è + æ¨èç™¾åˆ†æ¯” + æ¨èç†ç”±
- **æ€§æ ¼åˆ†æ**ï¼šå²—ä½æ€§æ ¼è¦æ±‚ã€å€™é€‰äººæ€§æ ¼ç‰¹å¾ã€å…·è±¡åŒ–å¡‘é€ å»ºè®®
- **è–ªé…¬è¯„ä¼°**ï¼šå¸‚åœºè¡Œæƒ…åˆ†æã€ä¸åŒè§„æ¨¡ä¼ä¸šè–ªé…¬èŒƒå›´ã€å€™é€‰äººå½“å‰è–ªé…¬è¯„ä¼°ã€è–ªé…¬æå‡è·¯å¾„
- **é¢„æœŸç®¡ç†**ï¼šè¯†åˆ«ä¸åˆç†é¢„æœŸã€æ¨èåˆé€‚èµ·å§‹å²—ä½çº§åˆ«ã€ç‰¹å®šè–ªèµ„æ‰€éœ€ç»éªŒå¹´é™
- **æˆé•¿å»ºè®®**ï¼šå¿ƒæ€å»ºè®¾ã€å¿…å¤‡æŠ€èƒ½æ¸…å•ã€ä¸åŒä¼ä¸šè§„æ¨¡è¦æ±‚åˆ†æã€å­¦ä¹ æå‡æ–¹å‘
- **å¤šæ¨¡æ€**ï¼šé£æ ¼æ ‡ç­¾ã€å½¢è±¡è¯„åˆ†ã€è¡Œä¸ºæ£€æµ‹

### å¤„ç†æ–¹å¼
- **7+Næ¬¡AIè°ƒç”¨**ï¼ˆN=è€ƒæ ¸ç»´åº¦æ•°é‡ï¼Œé€šå¸¸5-10ä¸ªï¼‰
- è‡ªé€‚åº”æŠ½å–ç»´åº¦ï¼Œé€é¡¹ç‹¬ç«‹è¯„åˆ†
- å²—ä½é€‚é…åº¦åˆ†æ + èŒä¸šå‘å±•è§„åˆ’ï¼ˆ1æ¬¡AIè°ƒç”¨ï¼‰
- æ€§æ ¼æ·±åº¦åˆ†æï¼ˆ1æ¬¡AIè°ƒç”¨ï¼‰
- è–ªé…¬å¸‚åœºè¯„ä¼°ï¼ˆ1æ¬¡AIè°ƒç”¨ï¼Œä½¿ç”¨Qwenè”ç½‘æœç´¢èƒ½åŠ›ï¼‰
- é¢„æœŸç®¡ç†åˆ†æï¼ˆèå…¥è–ªé…¬è¯„ä¼°ä¸­ï¼‰
- å¤šæ¨¡æ€åˆ†æï¼ˆæ”¯æŒè§†é¢‘/å›¾ç‰‡ï¼‰

## ğŸ’» æ ¸å¿ƒå®ç°

### æ–‡ä»¶ç»“æ„
```
service/
â”œâ”€â”€ AIInterviewAssessor.py    # æ ¸å¿ƒæœåŠ¡ï¼ˆ327è¡Œï¼‰
â””â”€â”€ multimodal_report.py       # å¤šæ¨¡æ€åˆ†æï¼ˆ100è¡Œï¼‰
routers/
â””â”€â”€ interview_report_router.py # APIè·¯ç”±ï¼ˆ97è¡Œï¼‰
```

### æ ¸å¿ƒæµç¨‹ï¼ˆ9æ­¥ï¼‰
```python
def generate_report(transcript, jd, interview_id, url_list, is_mp4, language):
    # æ­¥éª¤1: æŠ½å–è€ƒæ ¸ç»´åº¦ (1æ¬¡AIè°ƒç”¨)
    competencies = _extract_competencies(jd, transcript)
    # è¾“å‡º: {hard_skills: [...], soft_skills: [...], cultural_fit: [...]}
    
    # æ­¥éª¤2: é€é¡¹èƒ½åŠ›è¯„ä¼° (Næ¬¡AIè°ƒç”¨)
    for competency in all_competency_keys:
        result = _analyze_single_competency(competency, transcript)
        # è¾“å‡º: {score: 85, rationale: "...", evidence_quotes: [...]}
    
    # æ­¥éª¤3: å²—ä½é€‚é…åº¦åˆ†æ + èŒä¸šå‘å±•è§„åˆ’ (1æ¬¡AIè°ƒç”¨)
    job_match = _analyze_job_match_and_career(detailed_analysis, jd, transcript)
    # è¾“å‡º: {
    #   current_job_match_score: 78.5,
    #   capability_gaps: {hard_skills: [...], soft_skills: [...]},
    #   alternative_jobs: [
    #     {type: "æ¨ªå‘", job_title: "...", match_percentage: 85, reason: "..."},
    #     {type: "çºµå‘", job_title: "...", match_percentage: 70, reason: "..."}
    #   ]
    # }
    
    # æ­¥éª¤4: æ€§æ ¼æ·±åº¦åˆ†æ (1æ¬¡AIè°ƒç”¨)
    personality = _analyze_personality(jd, transcript)
    # è¾“å‡º: {
    #   job_personality_requirements: "...",
    #   candidate_personality_traits: "...",
    #   concrete_shaping_suggestions: [...]
    # }
    
    # æ­¥éª¤5: è–ªé…¬å¸‚åœºè¯„ä¼° (1æ¬¡AIè°ƒç”¨ï¼Œå¯ç”¨è”ç½‘æœç´¢)
    salary = _analyze_salary_market(jd, transcript, detailed_analysis)
    # è¾“å‡º: {
    #   market_analysis: "...",
    #   salary_ranges: {
    #     fortune_500: "20-30K",
    #     mid_size: "15-25K",
    #     startup: "12-20K"
    #   },
    #   candidate_salary_assessment: "18-22K",
    #   salary_growth_path: "...",
    #   expectation_management: {
    #     is_expectation_reasonable: true/false,
    #     recommended_starting_level: "...",
    #     experience_required_for_target_salary: "..."
    #   }
    # }
    
    # æ­¥éª¤6: ç”ŸæˆHRæ€»ç»“ (1æ¬¡AIè°ƒç”¨)
    summary = _generate_final_summary(detailed_analysis, job_match, personality, salary)
    # è¾“å‡º: {highlights: "...", risks: "...", conclusion: "T2-èƒœä»»..."}
    
    # æ­¥éª¤7: å¤šæ¨¡æ€åˆ†æ (1æ¬¡AIè°ƒç”¨, qwen-vl-max-latest)
    style = style_report(url_list, interview_id, is_mp4, language)
    # è¾“å‡º: {style: "èŒä¸šå¹²ç»ƒ", description: "...", appearance: "82åˆ†..."}
    
    # æ­¥éª¤8: ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š (1æ¬¡AIè°ƒç”¨)
    user_report = _user_report(jd, transcript, hr_report, personality, salary)
    # è¾“å‡º: {
    #   highlights, insufficient, 
    #   short_term_actions, long_term_actions,
    #   mindset_building: "...",
    #   essential_skills_checklist: [...],
    #   company_size_requirements: {...},
    #   learning_directions: [...]
    # }
    
    # æ­¥éª¤9: èšåˆæœ€ç»ˆæŠ¥å‘Š â†’ å­˜å…¥æ•°æ®åº“
    return final_report
```

## ğŸŒ APIæ¥å£

**POST** `/interviewReport`

### è¯·æ±‚
```json
{
  "interview_id": "123456",
  "transcript": [
    {"role": "interviewer", "content": "ä»‹ç»ä½ çš„Pythonç»éªŒ", "timestamp": 1},
    {"role": "candidate", "content": "æˆ‘æœ‰3å¹´Pythonå¼€å‘ç»éªŒ...", "timestamp": 2}
  ],
  "jd": "å²—ä½èŒè´£ï¼š\n1. åç«¯å¼€å‘\nä»»èŒè¦æ±‚ï¼š\n1. 3å¹´Pythonç»éªŒ",
  "interview_language": "zhongwen",
  "p_url": ["http://example.com/img1.png"],  // å›¾ç‰‡URL
  "v_url": ["http://example.com/video.mp4"]   // è§†é¢‘URL
}
```

### å“åº”ï¼ˆç«‹å³è¿”å›ï¼Œåå°å¼‚æ­¥ç”Ÿæˆï¼‰
```json
{
  "code": 0,
  "message": "success",
  "data": ""
}
```

### æœ€ç»ˆæŠ¥å‘Šç»“æ„ï¼ˆå­˜å…¥æ•°æ®åº“ï¼‰
```json
{
  "overall_assessment": {
    "match_score": 78.5,
    "conclusion": "T2-èƒœä»»ï¼Œå®šä¹‰ï¼šç¬¦åˆé¢„æœŸã€‚å»ºè®®å½•ç”¨ã€‚",
    "highlights": "æŠ€æœ¯åŸºç¡€æ‰å®ï¼Œæ²Ÿé€šæ¸…æ™°",
    "potential_risks": "ç¼ºä¹æ¶æ„ç»éªŒ"
  },
  "detailed_analysis": [
    {
      "competency": "Pythonå¼€å‘èƒ½åŠ›",
      "score": 85,
      "rationale": "æ‰å®çš„å¼€å‘åŸºç¡€ï¼Œç†Ÿæ‚‰Djangoæ¡†æ¶",
      "evidence_quotes": ["æˆ‘ä¸»å¯¼äº†è®¢å•ç³»ç»Ÿå¼€å‘", "æ—¥å‡100ä¸‡è¯·æ±‚é‡"]
    }
  ],
  "competency_model_used": {
    "hard_skills": ["Pythonå¼€å‘", "æ•°æ®åº“è®¾è®¡"],
    "soft_skills": ["æ²Ÿé€šèƒ½åŠ›"],
    "cultural_fit": ["å­¦ä¹ æ€åº¦"]
  },
  "job_match_analysis": {
    "current_job_match_score": 78.5,
    "capability_gaps": {
      "hard_skills": ["æ¶æ„è®¾è®¡ç»éªŒä¸è¶³", "å¾®æœåŠ¡å®æˆ˜ç»éªŒç¼ºä¹"],
      "soft_skills": ["å›¢é˜Ÿç®¡ç†ç»éªŒæœ‰é™"]
    },
    "alternative_jobs": [
      {
        "type": "æ¨ªå‘",
        "job_title": "å…¨æ ˆå¼€å‘å·¥ç¨‹å¸ˆ",
        "match_percentage": 85,
        "reason": "åç«¯èƒ½åŠ›æ‰å®ï¼Œè¡¥å……å‰ç«¯æŠ€èƒ½åå¯èƒœä»»å…¨æ ˆå²—ä½"
      },
      {
        "type": "çºµå‘",
        "job_title": "æŠ€æœ¯ä¸»ç®¡/Team Leader",
        "match_percentage": 65,
        "reason": "æŠ€æœ¯èƒ½åŠ›è¾¾æ ‡ï¼Œéœ€è¡¥å……å›¢é˜Ÿç®¡ç†å’Œæ¶æ„è®¾è®¡èƒ½åŠ›"
      }
    ]
  },
  "personality_analysis": {
    "job_personality_requirements": "è¯¥å²—ä½éœ€è¦è¾ƒå¼ºçš„é€»è¾‘æ€ç»´ã€é—®é¢˜è§£å†³èƒ½åŠ›ã€å›¢é˜Ÿåä½œç²¾ç¥å’ŒæŒç»­å­¦ä¹ æ„æ„¿",
    "candidate_personality_traits": "å€™é€‰äººå±•ç°å‡ºè¾ƒå¼ºçš„æŠ€æœ¯çƒ­æƒ…ã€è‰¯å¥½çš„è¡¨è¾¾èƒ½åŠ›ã€ç§¯æçš„å­¦ä¹ æ€åº¦ï¼Œæ€§æ ¼åå†…æ•›ä½†ä¸“ä¸šæ²Ÿé€šæ¸…æ™°",
    "concrete_shaping_suggestions": [
      "å¢å¼ºä¸»åŠ¨æ²Ÿé€šæ„è¯†ï¼Œåœ¨å›¢é˜Ÿä¸­å¤šåˆ†äº«æŠ€æœ¯è§è§£",
      "åŸ¹å…»å…¨å±€è§†è§’ï¼Œä»ä¸šåŠ¡è§’åº¦æ€è€ƒæŠ€æœ¯æ–¹æ¡ˆ",
      "æå‡æŠ—å‹èƒ½åŠ›ï¼Œåœ¨é«˜å‹ç¯å¢ƒä¸‹ä¿æŒå†·é™åˆ¤æ–­"
    ]
  },
  "salary_analysis": {
    "market_analysis": "æ ¹æ®2024å¹´å¸‚åœºæ•°æ®ï¼Œ3å¹´Pythonåç«¯å¼€å‘å·¥ç¨‹å¸ˆåœ¨ä¸€çº¿åŸå¸‚çš„è–ªèµ„åŒºé—´ä¸º15-30Kï¼Œå…·ä½“å–å†³äºå…¬å¸è§„æ¨¡ã€æŠ€æœ¯æ ˆæ·±åº¦å’Œé¡¹ç›®ç»éªŒ",
    "salary_ranges": {
      "fortune_500": "20-30Kï¼ˆå¤§å‚ï¼Œè¦æ±‚é«˜ï¼Œç¦åˆ©å¥½ï¼‰",
      "mid_size": "15-25Kï¼ˆä¸­å‹ä¼ä¸šï¼Œå¸‚åœºä¸»æµï¼‰",
      "startup": "12-22Kï¼ˆåˆ›ä¸šå…¬å¸ï¼Œè‚¡æƒæ¿€åŠ±ä¸ºä¸»ï¼‰"
    },
    "candidate_salary_assessment": "18-22K",
    "salary_growth_path": "1å¹´å†…é€šè¿‡è¡¥å……æ¶æ„èƒ½åŠ›è¾¾åˆ°22-28Kï¼›3å¹´å†…æ™‹å‡é«˜çº§å·¥ç¨‹å¸ˆå¯è¾¾30-40Kï¼›5å¹´å†…è½¬å‘æ¶æ„å¸ˆå¯è¾¾40-60K",
    "expectation_management": {
      "is_expectation_reasonable": true,
      "recommended_starting_level": "ä¸­çº§åç«¯å·¥ç¨‹å¸ˆï¼ˆ3-5å¹´ç»éªŒï¼‰",
      "experience_required_for_target_salary": "å¦‚æœŸæœ›25K+ï¼Œéœ€è¦5å¹´ä»¥ä¸Šç»éªŒæˆ–å…·å¤‡æ¶æ„è®¾è®¡èƒ½åŠ›"
    }
  },
  "style_report": {
    "style": "èŒä¸šå¹²ç»ƒ",
    "description": "çœ¼ç¥è‡ªä¿¡ï¼Œç€è£…å¾—ä½“",
    "behavior": "æœªå‘ç°å¼‚å¸¸",
    "appearance": "82åˆ†ã€‚äº”å®˜ç«¯æ­£ï¼Œæ­£è£…æ•´æ´"
  },
  "user_report": {
    "highlights": "ä½ çš„æŠ€æœ¯è¡¨è¾¾æ¸…æ™°ï¼ŒPythonåŸºç¡€æ‰å®ï¼Œé¡¹ç›®ç»éªŒä¸°å¯Œ...",
    "insufficient": "æ¶æ„è®¾è®¡å¯ä»¥æ›´æœ‰æ¡ç†ï¼Œå›¢é˜Ÿåä½œç»éªŒéœ€è¦åŠ å¼º...",
    "short_term_actions": ["æ¯å¤©ç»ƒä¹ 1ä¸ªç®—æ³•é¢˜", "å‡†å¤‡3ä¸ªSTARè¯æœ¯", "å­¦ä¹ ç³»ç»Ÿè®¾è®¡åŸºç¡€"],
    "long_term_actions": ["å­¦ä¹ åˆ†å¸ƒå¼ç³»ç»Ÿ", "å‚ä¸å¼€æºé¡¹ç›®", "åŸ¹å…»å›¢é˜Ÿç®¡ç†èƒ½åŠ›"],
    "mindset_building": "ä¿æŒæŠ€æœ¯çƒ­æƒ…çš„åŒæ—¶ï¼ŒåŸ¹å…»ä¸šåŠ¡æ€ç»´å’Œå…¨å±€è§†è§’ã€‚é¢è¯•æ˜¯åŒå‘é€‰æ‹©ï¼Œè‡ªä¿¡å±•ç°è‡ªå·±çš„åŒæ—¶ä¹Ÿè¦è¯„ä¼°å…¬å¸æ˜¯å¦é€‚åˆè‡ªå·±ã€‚",
    "essential_skills_checklist": [
      "Pythoné«˜çº§ç‰¹æ€§ï¼ˆè£…é¥°å™¨ã€å…ƒç±»ã€å¹¶å‘ï¼‰",
      "æ•°æ®åº“ä¼˜åŒ–ï¼ˆç´¢å¼•ã€æŸ¥è¯¢ä¼˜åŒ–ã€åˆ†åº“åˆ†è¡¨ï¼‰",
      "ç¼“å­˜ç­–ç•¥ï¼ˆRedisã€æœ¬åœ°ç¼“å­˜ï¼‰",
      "å¾®æœåŠ¡æ¶æ„ï¼ˆæœåŠ¡æ‹†åˆ†ã€APIè®¾è®¡ã€æœåŠ¡æ²»ç†ï¼‰",
      "ç³»ç»Ÿè®¾è®¡èƒ½åŠ›ï¼ˆé«˜å¹¶å‘ã€é«˜å¯ç”¨ã€å¯æ‰©å±•æ€§ï¼‰"
    ],
    "company_size_requirements": {
      "fortune_500": "è¦æ±‚ç®—æ³•ã€ç³»ç»Ÿè®¾è®¡æ·±åº¦ï¼Œæ³¨é‡æŠ€æœ¯å¹¿åº¦å’Œåä½œèƒ½åŠ›",
      "mid_size": "æ³¨é‡ä¸šåŠ¡å®ç°èƒ½åŠ›å’Œå¿«é€Ÿå­¦ä¹ èƒ½åŠ›ï¼Œè¦æ±‚ç›¸å¯¹å‡è¡¡",
      "startup": "å¼ºè°ƒå¿«é€Ÿäº¤ä»˜å’Œå¤šé¢æ‰‹èƒ½åŠ›ï¼Œå¯æ¥å—æŸäº›æ–¹é¢ç»éªŒä¸è¶³"
    },
    "learning_directions": [
      "æ·±åº¦æ–¹å‘ï¼šæ·±å…¥ç ”ç©¶é«˜æ€§èƒ½Pythonï¼ˆå¼‚æ­¥ç¼–ç¨‹ã€æ€§èƒ½ä¼˜åŒ–ï¼‰",
      "å¹¿åº¦æ–¹å‘ï¼šå­¦ä¹ å‰ç«¯åŸºç¡€ã€DevOpsã€äº‘åŸç”ŸæŠ€æœ¯",
      "è½¯æŠ€èƒ½æ–¹å‘ï¼šæŠ€æœ¯å†™ä½œã€æ¼”è®²è¡¨è¾¾ã€é¡¹ç›®ç®¡ç†"
    ],
    "Quantitative": "æ¯å‘¨2æ¬¡æ¨¡æ‹Ÿé¢è¯•ï¼Œæ¯æœˆå®Œæˆ1ä¸ªç³»ç»Ÿè®¾è®¡æ¡ˆä¾‹ï¼Œæ¯å­£åº¦è¾“å‡º1ç¯‡æŠ€æœ¯åšå®¢",
    "career_advice": "çŸ­æœŸï¼ˆ1å¹´å†…ï¼‰ï¼šå·©å›ºåç«¯åŸºç¡€ï¼Œè¡¥å……æ¶æ„èƒ½åŠ›ï¼Œäº‰å–æ™‹å‡ä¸­é«˜çº§å·¥ç¨‹å¸ˆã€‚ä¸­æœŸï¼ˆ3å¹´å†…ï¼‰ï¼šæ·±å…¥æŸä¸ªæŠ€æœ¯é¢†åŸŸï¼ˆå¦‚åˆ†å¸ƒå¼/é«˜å¹¶å‘ï¼‰ï¼ŒåŒæ—¶åŸ¹å…»å›¢é˜Ÿåä½œå’ŒæŠ€æœ¯å½±å“åŠ›ã€‚é•¿æœŸï¼ˆ5å¹´+ï¼‰ï¼šå‘æ¶æ„å¸ˆæˆ–æŠ€æœ¯ç®¡ç†æ–¹å‘å‘å±•ã€‚",
    "other": "ä¿æŒå­¦ä¹ èŠ‚å¥ï¼Œæ³¨é‡æŠ€æœ¯æ·±åº¦å’Œå¹¿åº¦çš„å¹³è¡¡ã€‚å»ºè®®åŠ å…¥æŠ€æœ¯ç¤¾åŒºï¼Œå¤šä¸è¡Œä¸šå†…äººå£«äº¤æµï¼Œæ‹“å±•è§†é‡ã€‚"
  }
}
```

## ğŸ”§ æŠ€æœ¯ç»†èŠ‚

### LLMé…ç½®
```python
# æ–‡æœ¬åˆ†ææ¨¡å‹
model = "qwen-plus"
temperature = 0.3
seed = 6
response_format = {"type": "json_object"}

# å¤šæ¨¡æ€æ¨¡å‹
multimodal_model = "qwen-vl-max-latest"
```

### é‡è¦æœºåˆ¶
- **é‡è¯•æœºåˆ¶**ï¼šå…³é”®AIè°ƒç”¨å¤±è´¥è‡ªåŠ¨é‡è¯•1æ¬¡
- **å¤šæ¨¡æ€ä¿åº•**ï¼šè§†é¢‘åˆ†æå¤±è´¥é™çº§ä¸ºæ–‡æœ¬åˆ†æ
- **å¼‚æ­¥å¤„ç†**ï¼šFastAPI BackgroundTasksåå°ç”Ÿæˆ
- **é˜²é‡å¤**ï¼š10åˆ†é’Ÿå†…åŒinterview_idä¸é‡å¤ç”Ÿæˆ

### æ”¯æŒçš„è¯­è¨€
zhongwenã€yingwenã€riyuã€hanyuã€xibanyayuã€yinniyuã€fayuã€deyuã€taiyu

## ğŸ“Š å…³é”®æŒ‡æ ‡

- **AIè°ƒç”¨æ¬¡æ•°**ï¼šé€šå¸¸8-15æ¬¡ï¼ˆ3å›ºå®š + 5-10ç»´åº¦è¯„ä¼°ï¼‰
- **ç”Ÿæˆè€—æ—¶**ï¼š3-5åˆ†é’Ÿ
- **æˆåŠŸç‡**ï¼š>95%ï¼ˆå¤šå±‚é‡è¯•ä¿éšœï¼‰
- **è¯„çº§ä½“ç³»**ï¼šT0å“è¶Š / T1å¨´ç†Ÿ / T2èƒœä»» / T3å¾…åŸ¹å…» / T4å·®è·è¾ƒå¤§

---

**æ ¸å¿ƒåŸåˆ™**ï¼šè‡ªé€‚åº”ç»´åº¦æŠ½å– + é€é¡¹ç‹¬ç«‹è¯„ä¼° + åŒè§†è§’æŠ¥å‘Š + å¤šæ¨¡æ€å¢å¼º
```

```markdown
# AIé¢è¯•è¯„ä¼°æŠ¥å‘Šç³»ç»Ÿè§„èŒƒï¼ˆåŸºäºGoldenä»£ç ï¼‰

## ğŸ¯ æ ¸å¿ƒæ€è·¯

**å¤šæ­¥éª¤æ·±åº¦åˆ†æ**ï¼šè‡ªé€‚åº”æŠ½å–è€ƒæ ¸ç»´åº¦ â†’ é€é¡¹æ‰“åˆ†è¯„ä¼° â†’ å²—ä½é€‚é…åº¦åˆ†æ â†’ æ€§æ ¼æ·±åº¦åˆ†æ â†’ èŒä¸šå‘å±•è§„åˆ’ â†’ è–ªé…¬å¸‚åœºè¯„ä¼° â†’ ç»¼åˆæ€»ç»“æŠ¥å‘Š â†’ å¤šæ¨¡æ€é£æ ¼åˆ†æ â†’ å€™é€‰äººåé¦ˆ

## ğŸ“‹ æ ¸å¿ƒåŠŸèƒ½

### è¾“å…¥
- é¢è¯•å¯¹è¯è®°å½•ï¼ˆtranscriptï¼‰
- å²—ä½æè¿°ï¼ˆJDï¼‰
- è§†é¢‘/å›¾ç‰‡URLï¼ˆurl_listï¼‰
- é¢è¯•è¯­è¨€ï¼ˆinterview_languageï¼‰

### è¾“å‡º
- **HRè§†è§’**ï¼šç»¼åˆè¯„åˆ†ã€äº®ç‚¹ã€é£é™©ã€è¯„çº§ï¼ˆT0~T4ï¼‰
- **å€™é€‰äººè§†è§’**ï¼šä¼˜åŠ¿ã€ä¸è¶³ã€çŸ­æœŸ/é•¿æœŸæ”¹è¿›å»ºè®®
- **å²—ä½é€‚é…åº¦**ï¼šå½“å‰å²—ä½åŒ¹é…åˆ†å€¼ã€èƒ½åŠ›å·®è·åˆ†æ
- **èŒä¸šå‘å±•**ï¼šæ¨ªå‘/çºµå‘å²—ä½æ¨è + æ¨èç™¾åˆ†æ¯” + æ¨èç†ç”±
- **æ€§æ ¼åˆ†æ**ï¼šå²—ä½æ€§æ ¼è¦æ±‚ã€å€™é€‰äººæ€§æ ¼ç‰¹å¾ã€å…·è±¡åŒ–å¡‘é€ å»ºè®®
- **è–ªé…¬è¯„ä¼°**ï¼šå¸‚åœºè¡Œæƒ…åˆ†æã€ä¸åŒè§„æ¨¡ä¼ä¸šè–ªé…¬èŒƒå›´ã€å€™é€‰äººå½“å‰è–ªé…¬è¯„ä¼°ã€è–ªé…¬æå‡è·¯å¾„
- **é¢„æœŸç®¡ç†**ï¼šè¯†åˆ«ä¸åˆç†é¢„æœŸã€æ¨èåˆé€‚èµ·å§‹å²—ä½çº§åˆ«ã€ç‰¹å®šè–ªèµ„æ‰€éœ€ç»éªŒå¹´é™
- **æˆé•¿å»ºè®®**ï¼šå¿ƒæ€å»ºè®¾ã€å¿…å¤‡æŠ€èƒ½æ¸…å•ã€ä¸åŒä¼ä¸šè§„æ¨¡è¦æ±‚åˆ†æã€å­¦ä¹ æå‡æ–¹å‘
- **å¤šæ¨¡æ€**ï¼šé£æ ¼æ ‡ç­¾ã€å½¢è±¡è¯„åˆ†ã€è¡Œä¸ºæ£€æµ‹

### å¤„ç†æ–¹å¼
- **7+Næ¬¡AIè°ƒç”¨**ï¼ˆN=è€ƒæ ¸ç»´åº¦æ•°é‡ï¼Œé€šå¸¸5-10ä¸ªï¼‰
- è‡ªé€‚åº”æŠ½å–ç»´åº¦ï¼Œé€é¡¹ç‹¬ç«‹è¯„åˆ†
- å²—ä½é€‚é…åº¦åˆ†æ + èŒä¸šå‘å±•è§„åˆ’ï¼ˆ1æ¬¡AIè°ƒç”¨ï¼‰
- æ€§æ ¼æ·±åº¦åˆ†æï¼ˆ1æ¬¡AIè°ƒç”¨ï¼‰
- è–ªé…¬å¸‚åœºè¯„ä¼°ï¼ˆ1æ¬¡AIè°ƒç”¨ï¼Œä½¿ç”¨Qwenè”ç½‘æœç´¢èƒ½åŠ›ï¼‰
- é¢„æœŸç®¡ç†åˆ†æï¼ˆèå…¥è–ªé…¬è¯„ä¼°ä¸­ï¼‰
- å¤šæ¨¡æ€åˆ†æï¼ˆæ”¯æŒè§†é¢‘/å›¾ç‰‡ï¼‰

## ğŸ’» æ ¸å¿ƒå®ç°

### æ–‡ä»¶ç»“æ„
```
service/
â”œâ”€â”€ AIInterviewAssessor.py    # æ ¸å¿ƒæœåŠ¡ï¼ˆ327è¡Œï¼‰
â””â”€â”€ multimodal_report.py       # å¤šæ¨¡æ€åˆ†æï¼ˆ100è¡Œï¼‰
routers/
â””â”€â”€ interview_report_router.py # APIè·¯ç”±ï¼ˆ97è¡Œï¼‰
```

### æ ¸å¿ƒæµç¨‹ï¼ˆ9æ­¥ï¼‰
```python
def generate_report(transcript, jd, interview_id, url_list, is_mp4, language):
    # æ­¥éª¤1: æŠ½å–è€ƒæ ¸ç»´åº¦ (1æ¬¡AIè°ƒç”¨)
    competencies = _extract_competencies(jd, transcript)
    # è¾“å‡º: {hard_skills: [...], soft_skills: [...], cultural_fit: [...]}
    
    # æ­¥éª¤2: é€é¡¹èƒ½åŠ›è¯„ä¼° (Næ¬¡AIè°ƒç”¨)
    for competency in all_competency_keys:
        result = _analyze_single_competency(competency, transcript)
        # è¾“å‡º: {score: 85, rationale: "...", evidence_quotes: [...]}
    
    # æ­¥éª¤3: å²—ä½é€‚é…åº¦åˆ†æ + èŒä¸šå‘å±•è§„åˆ’ (1æ¬¡AIè°ƒç”¨)
    job_match = _analyze_job_match_and_career(detailed_analysis, jd, transcript)
    # è¾“å‡º: {
    #   current_job_match_score: 78.5,
    #   capability_gaps: {hard_skills: [...], soft_skills: [...]},
    #   alternative_jobs: [
    #     {type: "æ¨ªå‘", job_title: "...", match_percentage: 85, reason: "..."},
    #     {type: "çºµå‘", job_title: "...", match_percentage: 70, reason: "..."}
    #   ]
    # }
    
    # æ­¥éª¤4: æ€§æ ¼æ·±åº¦åˆ†æ (1æ¬¡AIè°ƒç”¨)
    personality = _analyze_personality(jd, transcript)
    # è¾“å‡º: {
    #   job_personality_requirements: "...",
    #   candidate_personality_traits: "...",
    #   concrete_shaping_suggestions: [...]
    # }
    
    # æ­¥éª¤5: è–ªé…¬å¸‚åœºè¯„ä¼° (1æ¬¡AIè°ƒç”¨ï¼Œå¯ç”¨è”ç½‘æœç´¢)
    salary = _analyze_salary_market(jd, transcript, detailed_analysis)
    # è¾“å‡º: {
    #   market_analysis: "...",
    #   salary_ranges: {
    #     fortune_500: "20-30K",
    #     mid_size: "15-25K",
    #     startup: "12-20K"
    #   },
    #   candidate_salary_assessment: "18-22K",
    #   salary_growth_path: "...",
    #   expectation_management: {
    #     is_expectation_reasonable: true/false,
    #     recommended_starting_level: "...",
    #     experience_required_for_target_salary: "..."
    #   }
    # }
    
    # æ­¥éª¤6: ç”ŸæˆHRæ€»ç»“ (1æ¬¡AIè°ƒç”¨)
    summary = _generate_final_summary(detailed_analysis, job_match, personality, salary)
    # è¾“å‡º: {highlights: "...", risks: "...", conclusion: "T2-èƒœä»»..."}
    
    # æ­¥éª¤7: å¤šæ¨¡æ€åˆ†æ (1æ¬¡AIè°ƒç”¨, qwen-vl-max-latest)
    style = style_report(url_list, interview_id, is_mp4, language)
    # è¾“å‡º: {style: "èŒä¸šå¹²ç»ƒ", description: "...", appearance: "82åˆ†..."}
    
    # æ­¥éª¤8: ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š (1æ¬¡AIè°ƒç”¨)
    user_report = _user_report(jd, transcript, hr_report, personality, salary)
    # è¾“å‡º: {
    #   highlights, insufficient, 
    #   short_term_actions, long_term_actions,
    #   mindset_building: "...",
    #   essential_skills_checklist: [...],
    #   company_size_requirements: {...},
    #   learning_directions: [...]
    # }
    
    # æ­¥éª¤9: èšåˆæœ€ç»ˆæŠ¥å‘Š â†’ å­˜å…¥æ•°æ®åº“
    return final_report
```

## ğŸŒ APIæ¥å£

**POST** `/interviewReport`

### è¯·æ±‚
```json
{
  "interview_id": "123456",
  "transcript": [
    {"role": "interviewer", "content": "ä»‹ç»ä½ çš„Pythonç»éªŒ", "timestamp": 1},
    {"role": "candidate", "content": "æˆ‘æœ‰3å¹´Pythonå¼€å‘ç»éªŒ...", "timestamp": 2}
  ],
  "jd": "å²—ä½èŒè´£ï¼š\n1. åç«¯å¼€å‘\nä»»èŒè¦æ±‚ï¼š\n1. 3å¹´Pythonç»éªŒ",
  "interview_language": "zhongwen",
  "p_url": ["http://example.com/img1.png"],  // å›¾ç‰‡URL
  "v_url": ["http://example.com/video.mp4"]   // è§†é¢‘URL
}
```

### å“åº”ï¼ˆç«‹å³è¿”å›ï¼Œåå°å¼‚æ­¥ç”Ÿæˆï¼‰
```json
{
  "code": 0,
  "message": "success",
  "data": ""
}
```

### æœ€ç»ˆæŠ¥å‘Šç»“æ„ï¼ˆå­˜å…¥æ•°æ®åº“ï¼‰
```json
{
  "overall_assessment": {
    "match_score": 78.5,
    "conclusion": "T2-èƒœä»»ï¼Œå®šä¹‰ï¼šç¬¦åˆé¢„æœŸã€‚å»ºè®®å½•ç”¨ã€‚",
    "highlights": "æŠ€æœ¯åŸºç¡€æ‰å®ï¼Œæ²Ÿé€šæ¸…æ™°",
    "potential_risks": "ç¼ºä¹æ¶æ„ç»éªŒ"
  },
  "detailed_analysis": [
    {
      "competency": "Pythonå¼€å‘èƒ½åŠ›",
      "score": 85,
      "rationale": "æ‰å®çš„å¼€å‘åŸºç¡€ï¼Œç†Ÿæ‚‰Djangoæ¡†æ¶",
      "evidence_quotes": ["æˆ‘ä¸»å¯¼äº†è®¢å•ç³»ç»Ÿå¼€å‘", "æ—¥å‡100ä¸‡è¯·æ±‚é‡"]
    }
  ],
  "competency_model_used": {
    "hard_skills": ["Pythonå¼€å‘", "æ•°æ®åº“è®¾è®¡"],
    "soft_skills": ["æ²Ÿé€šèƒ½åŠ›"],
    "cultural_fit": ["å­¦ä¹ æ€åº¦"]
  },
  "job_match_analysis": {
    "current_job_match_score": 78.5,
    "capability_gaps": {
      "hard_skills": ["æ¶æ„è®¾è®¡ç»éªŒä¸è¶³", "å¾®æœåŠ¡å®æˆ˜ç»éªŒç¼ºä¹"],
      "soft_skills": ["å›¢é˜Ÿç®¡ç†ç»éªŒæœ‰é™"]
    },
    "alternative_jobs": [
      {
        "type": "æ¨ªå‘",
        "job_title": "å…¨æ ˆå¼€å‘å·¥ç¨‹å¸ˆ",
        "match_percentage": 85,
        "reason": "åç«¯èƒ½åŠ›æ‰å®ï¼Œè¡¥å……å‰ç«¯æŠ€èƒ½åå¯èƒœä»»å…¨æ ˆå²—ä½"
      },
      {
        "type": "çºµå‘",
        "job_title": "æŠ€æœ¯ä¸»ç®¡/Team Leader",
        "match_percentage": 65,
        "reason": "æŠ€æœ¯èƒ½åŠ›è¾¾æ ‡ï¼Œéœ€è¡¥å……å›¢é˜Ÿç®¡ç†å’Œæ¶æ„è®¾è®¡èƒ½åŠ›"
      }
    ]
  },
  "personality_analysis": {
    "job_personality_requirements": "è¯¥å²—ä½éœ€è¦è¾ƒå¼ºçš„é€»è¾‘æ€ç»´ã€é—®é¢˜è§£å†³èƒ½åŠ›ã€å›¢é˜Ÿåä½œç²¾ç¥å’ŒæŒç»­å­¦ä¹ æ„æ„¿",
    "candidate_personality_traits": "å€™é€‰äººå±•ç°å‡ºè¾ƒå¼ºçš„æŠ€æœ¯çƒ­æƒ…ã€è‰¯å¥½çš„è¡¨è¾¾èƒ½åŠ›ã€ç§¯æçš„å­¦ä¹ æ€åº¦ï¼Œæ€§æ ¼åå†…æ•›ä½†ä¸“ä¸šæ²Ÿé€šæ¸…æ™°",
    "concrete_shaping_suggestions": [
      "å¢å¼ºä¸»åŠ¨æ²Ÿé€šæ„è¯†ï¼Œåœ¨å›¢é˜Ÿä¸­å¤šåˆ†äº«æŠ€æœ¯è§è§£",
      "åŸ¹å…»å…¨å±€è§†è§’ï¼Œä»ä¸šåŠ¡è§’åº¦æ€è€ƒæŠ€æœ¯æ–¹æ¡ˆ",
      "æå‡æŠ—å‹èƒ½åŠ›ï¼Œåœ¨é«˜å‹ç¯å¢ƒä¸‹ä¿æŒå†·é™åˆ¤æ–­"
    ]
  },
  "salary_analysis": {
    "market_analysis": "æ ¹æ®2024å¹´å¸‚åœºæ•°æ®ï¼Œ3å¹´Pythonåç«¯å¼€å‘å·¥ç¨‹å¸ˆåœ¨ä¸€çº¿åŸå¸‚çš„è–ªèµ„åŒºé—´ä¸º15-30Kï¼Œå…·ä½“å–å†³äºå…¬å¸è§„æ¨¡ã€æŠ€æœ¯æ ˆæ·±åº¦å’Œé¡¹ç›®ç»éªŒ",
    "salary_ranges": {
      "fortune_500": "20-30Kï¼ˆå¤§å‚ï¼Œè¦æ±‚é«˜ï¼Œç¦åˆ©å¥½ï¼‰",
      "mid_size": "15-25Kï¼ˆä¸­å‹ä¼ä¸šï¼Œå¸‚åœºä¸»æµï¼‰",
      "startup": "12-22Kï¼ˆåˆ›ä¸šå…¬å¸ï¼Œè‚¡æƒæ¿€åŠ±ä¸ºä¸»ï¼‰"
    },
    "candidate_salary_assessment": "18-22K",
    "salary_growth_path": "1å¹´å†…é€šè¿‡è¡¥å……æ¶æ„èƒ½åŠ›è¾¾åˆ°22-28Kï¼›3å¹´å†…æ™‹å‡é«˜çº§å·¥ç¨‹å¸ˆå¯è¾¾30-40Kï¼›5å¹´å†…è½¬å‘æ¶æ„å¸ˆå¯è¾¾40-60K",
    "expectation_management": {
      "is_expectation_reasonable": true,
      "recommended_starting_level": "ä¸­çº§åç«¯å·¥ç¨‹å¸ˆï¼ˆ3-5å¹´ç»éªŒï¼‰",
      "experience_required_for_target_salary": "å¦‚æœŸæœ›25K+ï¼Œéœ€è¦5å¹´ä»¥ä¸Šç»éªŒæˆ–å…·å¤‡æ¶æ„è®¾è®¡èƒ½åŠ›"
    }
  },
  "style_report": {
    "style": "èŒä¸šå¹²ç»ƒ",
    "description": "çœ¼ç¥è‡ªä¿¡ï¼Œç€è£…å¾—ä½“",
    "behavior": "æœªå‘ç°å¼‚å¸¸",
    "appearance": "82åˆ†ã€‚äº”å®˜ç«¯æ­£ï¼Œæ­£è£…æ•´æ´"
  },
  "user_report": {
    "highlights": "ä½ çš„æŠ€æœ¯è¡¨è¾¾æ¸…æ™°ï¼ŒPythonåŸºç¡€æ‰å®ï¼Œé¡¹ç›®ç»éªŒä¸°å¯Œ...",
    "insufficient": "æ¶æ„è®¾è®¡å¯ä»¥æ›´æœ‰æ¡ç†ï¼Œå›¢é˜Ÿåä½œç»éªŒéœ€è¦åŠ å¼º...",
    "short_term_actions": ["æ¯å¤©ç»ƒä¹ 1ä¸ªç®—æ³•é¢˜", "å‡†å¤‡3ä¸ªSTARè¯æœ¯", "å­¦ä¹ ç³»ç»Ÿè®¾è®¡åŸºç¡€"],
    "long_term_actions": ["å­¦ä¹ åˆ†å¸ƒå¼ç³»ç»Ÿ", "å‚ä¸å¼€æºé¡¹ç›®", "åŸ¹å…»å›¢é˜Ÿç®¡ç†èƒ½åŠ›"],
    "mindset_building": "ä¿æŒæŠ€æœ¯çƒ­æƒ…çš„åŒæ—¶ï¼ŒåŸ¹å…»ä¸šåŠ¡æ€ç»´å’Œå…¨å±€è§†è§’ã€‚é¢è¯•æ˜¯åŒå‘é€‰æ‹©ï¼Œè‡ªä¿¡å±•ç°è‡ªå·±çš„åŒæ—¶ä¹Ÿè¦è¯„ä¼°å…¬å¸æ˜¯å¦é€‚åˆè‡ªå·±ã€‚",
    "essential_skills_checklist": [
      "Pythoné«˜çº§ç‰¹æ€§ï¼ˆè£…é¥°å™¨ã€å…ƒç±»ã€å¹¶å‘ï¼‰",
      "æ•°æ®åº“ä¼˜åŒ–ï¼ˆç´¢å¼•ã€æŸ¥è¯¢ä¼˜åŒ–ã€åˆ†åº“åˆ†è¡¨ï¼‰",
      "ç¼“å­˜ç­–ç•¥ï¼ˆRedisã€æœ¬åœ°ç¼“å­˜ï¼‰",
      "å¾®æœåŠ¡æ¶æ„ï¼ˆæœåŠ¡æ‹†åˆ†ã€APIè®¾è®¡ã€æœåŠ¡æ²»ç†ï¼‰",
      "ç³»ç»Ÿè®¾è®¡èƒ½åŠ›ï¼ˆé«˜å¹¶å‘ã€é«˜å¯ç”¨ã€å¯æ‰©å±•æ€§ï¼‰"
    ],
    "company_size_requirements": {
      "fortune_500": "è¦æ±‚ç®—æ³•ã€ç³»ç»Ÿè®¾è®¡æ·±åº¦ï¼Œæ³¨é‡æŠ€æœ¯å¹¿åº¦å’Œåä½œèƒ½åŠ›",
      "mid_size": "æ³¨é‡ä¸šåŠ¡å®ç°èƒ½åŠ›å’Œå¿«é€Ÿå­¦ä¹ èƒ½åŠ›ï¼Œè¦æ±‚ç›¸å¯¹å‡è¡¡",
      "startup": "å¼ºè°ƒå¿«é€Ÿäº¤ä»˜å’Œå¤šé¢æ‰‹èƒ½åŠ›ï¼Œå¯æ¥å—æŸäº›æ–¹é¢ç»éªŒä¸è¶³"
    },
    "learning_directions": [
      "æ·±åº¦æ–¹å‘ï¼šæ·±å…¥ç ”ç©¶é«˜æ€§èƒ½Pythonï¼ˆå¼‚æ­¥ç¼–ç¨‹ã€æ€§èƒ½ä¼˜åŒ–ï¼‰",
      "å¹¿åº¦æ–¹å‘ï¼šå­¦ä¹ å‰ç«¯åŸºç¡€ã€DevOpsã€äº‘åŸç”ŸæŠ€æœ¯",
      "è½¯æŠ€èƒ½æ–¹å‘ï¼šæŠ€æœ¯å†™ä½œã€æ¼”è®²è¡¨è¾¾ã€é¡¹ç›®ç®¡ç†"
    ],
    "Quantitative": "æ¯å‘¨2æ¬¡æ¨¡æ‹Ÿé¢è¯•ï¼Œæ¯æœˆå®Œæˆ1ä¸ªç³»ç»Ÿè®¾è®¡æ¡ˆä¾‹ï¼Œæ¯å­£åº¦è¾“å‡º1ç¯‡æŠ€æœ¯åšå®¢",
    "career_advice": "çŸ­æœŸï¼ˆ1å¹´å†…ï¼‰ï¼šå·©å›ºåç«¯åŸºç¡€ï¼Œè¡¥å……æ¶æ„èƒ½åŠ›ï¼Œäº‰å–æ™‹å‡ä¸­é«˜çº§å·¥ç¨‹å¸ˆã€‚ä¸­æœŸï¼ˆ3å¹´å†…ï¼‰ï¼šæ·±å…¥æŸä¸ªæŠ€æœ¯é¢†åŸŸï¼ˆå¦‚åˆ†å¸ƒå¼/é«˜å¹¶å‘ï¼‰ï¼ŒåŒæ—¶åŸ¹å…»å›¢é˜Ÿåä½œå’ŒæŠ€æœ¯å½±å“åŠ›ã€‚é•¿æœŸï¼ˆ5å¹´+ï¼‰ï¼šå‘æ¶æ„å¸ˆæˆ–æŠ€æœ¯ç®¡ç†æ–¹å‘å‘å±•ã€‚",
    "other": "ä¿æŒå­¦ä¹ èŠ‚å¥ï¼Œæ³¨é‡æŠ€æœ¯æ·±åº¦å’Œå¹¿åº¦çš„å¹³è¡¡ã€‚å»ºè®®åŠ å…¥æŠ€æœ¯ç¤¾åŒºï¼Œå¤šä¸è¡Œä¸šå†…äººå£«äº¤æµï¼Œæ‹“å±•è§†é‡ã€‚"
  }
}
```

## ğŸ”§ æŠ€æœ¯ç»†èŠ‚

### LLMé…ç½®
```python
# æ–‡æœ¬åˆ†ææ¨¡å‹
model = "qwen-plus"
temperature = 0.3
seed = 6
response_format = {"type": "json_object"}

# å¤šæ¨¡æ€æ¨¡å‹
multimodal_model = "qwen-vl-max-latest"

# è–ªé…¬å¸‚åœºåˆ†ææ¨¡å‹ï¼ˆå¯ç”¨è”ç½‘æœç´¢ï¼‰
salary_analysis_model = "qwen-plus"
enable_search = True  # å¯ç”¨Qwençš„è”ç½‘æœç´¢å·¥å…·
```

### é‡è¦æœºåˆ¶
- **é‡è¯•æœºåˆ¶**ï¼šå…³é”®AIè°ƒç”¨å¤±è´¥è‡ªåŠ¨é‡è¯•1æ¬¡
- **å¤šæ¨¡æ€ä¿åº•**ï¼šè§†é¢‘åˆ†æå¤±è´¥é™çº§ä¸ºæ–‡æœ¬åˆ†æ
- **å¼‚æ­¥å¤„ç†**ï¼šFastAPI BackgroundTasksåå°ç”Ÿæˆ
- **é˜²é‡å¤**ï¼š10åˆ†é’Ÿå†…åŒinterview_idä¸é‡å¤ç”Ÿæˆ

### æ”¯æŒçš„è¯­è¨€
zhongwenã€yingwenã€riyuã€hanyuã€xibanyayuã€yinniyuã€fayuã€deyuã€taiyu

## ğŸ“Š å…³é”®æŒ‡æ ‡

- **AIè°ƒç”¨æ¬¡æ•°**ï¼šé€šå¸¸8-15æ¬¡ï¼ˆ3å›ºå®š + 5-10ç»´åº¦è¯„ä¼°ï¼‰
- **ç”Ÿæˆè€—æ—¶**ï¼š3-5åˆ†é’Ÿ
- **æˆåŠŸç‡**ï¼š>95%ï¼ˆå¤šå±‚é‡è¯•ä¿éšœï¼‰
- **è¯„çº§ä½“ç³»**ï¼šT0å“è¶Š / T1å¨´ç†Ÿ / T2èƒœä»» / T3å¾…åŸ¹å…» / T4å·®è·è¾ƒå¤§

---

**æ ¸å¿ƒåŸåˆ™**ï¼šè‡ªé€‚åº”ç»´åº¦æŠ½å– + é€é¡¹ç‹¬ç«‹è¯„ä¼° + åŒè§†è§’æŠ¥å‘Š + å¤šæ¨¡æ€å¢å¼º
```

```markdown
# AIé¢è¯•è¯„ä¼°æŠ¥å‘Šç³»ç»Ÿè§„èŒƒï¼ˆåŸºäºGoldenä»£ç ï¼‰

## ğŸ¯ æ ¸å¿ƒæ€è·¯

**å¤šæ­¥éª¤æ·±åº¦åˆ†æ**ï¼šè‡ªé€‚åº”æŠ½å–è€ƒæ ¸ç»´åº¦ â†’ é€é¡¹æ‰“åˆ†è¯„ä¼° â†’ å²—ä½é€‚é…åº¦åˆ†æ â†’ æ€§æ ¼æ·±åº¦åˆ†æ â†’ èŒä¸šå‘å±•è§„åˆ’ â†’ è–ªé…¬å¸‚åœºè¯„ä¼° â†’ ç»¼åˆæ€»ç»“æŠ¥å‘Š â†’ å¤šæ¨¡æ€é£æ ¼åˆ†æ â†’ å€™é€‰äººåé¦ˆ

## ğŸ“‹ æ ¸å¿ƒåŠŸèƒ½

### è¾“å…¥
- é¢è¯•å¯¹è¯è®°å½•ï¼ˆtranscriptï¼‰
- å²—ä½æè¿°ï¼ˆJDï¼‰
- è§†é¢‘/å›¾ç‰‡URLï¼ˆurl_listï¼‰
- é¢è¯•è¯­è¨€ï¼ˆinterview_languageï¼‰

### è¾“å‡º
- **HRè§†è§’**ï¼šç»¼åˆè¯„åˆ†ã€äº®ç‚¹ã€é£é™©ã€è¯„çº§ï¼ˆT0~T4ï¼‰
- **å€™é€‰äººè§†è§’**ï¼šä¼˜åŠ¿ã€ä¸è¶³ã€çŸ­æœŸ/é•¿æœŸæ”¹è¿›å»ºè®®
- **å²—ä½é€‚é…åº¦**ï¼šå½“å‰å²—ä½åŒ¹é…åˆ†å€¼ã€èƒ½åŠ›å·®è·åˆ†æ
- **èŒä¸šå‘å±•**ï¼šæ¨ªå‘/çºµå‘å²—ä½æ¨è + æ¨èç™¾åˆ†æ¯” + æ¨èç†ç”±
- **æ€§æ ¼åˆ†æ**ï¼šå²—ä½æ€§æ ¼è¦æ±‚ã€å€™é€‰äººæ€§æ ¼ç‰¹å¾ã€å…·è±¡åŒ–å¡‘é€ å»ºè®®
- **è–ªé…¬è¯„ä¼°**ï¼šå¸‚åœºè¡Œæƒ…åˆ†æã€ä¸åŒè§„æ¨¡ä¼ä¸šè–ªé…¬èŒƒå›´ã€å€™é€‰äººå½“å‰è–ªé…¬è¯„ä¼°ã€è–ªé…¬æå‡è·¯å¾„
- **é¢„æœŸç®¡ç†**ï¼šè¯†åˆ«ä¸åˆç†é¢„æœŸã€æ¨èåˆé€‚èµ·å§‹å²—ä½çº§åˆ«ã€ç‰¹å®šè–ªèµ„æ‰€éœ€ç»éªŒå¹´é™
- **æˆé•¿å»ºè®®**ï¼šå¿ƒæ€å»ºè®¾ã€å¿…å¤‡æŠ€èƒ½æ¸…å•ã€ä¸åŒä¼ä¸šè§„æ¨¡è¦æ±‚åˆ†æã€å­¦ä¹ æå‡æ–¹å‘
- **å¤šæ¨¡æ€**ï¼šé£æ ¼æ ‡ç­¾ã€å½¢è±¡è¯„åˆ†ã€è¡Œä¸ºæ£€æµ‹

### å¤„ç†æ–¹å¼
- **7+Næ¬¡AIè°ƒç”¨**ï¼ˆN=è€ƒæ ¸ç»´åº¦æ•°é‡ï¼Œé€šå¸¸5-10ä¸ªï¼‰
- è‡ªé€‚åº”æŠ½å–ç»´åº¦ï¼Œé€é¡¹ç‹¬ç«‹è¯„åˆ†
- å²—ä½é€‚é…åº¦åˆ†æ + èŒä¸šå‘å±•è§„åˆ’ï¼ˆ1æ¬¡AIè°ƒç”¨ï¼‰
- æ€§æ ¼æ·±åº¦åˆ†æï¼ˆ1æ¬¡AIè°ƒç”¨ï¼‰
- è–ªé…¬å¸‚åœºè¯„ä¼°ï¼ˆ1æ¬¡AIè°ƒç”¨ï¼Œä½¿ç”¨Qwenè”ç½‘æœç´¢èƒ½åŠ›ï¼‰
- é¢„æœŸç®¡ç†åˆ†æï¼ˆèå…¥è–ªé…¬è¯„ä¼°ä¸­ï¼‰
- å¤šæ¨¡æ€åˆ†æï¼ˆæ”¯æŒè§†é¢‘/å›¾ç‰‡ï¼‰

## ğŸ’» æ ¸å¿ƒå®ç°

### æ–‡ä»¶ç»“æ„
```
service/
â”œâ”€â”€ AIInterviewAssessor.py    # æ ¸å¿ƒæœåŠ¡ï¼ˆ327è¡Œï¼‰
â””â”€â”€ multimodal_report.py       # å¤šæ¨¡æ€åˆ†æï¼ˆ100è¡Œï¼‰
routers/
â””â”€â”€ interview_report_router.py # APIè·¯ç”±ï¼ˆ97è¡Œï¼‰
```

### æ ¸å¿ƒæµç¨‹ï¼ˆ9æ­¥ï¼‰
```python
def generate_report(transcript, jd, interview_id, url_list, is_mp4, language):
    # æ­¥éª¤1: æŠ½å–è€ƒæ ¸ç»´åº¦ (1æ¬¡AIè°ƒç”¨)
    competencies = _extract_competencies(jd, transcript)
    # è¾“å‡º: {hard_skills: [...], soft_skills: [...], cultural_fit: [...]}
    
    # æ­¥éª¤2: é€é¡¹èƒ½åŠ›è¯„ä¼° (Næ¬¡AIè°ƒç”¨)
    for competency in all_competency_keys:
        result = _analyze_single_competency(competency, transcript)
        # è¾“å‡º: {score: 85, rationale: "...", evidence_quotes: [...]}
    
    # æ­¥éª¤3: å²—ä½é€‚é…åº¦åˆ†æ + èŒä¸šå‘å±•è§„åˆ’ (1æ¬¡AIè°ƒç”¨)
    job_match = _analyze_job_match_and_career(detailed_analysis, jd, transcript)
    # è¾“å‡º: {
    #   current_job_match_score: 78.5,
    #   capability_gaps: {hard_skills: [...], soft_skills: [...]},
    #   alternative_jobs: [
    #     {type: "æ¨ªå‘", job_title: "...", match_percentage: 85, reason: "..."},
    #     {type: "çºµå‘", job_title: "...", match_percentage: 70, reason: "..."}
    #   ]
    # }
    
    # æ­¥éª¤4: æ€§æ ¼æ·±åº¦åˆ†æ (1æ¬¡AIè°ƒç”¨)
    personality = _analyze_personality(jd, transcript)
    # è¾“å‡º: {
    #   job_personality_requirements: "...",
    #   candidate_personality_traits: "...",
    #   concrete_shaping_suggestions: [...]
    # }
    
    # æ­¥éª¤5: è–ªé…¬å¸‚åœºè¯„ä¼° (1æ¬¡AIè°ƒç”¨ï¼Œå¯ç”¨è”ç½‘æœç´¢)
    salary = _analyze_salary_market(jd, transcript, detailed_analysis)
    # è¾“å‡º: {
    #   market_analysis: "...",
    #   salary_ranges: {
    #     fortune_500: "20-30K",
    #     mid_size: "15-25K",
    #     startup: "12-20K"
    #   },
    #   candidate_salary_assessment: "18-22K",
    #   salary_growth_path: "...",
    #   expectation_management: {
    #     is_expectation_reasonable: true/false,
    #     recommended_starting_level: "...",
    #     experience_required_for_target_salary: "..."
    #   }
    # }
    
    # æ­¥éª¤6: ç”ŸæˆHRæ€»ç»“ (1æ¬¡AIè°ƒç”¨)
    summary = _generate_final_summary(detailed_analysis, job_match, personality, salary)
    # è¾“å‡º: {highlights: "...", risks: "...", conclusion: "T2-èƒœä»»..."}
    
    # æ­¥éª¤7: å¤šæ¨¡æ€åˆ†æ (1æ¬¡AIè°ƒç”¨, qwen-vl-max-latest)
    style = style_report(url_list, interview_id, is_mp4, language)
    # è¾“å‡º: {style: "èŒä¸šå¹²ç»ƒ", description: "...", appearance: "82åˆ†..."}
    
    # æ­¥éª¤8: ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š (1æ¬¡AIè°ƒç”¨)
    user_report = _user_report(jd, transcript, hr_report, personality, salary)
    # è¾“å‡º: {
    #   highlights, insufficient, 
    #   short_term_actions, long_term_actions,
    #   mindset_building: "...",
    #   essential_skills_checklist: [...],
    #   company_size_requirements: {...},
    #   learning_directions: [...]
    # }
    
    # æ­¥éª¤9: èšåˆæœ€ç»ˆæŠ¥å‘Š â†’ å­˜å…¥æ•°æ®åº“
    return final_report
```

## ğŸŒ APIæ¥å£

**POST** `/interviewReport`

### è¯·æ±‚
```json
{
  "interview_id": "123456",
  "transcript": [
    {"role": "interviewer", "content": "ä»‹ç»ä½ çš„Pythonç»éªŒ", "timestamp": 1},
    {"role": "candidate", "content": "æˆ‘æœ‰3å¹´Pythonå¼€å‘ç»éªŒ...", "timestamp": 2}
  ],
  "jd": "å²—ä½èŒè´£ï¼š\n1. åç«¯å¼€å‘\nä»»èŒè¦æ±‚ï¼š\n1. 3å¹´Pythonç»éªŒ",
  "interview_language": "zhongwen",
  "p_url": ["http://example.com/img1.png"],  // å›¾ç‰‡URL
  "v_url": ["http://example.com/video.mp4"]   // è§†é¢‘URL
}
```

### å“åº”ï¼ˆç«‹å³è¿”å›ï¼Œåå°å¼‚æ­¥ç”Ÿæˆï¼‰
```json
{
  "code": 0,
  "message": "success",
  "data": ""
}
```

### æœ€ç»ˆæŠ¥å‘Šç»“æ„ï¼ˆå­˜å…¥æ•°æ®åº“ï¼‰
```json
{
  "overall_assessment": {
    "match_score": 78.5,
    "conclusion": "T2-èƒœä»»ï¼Œå®šä¹‰ï¼šç¬¦åˆé¢„æœŸã€‚å»ºè®®å½•ç”¨ã€‚",
    "highlights": "æŠ€æœ¯åŸºç¡€æ‰å®ï¼Œæ²Ÿé€šæ¸…æ™°",
    "potential_risks": "ç¼ºä¹æ¶æ„ç»éªŒ"
  },
  "detailed_analysis": [
    {
      "competency": "Pythonå¼€å‘èƒ½åŠ›",
      "score": 85,
      "rationale": "æ‰å®çš„å¼€å‘åŸºç¡€ï¼Œç†Ÿæ‚‰Djangoæ¡†æ¶",
      "evidence_quotes": ["æˆ‘ä¸»å¯¼äº†è®¢å•ç³»ç»Ÿå¼€å‘", "æ—¥å‡100ä¸‡è¯·æ±‚é‡"]
    }
  ],
  "competency_model_used": {
    "hard_skills": ["Pythonå¼€å‘", "æ•°æ®åº“è®¾è®¡"],
    "soft_skills": ["æ²Ÿé€šèƒ½åŠ›"],
    "cultural_fit": ["å­¦ä¹ æ€åº¦"]
  },
  "job_match_analysis": {
    "current_job_match_score": 78.5,
    "capability_gaps": {
      "hard_skills": ["æ¶æ„è®¾è®¡ç»éªŒä¸è¶³", "å¾®æœåŠ¡å®æˆ˜ç»éªŒç¼ºä¹"],
      "soft_skills": ["å›¢é˜Ÿç®¡ç†ç»éªŒæœ‰é™"]
    },
    "alternative_jobs": [
      {
        "type": "æ¨ªå‘",
        "job_title": "å…¨æ ˆå¼€å‘å·¥ç¨‹å¸ˆ",
        "match_percentage": 85,
        "reason": "åç«¯èƒ½åŠ›æ‰å®ï¼Œè¡¥å……å‰ç«¯æŠ€èƒ½åå¯èƒœä»»å…¨æ ˆå²—ä½"
      },
      {
        "type": "çºµå‘",
        "job_title": "æŠ€æœ¯ä¸»ç®¡/Team Leader",
        "match_percentage": 65,
        "reason": "æŠ€æœ¯èƒ½åŠ›è¾¾æ ‡ï¼Œéœ€è¡¥å……å›¢é˜Ÿç®¡ç†å’Œæ¶æ„è®¾è®¡èƒ½åŠ›"
      }
    ]
  },
  "personality_analysis": {
    "job_personality_requirements": "è¯¥å²—ä½éœ€è¦è¾ƒå¼ºçš„é€»è¾‘æ€ç»´ã€é—®é¢˜è§£å†³èƒ½åŠ›ã€å›¢é˜Ÿåä½œç²¾ç¥å’ŒæŒç»­å­¦ä¹ æ„æ„¿",
    "candidate_personality_traits": "å€™é€‰äººå±•ç°å‡ºè¾ƒå¼ºçš„æŠ€æœ¯çƒ­æƒ…ã€è‰¯å¥½çš„è¡¨è¾¾èƒ½åŠ›ã€ç§¯æçš„å­¦ä¹ æ€åº¦ï¼Œæ€§æ ¼åå†…æ•›ä½†ä¸“ä¸šæ²Ÿé€šæ¸…æ™°",
    "concrete_shaping_suggestions": [
      "å¢å¼ºä¸»åŠ¨æ²Ÿé€šæ„è¯†ï¼Œåœ¨å›¢é˜Ÿä¸­å¤šåˆ†äº«æŠ€æœ¯è§è§£",
      "åŸ¹å…»å…¨å±€è§†è§’ï¼Œä»ä¸šåŠ¡è§’åº¦æ€è€ƒæŠ€æœ¯æ–¹æ¡ˆ",
      "æå‡æŠ—å‹èƒ½åŠ›ï¼Œåœ¨é«˜å‹ç¯å¢ƒä¸‹ä¿æŒå†·é™åˆ¤æ–­"
    ]
  },
  "salary_analysis": {
    "market_analysis": "æ ¹æ®2024å¹´å¸‚åœºæ•°æ®ï¼Œ3å¹´Pythonåç«¯å¼€å‘å·¥ç¨‹å¸ˆåœ¨ä¸€çº¿åŸå¸‚çš„è–ªèµ„åŒºé—´ä¸º15-30Kï¼Œå…·ä½“å–å†³äºå…¬å¸è§„æ¨¡ã€æŠ€æœ¯æ ˆæ·±åº¦å’Œé¡¹ç›®ç»éªŒ",
    "salary_ranges": {
      "fortune_500": "20-30Kï¼ˆå¤§å‚ï¼Œè¦æ±‚é«˜ï¼Œç¦åˆ©å¥½ï¼‰",
      "mid_size": "15-25Kï¼ˆä¸­å‹ä¼ä¸šï¼Œå¸‚åœºä¸»æµï¼‰",
      "startup": "12-22Kï¼ˆåˆ›ä¸šå…¬å¸ï¼Œè‚¡æƒæ¿€åŠ±ä¸ºä¸»ï¼‰"
    },
    "candidate_salary_assessment": "18-22K",
    "salary_growth_path": "1å¹´å†…é€šè¿‡è¡¥å……æ¶æ„èƒ½åŠ›è¾¾åˆ°22-28Kï¼›3å¹´å†…æ™‹å‡é«˜çº§å·¥ç¨‹å¸ˆå¯è¾¾30-40Kï¼›5å¹´å†…è½¬å‘æ¶æ„å¸ˆå¯è¾¾40-60K",
    "expectation_management": {
      "is_expectation_reasonable": true,
      "recommended_starting_level": "ä¸­çº§åç«¯å·¥ç¨‹å¸ˆï¼ˆ3-5å¹´ç»éªŒï¼‰",
      "experience_required_for_target_salary": "å¦‚æœŸæœ›25K+ï¼Œéœ€è¦5å¹´ä»¥ä¸Šç»éªŒæˆ–å…·å¤‡æ¶æ„è®¾è®¡èƒ½åŠ›"
    }
  },
  "style_report": {
    "style": "èŒä¸šå¹²ç»ƒ",
    "description": "çœ¼ç¥è‡ªä¿¡ï¼Œç€è£…å¾—ä½“",
    "behavior": "æœªå‘ç°å¼‚å¸¸",
    "appearance": "82åˆ†ã€‚äº”å®˜ç«¯æ­£ï¼Œæ­£è£…æ•´æ´"
  },
  "user_report": {
    "highlights": "ä½ çš„æŠ€æœ¯è¡¨è¾¾æ¸…æ™°ï¼ŒPythonåŸºç¡€æ‰å®ï¼Œé¡¹ç›®ç»éªŒä¸°å¯Œ...",
    "insufficient": "æ¶æ„è®¾è®¡å¯ä»¥æ›´æœ‰æ¡ç†ï¼Œå›¢é˜Ÿåä½œç»éªŒéœ€è¦åŠ å¼º...",
    "short_term_actions": ["æ¯å¤©ç»ƒä¹ 1ä¸ªç®—æ³•é¢˜", "å‡†å¤‡3ä¸ªSTARè¯æœ¯", "å­¦ä¹ ç³»ç»Ÿè®¾è®¡åŸºç¡€"],
    "long_term_actions": ["å­¦ä¹ åˆ†å¸ƒå¼ç³»ç»Ÿ", "å‚ä¸å¼€æºé¡¹ç›®", "åŸ¹å…»å›¢é˜Ÿç®¡ç†èƒ½åŠ›"],
    "mindset_building": "ä¿æŒæŠ€æœ¯çƒ­æƒ…çš„åŒæ—¶ï¼ŒåŸ¹å…»ä¸šåŠ¡æ€ç»´å’Œå…¨å±€è§†è§’ã€‚é¢è¯•æ˜¯åŒå‘é€‰æ‹©ï¼Œè‡ªä¿¡å±•ç°è‡ªå·±çš„åŒæ—¶ä¹Ÿè¦è¯„ä¼°å…¬å¸æ˜¯å¦é€‚åˆè‡ªå·±ã€‚",
    "essential_skills_checklist": [
      "Pythoné«˜çº§ç‰¹æ€§ï¼ˆè£…é¥°å™¨ã€å…ƒç±»ã€å¹¶å‘ï¼‰",
      "æ•°æ®åº“ä¼˜åŒ–ï¼ˆç´¢å¼•ã€æŸ¥è¯¢ä¼˜åŒ–ã€åˆ†åº“åˆ†è¡¨ï¼‰",
      "ç¼“å­˜ç­–ç•¥ï¼ˆRedisã€æœ¬åœ°ç¼“å­˜ï¼‰",
      "å¾®æœåŠ¡æ¶æ„ï¼ˆæœåŠ¡æ‹†åˆ†ã€APIè®¾è®¡ã€æœåŠ¡æ²»ç†ï¼‰",
      "ç³»ç»Ÿè®¾è®¡èƒ½åŠ›ï¼ˆé«˜å¹¶å‘ã€é«˜å¯ç”¨ã€å¯æ‰©å±•æ€§ï¼‰"
    ],
    "company_size_requirements": {
      "fortune_500": "è¦æ±‚ç®—æ³•ã€ç³»ç»Ÿè®¾è®¡æ·±åº¦ï¼Œæ³¨é‡æŠ€æœ¯å¹¿åº¦å’Œåä½œèƒ½åŠ›",
      "mid_size": "æ³¨é‡ä¸šåŠ¡å®ç°èƒ½åŠ›å’Œå¿«é€Ÿå­¦ä¹ èƒ½åŠ›ï¼Œè¦æ±‚ç›¸å¯¹å‡è¡¡",
      "startup": "å¼ºè°ƒå¿«é€Ÿäº¤ä»˜å’Œå¤šé¢æ‰‹èƒ½åŠ›ï¼Œå¯æ¥å—æŸäº›æ–¹é¢ç»éªŒä¸è¶³"
    },
    "learning_directions": [
      "æ·±åº¦æ–¹å‘ï¼šæ·±å…¥ç ”ç©¶é«˜æ€§èƒ½Pythonï¼ˆå¼‚æ­¥ç¼–ç¨‹ã€æ€§èƒ½ä¼˜åŒ–ï¼‰",
      "å¹¿åº¦æ–¹å‘ï¼šå­¦ä¹ å‰ç«¯åŸºç¡€ã€DevOpsã€äº‘åŸç”ŸæŠ€æœ¯",
      "è½¯æŠ€èƒ½æ–¹å‘ï¼šæŠ€æœ¯å†™ä½œã€æ¼”è®²è¡¨è¾¾ã€é¡¹ç›®ç®¡ç†"
    ],
    "Quantitative": "æ¯å‘¨2æ¬¡æ¨¡æ‹Ÿé¢è¯•ï¼Œæ¯æœˆå®Œæˆ1ä¸ªç³»ç»Ÿè®¾è®¡æ¡ˆä¾‹ï¼Œæ¯å­£åº¦è¾“å‡º1ç¯‡æŠ€æœ¯åšå®¢",
    "career_advice": "çŸ­æœŸï¼ˆ1å¹´å†…ï¼‰ï¼šå·©å›ºåç«¯åŸºç¡€ï¼Œè¡¥å……æ¶æ„èƒ½åŠ›ï¼Œäº‰å–æ™‹å‡ä¸­é«˜çº§å·¥ç¨‹å¸ˆã€‚ä¸­æœŸï¼ˆ3å¹´å†…ï¼‰ï¼šæ·±å…¥æŸä¸ªæŠ€æœ¯é¢†åŸŸï¼ˆå¦‚åˆ†å¸ƒå¼/é«˜å¹¶å‘ï¼‰ï¼ŒåŒæ—¶åŸ¹å…»å›¢é˜Ÿåä½œå’ŒæŠ€æœ¯å½±å“åŠ›ã€‚é•¿æœŸï¼ˆ5å¹´+ï¼‰ï¼šå‘æ¶æ„å¸ˆæˆ–æŠ€æœ¯ç®¡ç†æ–¹å‘å‘å±•ã€‚",
    "other": "ä¿æŒå­¦ä¹ èŠ‚å¥ï¼Œæ³¨é‡æŠ€æœ¯æ·±åº¦å’Œå¹¿åº¦çš„å¹³è¡¡ã€‚å»ºè®®åŠ å…¥æŠ€æœ¯ç¤¾åŒºï¼Œå¤šä¸è¡Œä¸šå†…äººå£«äº¤æµï¼Œæ‹“å±•è§†é‡ã€‚"
  }
}
```

## ğŸ”§ æŠ€æœ¯ç»†èŠ‚

### LLMé…ç½®
```python
# æ–‡æœ¬åˆ†ææ¨¡å‹
model = "qwen-plus"
temperature = 0.3
seed = 6
response_format = {"type": "json_object"}

# å¤šæ¨¡æ€æ¨¡å‹
multimodal_model = "qwen-vl-max-latest"

# è–ªé…¬å¸‚åœºåˆ†ææ¨¡å‹ï¼ˆå¯ç”¨è”ç½‘æœç´¢ï¼‰
salary_analysis_model = "qwen-plus"
enable_search = True  # å¯ç”¨Qwençš„è”ç½‘æœç´¢å·¥å…·
```

### é‡è¦æœºåˆ¶
- **é‡è¯•æœºåˆ¶**ï¼šå…³é”®AIè°ƒç”¨å¤±è´¥è‡ªåŠ¨é‡è¯•1æ¬¡
- **å¤šæ¨¡æ€ä¿åº•**ï¼šè§†é¢‘åˆ†æå¤±è´¥é™çº§ä¸ºæ–‡æœ¬åˆ†æ
- **å¼‚æ­¥å¤„ç†**ï¼šFastAPI BackgroundTasksåå°ç”Ÿæˆ
- **é˜²é‡å¤**ï¼š10åˆ†é’Ÿå†…åŒinterview_idä¸é‡å¤ç”Ÿæˆ
- **è”ç½‘æœç´¢**ï¼šè–ªé…¬åˆ†æå¯ç”¨Qwenæœç´¢å·¥å…·ï¼Œå®æ—¶è·å–å¸‚åœºæ•°æ®
- **æœç´¢é™çº§**ï¼šè”ç½‘æœç´¢å¤±è´¥æ—¶ï¼ŒåŸºäºLLMå†…ç½®çŸ¥è¯†ç»™å‡ºå‚è€ƒå»ºè®®ï¼ˆæ ‡æ³¨"åŸºäºå†å²æ•°æ®"ï¼‰

### æ”¯æŒçš„è¯­è¨€
zhongwenã€yingwenã€riyuã€hanyuã€xibanyayuã€yinniyuã€fayuã€deyuã€taiyu

## ğŸ“Š å…³é”®æŒ‡æ ‡

- **AIè°ƒç”¨æ¬¡æ•°**ï¼šé€šå¸¸8-15æ¬¡ï¼ˆ3å›ºå®š + 5-10ç»´åº¦è¯„ä¼°ï¼‰
- **ç”Ÿæˆè€—æ—¶**ï¼š3-5åˆ†é’Ÿ
- **æˆåŠŸç‡**ï¼š>95%ï¼ˆå¤šå±‚é‡è¯•ä¿éšœï¼‰
- **è¯„çº§ä½“ç³»**ï¼šT0å“è¶Š / T1å¨´ç†Ÿ / T2èƒœä»» / T3å¾…åŸ¹å…» / T4å·®è·è¾ƒå¤§

---

**æ ¸å¿ƒåŸåˆ™**ï¼šè‡ªé€‚åº”ç»´åº¦æŠ½å– + é€é¡¹ç‹¬ç«‹è¯„ä¼° + åŒè§†è§’æŠ¥å‘Š + å¤šæ¨¡æ€å¢å¼º
```

```markdown
# AIé¢è¯•è¯„ä¼°æŠ¥å‘Šç³»ç»Ÿè§„èŒƒï¼ˆåŸºäºGoldenä»£ç ï¼‰

## ğŸ¯ æ ¸å¿ƒæ€è·¯

**å¤šæ­¥éª¤æ·±åº¦åˆ†æ**ï¼šè‡ªé€‚åº”æŠ½å–è€ƒæ ¸ç»´åº¦ â†’ é€é¡¹æ‰“åˆ†è¯„ä¼° â†’ å²—ä½é€‚é…åº¦åˆ†æ â†’ æ€§æ ¼æ·±åº¦åˆ†æ â†’ èŒä¸šå‘å±•è§„åˆ’ â†’ è–ªé…¬å¸‚åœºè¯„ä¼° â†’ ç»¼åˆæ€»ç»“æŠ¥å‘Š â†’ å¤šæ¨¡æ€é£æ ¼åˆ†æ â†’ å€™é€‰äººåé¦ˆ

## ğŸ“‹ æ ¸å¿ƒåŠŸèƒ½

### è¾“å…¥
- é¢è¯•å¯¹è¯è®°å½•ï¼ˆtranscriptï¼‰
- å²—ä½æè¿°ï¼ˆJDï¼‰
- è§†é¢‘/å›¾ç‰‡URLï¼ˆurl_listï¼‰
- é¢è¯•è¯­è¨€ï¼ˆinterview_languageï¼‰

### è¾“å‡º
- **HRè§†è§’**ï¼šç»¼åˆè¯„åˆ†ã€äº®ç‚¹ã€é£é™©ã€è¯„çº§ï¼ˆT0~T4ï¼‰
- **å€™é€‰äººè§†è§’**ï¼šä¼˜åŠ¿ã€ä¸è¶³ã€çŸ­æœŸ/é•¿æœŸæ”¹è¿›å»ºè®®
- **å²—ä½é€‚é…åº¦**ï¼šå½“å‰å²—ä½åŒ¹é…åˆ†å€¼ã€èƒ½åŠ›å·®è·åˆ†æ
- **èŒä¸šå‘å±•**ï¼šæ¨ªå‘/çºµå‘å²—ä½æ¨è + æ¨èç™¾åˆ†æ¯” + æ¨èç†ç”±
- **æ€§æ ¼åˆ†æ**ï¼šå²—ä½æ€§æ ¼è¦æ±‚ã€å€™é€‰äººæ€§æ ¼ç‰¹å¾ã€å…·è±¡åŒ–å¡‘é€ å»ºè®®
- **è–ªé…¬è¯„ä¼°**ï¼šå¸‚åœºè¡Œæƒ…åˆ†æã€ä¸åŒè§„æ¨¡ä¼ä¸šè–ªé…¬èŒƒå›´ã€å€™é€‰äººå½“å‰è–ªé…¬è¯„ä¼°ã€è–ªé…¬æå‡è·¯å¾„
- **é¢„æœŸç®¡ç†**ï¼šè¯†åˆ«ä¸åˆç†é¢„æœŸã€æ¨èåˆé€‚èµ·å§‹å²—ä½çº§åˆ«ã€ç‰¹å®šè–ªèµ„æ‰€éœ€ç»éªŒå¹´é™
- **æˆé•¿å»ºè®®**ï¼šå¿ƒæ€å»ºè®¾ã€å¿…å¤‡æŠ€èƒ½æ¸…å•ã€ä¸åŒä¼ä¸šè§„æ¨¡è¦æ±‚åˆ†æã€å­¦ä¹ æå‡æ–¹å‘
- **å¤šæ¨¡æ€**ï¼šé£æ ¼æ ‡ç­¾ã€å½¢è±¡è¯„åˆ†ã€è¡Œä¸ºæ£€æµ‹

### å¤„ç†æ–¹å¼
- **7+Næ¬¡AIè°ƒç”¨**ï¼ˆN=è€ƒæ ¸ç»´åº¦æ•°é‡ï¼Œé€šå¸¸5-10ä¸ªï¼‰
- è‡ªé€‚åº”æŠ½å–ç»´åº¦ï¼Œé€é¡¹ç‹¬ç«‹è¯„åˆ†
- å²—ä½é€‚é…åº¦åˆ†æ + èŒä¸šå‘å±•è§„åˆ’ï¼ˆ1æ¬¡AIè°ƒç”¨ï¼‰
- æ€§æ ¼æ·±åº¦åˆ†æï¼ˆ1æ¬¡AIè°ƒç”¨ï¼‰
- è–ªé…¬å¸‚åœºè¯„ä¼°ï¼ˆ1æ¬¡AIè°ƒç”¨ï¼Œä½¿ç”¨Qwenè”ç½‘æœç´¢èƒ½åŠ›ï¼‰
- é¢„æœŸç®¡ç†åˆ†æï¼ˆèå…¥è–ªé…¬è¯„ä¼°ä¸­ï¼‰
- å¤šæ¨¡æ€åˆ†æï¼ˆæ”¯æŒè§†é¢‘/å›¾ç‰‡ï¼‰

## ğŸ’» æ ¸å¿ƒå®ç°

### æ–‡ä»¶ç»“æ„
```
service/
â”œâ”€â”€ AIInterviewAssessor.py    # æ ¸å¿ƒæœåŠ¡ï¼ˆ327è¡Œï¼‰
â””â”€â”€ multimodal_report.py       # å¤šæ¨¡æ€åˆ†æï¼ˆ100è¡Œï¼‰
routers/
â””â”€â”€ interview_report_router.py # APIè·¯ç”±ï¼ˆ97è¡Œï¼‰
```

### æ ¸å¿ƒæµç¨‹ï¼ˆ9æ­¥ï¼‰
```python
def generate_report(transcript, jd, interview_id, url_list, is_mp4, language):
    # æ­¥éª¤1: æŠ½å–è€ƒæ ¸ç»´åº¦ (1æ¬¡AIè°ƒç”¨)
    competencies = _extract_competencies(jd, transcript)
    # è¾“å‡º: {hard_skills: [...], soft_skills: [...], cultural_fit: [...]}
    
    # æ­¥éª¤2: é€é¡¹èƒ½åŠ›è¯„ä¼° (Næ¬¡AIè°ƒç”¨)
    for competency in all_competency_keys:
        result = _analyze_single_competency(competency, transcript)
        # è¾“å‡º: {score: 85, rationale: "...", evidence_quotes: [...]}
    
    # æ­¥éª¤3: å²—ä½é€‚é…åº¦åˆ†æ + èŒä¸šå‘å±•è§„åˆ’ (1æ¬¡AIè°ƒç”¨)
    job_match = _analyze_job_match_and_career(detailed_analysis, jd, transcript)
    # è¾“å‡º: {
    #   current_job_match_score: 78.5,
    #   capability_gaps: {hard_skills: [...], soft_skills: [...]},
    #   alternative_jobs: [
    #     {type: "æ¨ªå‘", job_title: "...", match_percentage: 85, reason: "..."},
    #     {type: "çºµå‘", job_title: "...", match_percentage: 70, reason: "..."}
    #   ]
    # }
    
    # æ­¥éª¤4: æ€§æ ¼æ·±åº¦åˆ†æ (1æ¬¡AIè°ƒç”¨)
    personality = _analyze_personality(jd, transcript)
    # è¾“å‡º: {
    #   job_personality_requirements: "...",
    #   candidate_personality_traits: "...",
    #   concrete_shaping_suggestions: [...]
    # }
    
    # æ­¥éª¤5: è–ªé…¬å¸‚åœºè¯„ä¼° (1æ¬¡AIè°ƒç”¨ï¼Œå¯ç”¨è”ç½‘æœç´¢)
    salary = _analyze_salary_market(jd, transcript, detailed_analysis)
    # è¾“å‡º: {
    #   market_analysis: "...",
    #   salary_ranges: {
    #     fortune_500: "20-30K",
    #     mid_size: "15-25K",
    #     startup: "12-20K"
    #   },
    #   candidate_salary_assessment: "18-22K",
    #   salary_growth_path: "...",
    #   expectation_management: {
    #     is_expectation_reasonable: true/false,
    #     recommended_starting_level: "...",
    #     experience_required_for_target_salary: "..."
    #   }
    # }
    
    # æ­¥éª¤6: ç”ŸæˆHRæ€»ç»“ (1æ¬¡AIè°ƒç”¨)
    summary = _generate_final_summary(detailed_analysis, job_match, personality, salary)
    # è¾“å‡º: {highlights: "...", risks: "...", conclusion: "T2-èƒœä»»..."}
    
    # æ­¥éª¤7: å¤šæ¨¡æ€åˆ†æ (1æ¬¡AIè°ƒç”¨, qwen-vl-max-latest)
    style = style_report(url_list, interview_id, is_mp4, language)
    # è¾“å‡º: {style: "èŒä¸šå¹²ç»ƒ", description: "...", appearance: "82åˆ†..."}
    
    # æ­¥éª¤8: ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š (1æ¬¡AIè°ƒç”¨)
    user_report = _user_report(jd, transcript, hr_report, personality, salary)
    # è¾“å‡º: {
    #   highlights, insufficient, 
    #   short_term_actions, long_term_actions,
    #   mindset_building: "...",
    #   essential_skills_checklist: [...],
    #   company_size_requirements: {...},
    #   learning_directions: [...]
    # }
    
    # æ­¥éª¤9: èšåˆæœ€ç»ˆæŠ¥å‘Š â†’ å­˜å…¥æ•°æ®åº“
    return final_report
```

## ğŸŒ APIæ¥å£

**POST** `/interviewReport`

### è¯·æ±‚
```json
{
  "interview_id": "123456",
  "transcript": [
    {"role": "interviewer", "content": "ä»‹ç»ä½ çš„Pythonç»éªŒ", "timestamp": 1},
    {"role": "candidate", "content": "æˆ‘æœ‰3å¹´Pythonå¼€å‘ç»éªŒ...", "timestamp": 2}
  ],
  "jd": "å²—ä½èŒè´£ï¼š\n1. åç«¯å¼€å‘\nä»»èŒè¦æ±‚ï¼š\n1. 3å¹´Pythonç»éªŒ",
  "interview_language": "zhongwen",
  "p_url": ["http://example.com/img1.png"],  // å›¾ç‰‡URL
  "v_url": ["http://example.com/video.mp4"]   // è§†é¢‘URL
}
```

### å“åº”ï¼ˆç«‹å³è¿”å›ï¼Œåå°å¼‚æ­¥ç”Ÿæˆï¼‰
```json
{
  "code": 0,
  "message": "success",
  "data": ""
}
```

### æœ€ç»ˆæŠ¥å‘Šç»“æ„ï¼ˆå­˜å…¥æ•°æ®åº“ï¼‰
```json
{
  "overall_assessment": {
    "match_score": 78.5,
    "conclusion": "T2-èƒœä»»ï¼Œå®šä¹‰ï¼šç¬¦åˆé¢„æœŸã€‚å»ºè®®å½•ç”¨ã€‚",
    "highlights": "æŠ€æœ¯åŸºç¡€æ‰å®ï¼Œæ²Ÿé€šæ¸…æ™°",
    "potential_risks": "ç¼ºä¹æ¶æ„ç»éªŒ"
  },
  "detailed_analysis": [
    {
      "competency": "Pythonå¼€å‘èƒ½åŠ›",
      "score": 85,
      "rationale": "æ‰å®çš„å¼€å‘åŸºç¡€ï¼Œç†Ÿæ‚‰Djangoæ¡†æ¶",
      "evidence_quotes": ["æˆ‘ä¸»å¯¼äº†è®¢å•ç³»ç»Ÿå¼€å‘", "æ—¥å‡100ä¸‡è¯·æ±‚é‡"]
    }
  ],
  "competency_model_used": {
    "hard_skills": ["Pythonå¼€å‘", "æ•°æ®åº“è®¾è®¡"],
    "soft_skills": ["æ²Ÿé€šèƒ½åŠ›"],
    "cultural_fit": ["å­¦ä¹ æ€åº¦"]
  },
  "job_match_analysis": {
    "current_job_match_score": 78.5,
    "capability_gaps": {
      "hard_skills": ["æ¶æ„è®¾è®¡ç»éªŒä¸è¶³", "å¾®æœåŠ¡å®æˆ˜ç»éªŒç¼ºä¹"],
      "soft_skills": ["å›¢é˜Ÿç®¡ç†ç»éªŒæœ‰é™"]
    },
    "alternative_jobs": [
      {
        "type": "æ¨ªå‘",
        "job_title": "å…¨æ ˆå¼€å‘å·¥ç¨‹å¸ˆ",
        "match_percentage": 85,
        "reason": "åç«¯èƒ½åŠ›æ‰å®ï¼Œè¡¥å……å‰ç«¯æŠ€èƒ½åå¯èƒœä»»å…¨æ ˆå²—ä½"
      },
      {
        "type": "çºµå‘",
        "job_title": "æŠ€æœ¯ä¸»ç®¡/Team Leader",
        "match_percentage": 65,
        "reason": "æŠ€æœ¯èƒ½åŠ›è¾¾æ ‡ï¼Œéœ€è¡¥å……å›¢é˜Ÿç®¡ç†å’Œæ¶æ„è®¾è®¡èƒ½åŠ›"
      }
    ]
  },
  "personality_analysis": {
    "job_personality_requirements": "è¯¥å²—ä½éœ€è¦è¾ƒå¼ºçš„é€»è¾‘æ€ç»´ã€é—®é¢˜è§£å†³èƒ½åŠ›ã€å›¢é˜Ÿåä½œç²¾ç¥å’ŒæŒç»­å­¦ä¹ æ„æ„¿",
    "candidate_personality_traits": "å€™é€‰äººå±•ç°å‡ºè¾ƒå¼ºçš„æŠ€æœ¯çƒ­æƒ…ã€è‰¯å¥½çš„è¡¨è¾¾èƒ½åŠ›ã€ç§¯æçš„å­¦ä¹ æ€åº¦ï¼Œæ€§æ ¼åå†…æ•›ä½†ä¸“ä¸šæ²Ÿé€šæ¸…æ™°",
    "concrete_shaping_suggestions": [
      "å¢å¼ºä¸»åŠ¨æ²Ÿé€šæ„è¯†ï¼Œåœ¨å›¢é˜Ÿä¸­å¤šåˆ†äº«æŠ€æœ¯è§è§£",
      "åŸ¹å…»å…¨å±€è§†è§’ï¼Œä»ä¸šåŠ¡è§’åº¦æ€è€ƒæŠ€æœ¯æ–¹æ¡ˆ",
      "æå‡æŠ—å‹èƒ½åŠ›ï¼Œåœ¨é«˜å‹ç¯å¢ƒä¸‹ä¿æŒå†·é™åˆ¤æ–­"
    ]
  },
  "salary_analysis": {
    "market_analysis": "æ ¹æ®2024å¹´å¸‚åœºæ•°æ®ï¼Œ3å¹´Pythonåç«¯å¼€å‘å·¥ç¨‹å¸ˆåœ¨ä¸€çº¿åŸå¸‚çš„è–ªèµ„åŒºé—´ä¸º15-30Kï¼Œå…·ä½“å–å†³äºå…¬å¸è§„æ¨¡ã€æŠ€æœ¯æ ˆæ·±åº¦å’Œé¡¹ç›®ç»éªŒ",
    "salary_ranges": {
      "fortune_500": "20-30Kï¼ˆå¤§å‚ï¼Œè¦æ±‚é«˜ï¼Œç¦åˆ©å¥½ï¼‰",
      "mid_size": "15-25Kï¼ˆä¸­å‹ä¼ä¸šï¼Œå¸‚åœºä¸»æµï¼‰",
      "startup": "12-22Kï¼ˆåˆ›ä¸šå…¬å¸ï¼Œè‚¡æƒæ¿€åŠ±ä¸ºä¸»ï¼‰"
    },
    "candidate_salary_assessment": "18-22K",
    "salary_growth_path": "1å¹´å†…é€šè¿‡è¡¥å……æ¶æ„èƒ½åŠ›è¾¾åˆ°22-28Kï¼›3å¹´å†…æ™‹å‡é«˜çº§å·¥ç¨‹å¸ˆå¯è¾¾30-40Kï¼›5å¹´å†…è½¬å‘æ¶æ„å¸ˆå¯è¾¾40-60K",
    "expectation_management": {
      "is_expectation_reasonable": true,
      "recommended_starting_level": "ä¸­çº§åç«¯å·¥ç¨‹å¸ˆï¼ˆ3-5å¹´ç»éªŒï¼‰",
      "experience_required_for_target_salary": "å¦‚æœŸæœ›25K+ï¼Œéœ€è¦5å¹´ä»¥ä¸Šç»éªŒæˆ–å…·å¤‡æ¶æ„è®¾è®¡èƒ½åŠ›"
    }
  },
  "style_report": {
    "style": "èŒä¸šå¹²ç»ƒ",
    "description": "çœ¼ç¥è‡ªä¿¡ï¼Œç€è£…å¾—ä½“",
    "behavior": "æœªå‘ç°å¼‚å¸¸",
    "appearance": "82åˆ†ã€‚äº”å®˜ç«¯æ­£ï¼Œæ­£è£…æ•´æ´"
  },
  "user_report": {
    "highlights": "ä½ çš„æŠ€æœ¯è¡¨è¾¾æ¸…æ™°ï¼ŒPythonåŸºç¡€æ‰å®ï¼Œé¡¹ç›®ç»éªŒä¸°å¯Œ...",
    "insufficient": "æ¶æ„è®¾è®¡å¯ä»¥æ›´æœ‰æ¡ç†ï¼Œå›¢é˜Ÿåä½œç»éªŒéœ€è¦åŠ å¼º...",
    "short_term_actions": ["æ¯å¤©ç»ƒä¹ 1ä¸ªç®—æ³•é¢˜", "å‡†å¤‡3ä¸ªSTARè¯æœ¯", "å­¦ä¹ ç³»ç»Ÿè®¾è®¡åŸºç¡€"],
    "long_term_actions": ["å­¦ä¹ åˆ†å¸ƒå¼ç³»ç»Ÿ", "å‚ä¸å¼€æºé¡¹ç›®", "åŸ¹å…»å›¢é˜Ÿç®¡ç†èƒ½åŠ›"],
    "mindset_building": "ä¿æŒæŠ€æœ¯çƒ­æƒ…çš„åŒæ—¶ï¼ŒåŸ¹å…»ä¸šåŠ¡æ€ç»´å’Œå…¨å±€è§†è§’ã€‚é¢è¯•æ˜¯åŒå‘é€‰æ‹©ï¼Œè‡ªä¿¡å±•ç°è‡ªå·±çš„åŒæ—¶ä¹Ÿè¦è¯„ä¼°å…¬å¸æ˜¯å¦é€‚åˆè‡ªå·±ã€‚",
    "essential_skills_checklist": [
      "Pythoné«˜çº§ç‰¹æ€§ï¼ˆè£…é¥°å™¨ã€å…ƒç±»ã€å¹¶å‘ï¼‰",
      "æ•°æ®åº“ä¼˜åŒ–ï¼ˆç´¢å¼•ã€æŸ¥è¯¢ä¼˜åŒ–ã€åˆ†åº“åˆ†è¡¨ï¼‰",
      "ç¼“å­˜ç­–ç•¥ï¼ˆRedisã€æœ¬åœ°ç¼“å­˜ï¼‰",
      "å¾®æœåŠ¡æ¶æ„ï¼ˆæœåŠ¡æ‹†åˆ†ã€APIè®¾è®¡ã€æœåŠ¡æ²»ç†ï¼‰",
      "ç³»ç»Ÿè®¾è®¡èƒ½åŠ›ï¼ˆé«˜å¹¶å‘ã€é«˜å¯ç”¨ã€å¯æ‰©å±•æ€§ï¼‰"
    ],
    "company_size_requirements": {
      "fortune_500": "è¦æ±‚ç®—æ³•ã€ç³»ç»Ÿè®¾è®¡æ·±åº¦ï¼Œæ³¨é‡æŠ€æœ¯å¹¿åº¦å’Œåä½œèƒ½åŠ›",
      "mid_size": "æ³¨é‡ä¸šåŠ¡å®ç°èƒ½åŠ›å’Œå¿«é€Ÿå­¦ä¹ èƒ½åŠ›ï¼Œè¦æ±‚ç›¸å¯¹å‡è¡¡",
      "startup": "å¼ºè°ƒå¿«é€Ÿäº¤ä»˜å’Œå¤šé¢æ‰‹èƒ½åŠ›ï¼Œå¯æ¥å—æŸäº›æ–¹é¢ç»éªŒä¸è¶³"
    },
    "learning_directions": [
      "æ·±åº¦æ–¹å‘ï¼šæ·±å…¥ç ”ç©¶é«˜æ€§èƒ½Pythonï¼ˆå¼‚æ­¥ç¼–ç¨‹ã€æ€§èƒ½ä¼˜åŒ–ï¼‰",
      "å¹¿åº¦æ–¹å‘ï¼šå­¦ä¹ å‰ç«¯åŸºç¡€ã€DevOpsã€äº‘åŸç”ŸæŠ€æœ¯",
      "è½¯æŠ€èƒ½æ–¹å‘ï¼šæŠ€æœ¯å†™ä½œã€æ¼”è®²è¡¨è¾¾ã€é¡¹ç›®ç®¡ç†"
    ],
    "Quantitative": "æ¯å‘¨2æ¬¡æ¨¡æ‹Ÿé¢è¯•ï¼Œæ¯æœˆå®Œæˆ1ä¸ªç³»ç»Ÿè®¾è®¡æ¡ˆä¾‹ï¼Œæ¯å­£åº¦è¾“å‡º1ç¯‡æŠ€æœ¯åšå®¢",
    "career_advice": "çŸ­æœŸï¼ˆ1å¹´å†…ï¼‰ï¼šå·©å›ºåç«¯åŸºç¡€ï¼Œè¡¥å……æ¶æ„èƒ½åŠ›ï¼Œäº‰å–æ™‹å‡ä¸­é«˜çº§å·¥ç¨‹å¸ˆã€‚ä¸­æœŸï¼ˆ3å¹´å†…ï¼‰ï¼šæ·±å…¥æŸä¸ªæŠ€æœ¯é¢†åŸŸï¼ˆå¦‚åˆ†å¸ƒå¼/é«˜å¹¶å‘ï¼‰ï¼ŒåŒæ—¶åŸ¹å…»å›¢é˜Ÿåä½œå’ŒæŠ€æœ¯å½±å“åŠ›ã€‚é•¿æœŸï¼ˆ5å¹´+ï¼‰ï¼šå‘æ¶æ„å¸ˆæˆ–æŠ€æœ¯ç®¡ç†æ–¹å‘å‘å±•ã€‚",
    "other": "ä¿æŒå­¦ä¹ èŠ‚å¥ï¼Œæ³¨é‡æŠ€æœ¯æ·±åº¦å’Œå¹¿åº¦çš„å¹³è¡¡ã€‚å»ºè®®åŠ å…¥æŠ€æœ¯ç¤¾åŒºï¼Œå¤šä¸è¡Œä¸šå†…äººå£«äº¤æµï¼Œæ‹“å±•è§†é‡ã€‚"
  }
}
```

## ğŸ”§ æŠ€æœ¯ç»†èŠ‚

### LLMé…ç½®
```python
# æ–‡æœ¬åˆ†ææ¨¡å‹
model = "qwen-plus"
temperature = 0.3
seed = 6
response_format = {"type": "json_object"}

# å¤šæ¨¡æ€æ¨¡å‹
multimodal_model = "qwen-vl-max-latest"

# è–ªé…¬å¸‚åœºåˆ†ææ¨¡å‹ï¼ˆå¯ç”¨è”ç½‘æœç´¢ï¼‰
salary_analysis_model = "qwen-plus"
enable_search = True  # å¯ç”¨Qwençš„è”ç½‘æœç´¢å·¥å…·
```

### é‡è¦æœºåˆ¶
- **é‡è¯•æœºåˆ¶**ï¼šå…³é”®AIè°ƒç”¨å¤±è´¥è‡ªåŠ¨é‡è¯•1æ¬¡
- **å¤šæ¨¡æ€ä¿åº•**ï¼šè§†é¢‘åˆ†æå¤±è´¥é™çº§ä¸ºæ–‡æœ¬åˆ†æ
- **å¼‚æ­¥å¤„ç†**ï¼šFastAPI BackgroundTasksåå°ç”Ÿæˆ
- **é˜²é‡å¤**ï¼š10åˆ†é’Ÿå†…åŒinterview_idä¸é‡å¤ç”Ÿæˆ
- **è”ç½‘æœç´¢**ï¼šè–ªé…¬åˆ†æå¯ç”¨Qwenæœç´¢å·¥å…·ï¼Œå®æ—¶è·å–å¸‚åœºæ•°æ®
- **æœç´¢é™çº§**ï¼šè”ç½‘æœç´¢å¤±è´¥æ—¶ï¼ŒåŸºäºLLMå†…ç½®çŸ¥è¯†ç»™å‡ºå‚è€ƒå»ºè®®ï¼ˆæ ‡æ³¨"åŸºäºå†å²æ•°æ®"ï¼‰

### æ”¯æŒçš„è¯­è¨€
zhongwenã€yingwenã€riyuã€hanyuã€xibanyayuã€yinniyuã€fayuã€deyuã€taiyu

## ğŸ“Š å…³é”®æŒ‡æ ‡

- **AIè°ƒç”¨æ¬¡æ•°**ï¼šé€šå¸¸12-19æ¬¡ï¼ˆ7å›ºå®š + 5-10ç»´åº¦è¯„ä¼° + 2æ–°å¢åˆ†æï¼‰
- **ç”Ÿæˆè€—æ—¶**ï¼š4-6åˆ†é’Ÿï¼ˆæ–°å¢è”ç½‘æœç´¢å’Œæ·±åº¦åˆ†æï¼‰
- **æˆåŠŸç‡**ï¼š>95%ï¼ˆå¤šå±‚é‡è¯•ä¿éšœï¼‰
- **è¯„çº§ä½“ç³»**ï¼šT0å“è¶Š / T1å¨´ç†Ÿ / T2èƒœä»» / T3å¾…åŸ¹å…» / T4å·®è·è¾ƒå¤§

## ğŸ†• æ–°å¢åŠŸèƒ½è¯´æ˜ï¼ˆé˜¶æ®µ1+2ï¼‰

### é˜¶æ®µ1ï¼šå¢å¼ºç°æœ‰åŠŸèƒ½
1. **å²—ä½é€‚é…åº¦æ˜ç¡®è¯„åˆ†**
   - ä»åŸæœ‰çš„ç»¼åˆè¯„åˆ†ä¸­ç‹¬ç«‹å‡ºæ¥
   - ç»™å‡ºæ¸…æ™°çš„ç™¾åˆ†åˆ¶é€‚é…åº¦åˆ†æ•°
   - è¯¦ç»†åˆ—å‡ºç¡¬æŠ€èƒ½å’Œè½¯æŠ€èƒ½çš„å·®è·

2. **æ€§æ ¼åˆ†æç‹¬ç«‹æ¨¡å—åŒ–**
   - ä»è½¯æŠ€èƒ½è¯„ä¼°ä¸­ç‹¬ç«‹å‡ºæ¥
   - åˆ†æå²—ä½å¯¹æ€§æ ¼çš„å…·ä½“è¦æ±‚
   - ç»™å‡ºå…·è±¡åŒ–çš„æ€§æ ¼å¡‘é€ å»ºè®®ï¼ˆå¯æ“ä½œæ€§å¼ºï¼‰

3. **æˆé•¿å»ºè®®æ›´ç³»ç»ŸåŒ–**
   - å¿ƒæ€å»ºè®¾ï¼šå¿ƒç†å±‚é¢çš„æŒ‡å¯¼
   - å¿…å¤‡æŠ€èƒ½æ¸…å•ï¼šæŠ€æœ¯å±‚é¢çš„æå‡æ–¹å‘
   - ä¸åŒä¼ä¸šè§„æ¨¡è¦æ±‚åˆ†æï¼šå¸®åŠ©å€™é€‰äººé€‰æ‹©åˆé€‚çš„å…¬å¸
   - å­¦ä¹ æå‡æ–¹å‘ï¼šæ·±åº¦ã€å¹¿åº¦ã€è½¯æŠ€èƒ½ä¸‰ä¸ªç»´åº¦

### é˜¶æ®µ2ï¼šæ–°å¢èŒä¸šè§„åˆ’åŠŸèƒ½
1. **å²—ä½æ¨è**
   - æ¨ªå‘å‘å±•ï¼šåŒçº§åˆ«å…¶ä»–é€‚åˆçš„å²—ä½
   - çºµå‘å‘å±•ï¼šæ™‹å‡è·¯å¾„å’Œç›®æ ‡å²—ä½
   - æ¯ä¸ªæ¨èåŒ…å«åŒ¹é…åº¦ç™¾åˆ†æ¯”å’Œè¯¦ç»†ç†ç”±
   - åŸºäºLLMæ¨ç†ï¼Œæ— éœ€å¤æ‚ç®—æ³•

2. **è–ªé…¬å¸‚åœºè¯„ä¼°**ï¼ˆä½¿ç”¨Qwenè”ç½‘æœç´¢ï¼‰
   - å®æ—¶å¸‚åœºè¡Œæƒ…åˆ†æ
   - ä¸åŒè§„æ¨¡ä¼ä¸šï¼ˆ500å¼º/ä¸­å‹/åˆ›ä¸šï¼‰çš„è–ªé…¬èŒƒå›´
   - å€™é€‰äººå½“å‰è–ªé…¬è¯„ä¼°
   - è–ªé…¬æå‡è·¯å¾„å’Œæ—¶é—´è§„åˆ’

3. **é¢„æœŸç®¡ç†ç³»ç»Ÿ**
   - è¯†åˆ«å€™é€‰äººçš„ä¸åˆç†é¢„æœŸï¼ˆè–ªé…¬è¿‡é«˜/å²—ä½çº§åˆ«è¿‡é«˜ï¼‰
   - æ¨èåˆé€‚çš„èµ·å§‹å²—ä½çº§åˆ«
   - åˆ†æç‰¹å®šè–ªèµ„æ‰€éœ€çš„ç»éªŒå¹´é™
   - ç»™å‡ºç°å®å¯è¡Œçš„èŒä¸šå‘å±•å»ºè®®

---

**æ ¸å¿ƒåŸåˆ™**ï¼šè‡ªé€‚åº”ç»´åº¦æŠ½å– + é€é¡¹ç‹¬ç«‹è¯„ä¼° + åŒè§†è§’æŠ¥å‘Š + å¤šæ¨¡æ€å¢å¼º + èŒä¸šè§„åˆ’å¯¼å‘ + å¸‚åœºæ•°æ®é©±åŠ¨
```

å®Œæˆï¼ç°åœ¨è®©æˆ‘æŸ¥çœ‹ä¸€ä¸‹ä¿®æ”¹åçš„å®Œæ•´æ–‡æ¡£ï¼Œå¹¶ç»™ä½ ä¸€ä¸ªæ€»ç»“ï¼š

å®Œç¾ï¼æ–‡æ¡£ä¿®æ”¹å®Œæˆã€‚ç°åœ¨è®©æˆ‘ç»™ä½ ä¸€ä¸ªæ¸…æ™°çš„ä¿®æ”¹æ€»ç»“ï¼š

## âœ… ä¿®æ”¹å®Œæˆæ€»ç»“

### ğŸ“ ä¿®æ”¹çš„æ–‡ä»¶
- `project_code/career/docs/specs/evaluation-report/evaluation-report-ultra-simple-spec.md`

---

## ğŸ”„ æ ¸å¿ƒä¿®æ”¹ç‚¹ï¼ˆå…±7å¤„ï¼‰

### 1ï¸âƒ£ **æ ¸å¿ƒæ€è·¯æ‰©å±•**ï¼ˆç¬¬5è¡Œï¼‰
**åŸå†…å®¹**ï¼š
```
è‡ªé€‚åº”æŠ½å–è€ƒæ ¸ç»´åº¦ â†’ é€é¡¹æ‰“åˆ†è¯„ä¼° â†’ ç»¼åˆæ€»ç»“æŠ¥å‘Š â†’ å¤šæ¨¡æ€é£æ ¼åˆ†æ â†’ å€™é€‰äººåé¦ˆ
```

**æ–°å†…å®¹**ï¼š
```
è‡ªé€‚åº”æŠ½å–è€ƒæ ¸ç»´åº¦ â†’ é€é¡¹æ‰“åˆ†è¯„ä¼° â†’ å²—ä½é€‚é…åº¦åˆ†æ â†’ æ€§æ ¼æ·±åº¦åˆ†æ â†’ 
èŒä¸šå‘å±•è§„åˆ’ â†’ è–ªé…¬å¸‚åœºè¯„ä¼° â†’ ç»¼åˆæ€»ç»“æŠ¥å‘Š â†’ å¤šæ¨¡æ€é£æ ¼åˆ†æ â†’ å€™é€‰äººåé¦ˆ
```

---

### 2ï¸âƒ£ **è¾“å‡ºå†…å®¹æ‰©å±•**ï¼ˆç¬¬15-24è¡Œï¼‰
**æ–°å¢è¾“å‡º**ï¼š
- âœ… å²—ä½é€‚é…åº¦ï¼šå½“å‰å²—ä½åŒ¹é…åˆ†å€¼ã€èƒ½åŠ›å·®è·åˆ†æ
- âœ… èŒä¸šå‘å±•ï¼šæ¨ªå‘/çºµå‘å²—ä½æ¨è + æ¨èç™¾åˆ†æ¯” + æ¨èç†ç”±
- âœ… æ€§æ ¼åˆ†æï¼šå²—ä½æ€§æ ¼è¦æ±‚ã€å€™é€‰äººæ€§æ ¼ç‰¹å¾ã€å…·è±¡åŒ–å¡‘é€ å»ºè®®
- âœ… è–ªé…¬è¯„ä¼°ï¼šå¸‚åœºè¡Œæƒ…ã€ä¸åŒè§„æ¨¡ä¼ä¸šè–ªé…¬èŒƒå›´ã€å€™é€‰äººè–ªé…¬è¯„ä¼°ã€æå‡è·¯å¾„
- âœ… é¢„æœŸç®¡ç†ï¼šè¯†åˆ«ä¸åˆç†é¢„æœŸã€æ¨èèµ·å§‹å²—ä½çº§åˆ«ã€è–ªèµ„æ‰€éœ€ç»éªŒ
- âœ… æˆé•¿å»ºè®®ï¼šå¿ƒæ€å»ºè®¾ã€å¿…å¤‡æŠ€èƒ½æ¸…å•ã€ä¼ä¸šè§„æ¨¡è¦æ±‚ã€å­¦ä¹ æ–¹å‘

---

### 3ï¸âƒ£ **å¤„ç†æ–¹å¼æ›´æ–°**ï¼ˆç¬¬26-33è¡Œï¼‰
**åŸå†…å®¹**ï¼š3+Næ¬¡AIè°ƒç”¨
**æ–°å†…å®¹**ï¼š7+Næ¬¡AIè°ƒç”¨

**æ–°å¢æ­¥éª¤**ï¼š
- å²—ä½é€‚é…åº¦åˆ†æ + èŒä¸šå‘å±•è§„åˆ’ï¼ˆ1æ¬¡AIè°ƒç”¨ï¼‰
- æ€§æ ¼æ·±åº¦åˆ†æï¼ˆ1æ¬¡AIè°ƒç”¨ï¼‰
- è–ªé…¬å¸‚åœºè¯„ä¼°ï¼ˆ1æ¬¡AIè°ƒç”¨ï¼Œ**ä½¿ç”¨Qwenè”ç½‘æœç´¢èƒ½åŠ›**ï¼‰
- é¢„æœŸç®¡ç†åˆ†æï¼ˆèå…¥è–ªé…¬è¯„ä¼°ä¸­ï¼‰

---

### 4ï¸âƒ£ **æ ¸å¿ƒæµç¨‹æ‰©å±•**ï¼ˆç¬¬46-116è¡Œï¼‰
**åŸæµç¨‹**ï¼š5æ­¥
**æ–°æµç¨‹**ï¼š9æ­¥

**æ–°å¢æ­¥éª¤è¯¦æƒ…**ï¼š
- **æ­¥éª¤3**ï¼šå²—ä½é€‚é…åº¦åˆ†æ + èŒä¸šå‘å±•è§„åˆ’
  - è¾“å‡ºé€‚é…åº¦åˆ†æ•°ã€èƒ½åŠ›å·®è·ã€æ¨ªå‘/çºµå‘å²—ä½æ¨è
- **æ­¥éª¤4**ï¼šæ€§æ ¼æ·±åº¦åˆ†æ
  - å²—ä½æ€§æ ¼è¦æ±‚ã€å€™é€‰äººç‰¹å¾ã€å…·è±¡åŒ–å¡‘é€ å»ºè®®
- **æ­¥éª¤5**ï¼šè–ªé…¬å¸‚åœºè¯„ä¼°ï¼ˆå¯ç”¨è”ç½‘æœç´¢ï¼‰
  - å¸‚åœºåˆ†æã€ä¸åŒè§„æ¨¡ä¼ä¸šè–ªé…¬ã€å€™é€‰äººè¯„ä¼°ã€æå‡è·¯å¾„ã€é¢„æœŸç®¡ç†

---

### 5ï¸âƒ£ **æœ€ç»ˆæŠ¥å‘Šç»“æ„å¤§å¹…æ‰©å±•**ï¼ˆç¬¬146-247è¡Œï¼‰
**æ–°å¢3ä¸ªé¡¶çº§å­—æ®µ**ï¼š

#### a) `job_match_analysis`ï¼ˆå²—ä½åŒ¹é…åˆ†æï¼‰
```json
{
  "current_job_match_score": 78.5,
  "capability_gaps": {...},
  "alternative_jobs": [æ¨ªå‘/çºµå‘æ¨è]
}
```

#### b) `personality_analysis`ï¼ˆæ€§æ ¼åˆ†æï¼‰
```json
{
  "job_personality_requirements": "...",
  "candidate_personality_traits": "...",
  "concrete_shaping_suggestions": [...]
}
```

#### c) `salary_analysis`ï¼ˆè–ªé…¬åˆ†æï¼‰â­ æ ¸å¿ƒæ–°å¢
```json
{
  "market_analysis": "...",
  "salary_ranges": {
    "fortune_500": "20-30K",
    "mid_size": "15-25K", 
    "startup": "12-22K"
  },
  "candidate_salary_assessment": "18-22K",
  "salary_growth_path": "...",
  "expectation_management": {...}
}
```

#### d) `user_report` å¢å¼º
**æ–°å¢å­—æ®µ**ï¼š
- `mindset_building`ï¼šå¿ƒæ€å»ºè®¾
- `essential_skills_checklist`ï¼šå¿…å¤‡æŠ€èƒ½æ¸…å•
- `company_size_requirements`ï¼šä¸åŒä¼ä¸šè§„æ¨¡è¦æ±‚
- `learning_directions`ï¼šå­¦ä¹ æå‡æ–¹å‘

---

### 6ï¸âƒ£ **LLMé…ç½®æ–°å¢**ï¼ˆç¬¬251-265è¡Œï¼‰
**æ–°å¢é…ç½®**ï¼š
```python
# è–ªé…¬å¸‚åœºåˆ†ææ¨¡å‹ï¼ˆå¯ç”¨è”ç½‘æœç´¢ï¼‰
salary_analysis_model = "qwen-plus"
enable_search = True  # å¯ç”¨Qwençš„è”ç½‘æœç´¢å·¥å…·
```

---

### 7ï¸âƒ£ **æŠ€æœ¯æœºåˆ¶æ–°å¢**ï¼ˆç¬¬267-273è¡Œï¼‰
**æ–°å¢æœºåˆ¶**ï¼š
- âœ… **è”ç½‘æœç´¢**ï¼šè–ªé…¬åˆ†æå¯ç”¨Qwenæœç´¢å·¥å…·ï¼Œå®æ—¶è·å–å¸‚åœºæ•°æ®
- âœ… **æœç´¢é™çº§**ï¼šè”ç½‘æœç´¢å¤±è´¥æ—¶ï¼ŒåŸºäºLLMå†…ç½®çŸ¥è¯†ç»™å‡ºå‚è€ƒå»ºè®®ï¼ˆæ ‡æ³¨"åŸºäºå†å²æ•°æ®"ï¼‰

---

### 8ï¸âƒ£ **å…³é”®æŒ‡æ ‡æ›´æ–°**ï¼ˆç¬¬278-283è¡Œï¼‰
**æ›´æ–°å†…å®¹**ï¼š
- AIè°ƒç”¨æ¬¡æ•°ï¼š8-15æ¬¡ â†’ **12-19æ¬¡**
- ç”Ÿæˆè€—æ—¶ï¼š3-5åˆ†é’Ÿ â†’ **4-6åˆ†é’Ÿ**

---

### 9ï¸âƒ£ **æ–°å¢å®Œæ•´çš„åŠŸèƒ½è¯´æ˜ç« èŠ‚**ï¼ˆç¬¬285-325è¡Œï¼‰â­ å…¨æ–°
è¯¦ç»†è¯´æ˜äº†ï¼š
- **é˜¶æ®µ1ï¼šå¢å¼ºç°æœ‰åŠŸèƒ½**ï¼ˆ3ä¸ªå­åŠŸèƒ½ï¼‰
- **é˜¶æ®µ2ï¼šæ–°å¢èŒä¸šè§„åˆ’åŠŸèƒ½**ï¼ˆ3ä¸ªå­åŠŸèƒ½ï¼‰
- æ¯ä¸ªåŠŸèƒ½çš„å…·ä½“å†…å®¹å’Œå®ç°æ–¹å¼

---

## ğŸ“Š ä¿®æ”¹ç»Ÿè®¡

| é¡¹ç›® | åŸå†…å®¹ | æ–°å†…å®¹ | å˜åŒ– |
|------|--------|--------|------|
| æ–‡æ¡£æ€»è¡Œæ•° | 164è¡Œ | 325è¡Œ | +161è¡Œ |
| æ ¸å¿ƒæµç¨‹æ­¥éª¤ | 5æ­¥ | 9æ­¥ | +4æ­¥ |
| AIè°ƒç”¨æ¬¡æ•° | 8-15æ¬¡ | 12-19æ¬¡ | +4-7æ¬¡ |
| æŠ¥å‘Šé¡¶çº§å­—æ®µ | 5ä¸ª | 8ä¸ª | +3ä¸ª |
| è¾“å‡ºç»´åº¦ | 3ä¸ª | 9ä¸ª | +6ä¸ª |
| ç”Ÿæˆè€—æ—¶ | 3-5åˆ†é’Ÿ | 4-6åˆ†é’Ÿ | +1åˆ†é’Ÿ |

---

## âœ¨ å…³é”®ç‰¹æ€§

1. âœ… **ä¿æŒåŸæœ‰é£æ ¼**ï¼šæ–‡æ¡£ç»“æ„ã€æ ¼å¼ã€ä»£ç ç¤ºä¾‹é£æ ¼å®Œå…¨ä¸€è‡´
2. âœ… **æ¸…æ™°çš„é˜¶æ®µåˆ’åˆ†**ï¼šæ˜ç¡®åŒºåˆ†é˜¶æ®µ1ï¼ˆå¢å¼ºï¼‰å’Œé˜¶æ®µ2ï¼ˆæ–°å¢ï¼‰
3. âœ… **å®Œæ•´çš„æ•°æ®ç»“æ„**ï¼šæä¾›äº†è¯¦ç»†çš„JSONè¾“å‡ºç¤ºä¾‹
4. âœ… **æŠ€æœ¯å®ç°æ˜ç¡®**ï¼šæ˜ç¡®æŒ‡å®šä½¿ç”¨Qwenè”ç½‘æœç´¢åŠŸèƒ½
5. âœ… **é™çº§ç­–ç•¥è€ƒè™‘**ï¼šè”ç½‘æœç´¢å¤±è´¥æœ‰ä¿åº•æ–¹æ¡ˆ

---

## ğŸ¯ å¯ä»¥ç›´æ¥ç”¨äºå¼€å‘

è¿™ä»½ä¿®æ”¹åçš„specæ–‡æ¡£ï¼š
- âœ… æ¸…æ™°å®šä¹‰äº†æ‰€æœ‰æ–°åŠŸèƒ½
- âœ… ç»™å‡ºäº†å®Œæ•´çš„æ•°æ®ç»“æ„
- âœ… è¯´æ˜äº†æŠ€æœ¯å®ç°æ–¹å¼
- âœ… ä¿æŒäº†ä¸ç°æœ‰ä»£ç çš„ä¸€è‡´æ€§

ä½ å¯ä»¥ç›´æ¥åŸºäºè¿™ä¸ªspecè¿›è¡Œä»£ç å®ç°äº†ï¼éœ€è¦æˆ‘å¸®ä½ åšä»€ä¹ˆå—ï¼Ÿ

```plaintext
è‡ªé€‚åº”æŠ½å–è€ƒæ ¸ç»´åº¦ â†’ é€é¡¹æ‰“åˆ†è¯„ä¼° â†’ ç»¼åˆæ€»ç»“æŠ¥å‘Š â†’ å¤šæ¨¡æ€é£æ ¼åˆ†æ â†’ å€™é€‰äººåé¦ˆ
```

```plaintext
è‡ªé€‚åº”æŠ½å–è€ƒæ ¸ç»´åº¦ â†’ é€é¡¹æ‰“åˆ†è¯„ä¼° â†’ å²—ä½é€‚é…åº¦åˆ†æ â†’ æ€§æ ¼æ·±åº¦åˆ†æ â†’ 
èŒä¸šå‘å±•è§„åˆ’ â†’ è–ªé…¬å¸‚åœºè¯„ä¼° â†’ ç»¼åˆæ€»ç»“æŠ¥å‘Š â†’ å¤šæ¨¡æ€é£æ ¼åˆ†æ â†’ å€™é€‰äººåé¦ˆ
```

```json
{
  "current_job_match_score": 78.5,
  "capability_gaps": {...},
  "alternative_jobs": [æ¨ªå‘/çºµå‘æ¨è]
}
```

```json
{
  "job_personality_requirements": "...",
  "candidate_personality_traits": "...",
  "concrete_shaping_suggestions": [...]
}
```

```json
{
  "market_analysis": "...",
  "salary_ranges": {
    "fortune_500": "20-30K",
    "mid_size": "15-25K", 
    "startup": "12-22K"
  },
  "candidate_salary_assessment": "18-22K",
  "salary_growth_path": "...",
  "expectation_management": {...}
}
```

```python
# è–ªé…¬å¸‚åœºåˆ†ææ¨¡å‹ï¼ˆå¯ç”¨è”ç½‘æœç´¢ï¼‰
salary_analysis_model = "qwen-plus"
enable_search = True  # å¯ç”¨Qwençš„è”ç½‘æœç´¢å·¥å…·
```

---

**User**

æ•´ä¸ªé¡¹ç›®æœ‰ç‚¹ä¸å¤ªæ‡‚ï¼Œå°±æ˜¯è¿™ä¸ªé¡¹ç›®é¢è¯•æŠ¥å‘Šç”Ÿæˆçš„è§¦å‘æ—¶é—´æ˜¯ä»€ä¹ˆï¼Ÿæ˜¯æ€ä¹ˆè¢«è°ƒç”¨çš„å‘€ï¼Ÿç„¶åæˆ‘çš„ç†è§£æ˜¯é¢è¯•å®Œä»¥åè‡ªåŠ¨ç”Ÿæˆï¼Œä½†æ˜¯é¢è¯•å®Œä»¥åå®ƒç›´æ¥å›è°ƒè¿™ä¸ªç›¸åº”çš„é¢è¯•æŠ¥å‘Šçš„ä¸€ä¸ªæ¥å£å˜›ï¼Œå› ä¸ºæˆ‘ä»¬æ˜¯æœ‰ä¸€ä¸ªä¸“é—¨çš„é¢è¯•æŠ¥å‘Šçš„æ¥å£å•Šï¼Œå¥½åƒæ˜¯postè¯·æ±‚è¿™ä¸ªpostè¯·æ±‚æ˜¯å®¢æˆ·ç«¯å‘å—è¿˜æ˜¯è¯´ä»£ç è‡ªåŠ¨å›è°ƒäº†ï¼Ÿå¯¹æ­¤æˆ‘æœ‰ç‚¹å›°æƒ‘ï¼Œèƒ½ä¸èƒ½å¸®æˆ‘æ¢³ç†ä¸€ä¸‹ï¼Ÿ

---

**Cursor**

æŸ¥æ‰¾é¢è¯•æŠ¥å‘Šç”Ÿæˆçš„è§¦å‘æ—¶æœºå’Œè°ƒç”¨æµç¨‹ã€‚


ç»§ç»­æŸ¥æ‰¾é¢è¯•ç»“æŸåçš„è°ƒç”¨æµç¨‹ï¼š


æŸ¥çœ‹æŠ¥å‘Šç”Ÿæˆå®Œæˆåçš„å›è°ƒé€»è¾‘ï¼š


æŸ¥çœ‹æŠ¥å‘Šç”ŸæˆæˆåŠŸåçš„å®Œæ•´æµç¨‹ï¼š


æŸ¥çœ‹å¤‡ä»½ä»£ç ä¸­çš„æˆåŠŸå›è°ƒé€»è¾‘ï¼š


æ¢³ç†é¢è¯•æŠ¥å‘Šç”Ÿæˆçš„å®Œæ•´æµç¨‹ï¼š

## é¢è¯•æŠ¥å‘Šç”Ÿæˆæµç¨‹

### 1. è§¦å‘æ—¶æœºï¼šå®¢æˆ·ç«¯ä¸»åŠ¨è°ƒç”¨

é¢è¯•ç»“æŸåï¼Œå®¢æˆ·ç«¯ï¼ˆå‰ç«¯/ç§»åŠ¨ç«¯ï¼‰ä¸»åŠ¨è°ƒç”¨ `/interviewReport` POST æ¥å£ã€‚

```15:16:project_code/career/code/routers/interview_report_router.py
@router.post('/interviewReport')
async def interview_report(request: Request,background_task:BackgroundTasks) -> Dict[str, Any]:
```

ä¸æ˜¯ä»£ç è‡ªåŠ¨å›è°ƒï¼Œè€Œæ˜¯å®¢æˆ·ç«¯åœ¨é¢è¯•ç»“æŸæ—¶ä¸»åŠ¨å‘èµ·è¯·æ±‚ã€‚

---

### 2. æ¥å£å¤„ç†ï¼šç«‹å³è¿”å› + åå°å¼‚æ­¥ç”Ÿæˆ

æ¥å£æ”¶åˆ°è¯·æ±‚åï¼š
1. ç«‹å³è¿”å›æˆåŠŸå“åº”ï¼ˆä¸ç­‰å¾…æŠ¥å‘Šç”Ÿæˆï¼‰
2. ä½¿ç”¨ FastAPI çš„ `BackgroundTasks` å¼‚æ­¥ç”ŸæˆæŠ¥å‘Š

```56:62:project_code/career/code/routers/interview_report_router.py
                background_task.add_task(ai_report.generate_report,
                                         transcript_json_str=transcript,
                                         jd=jd,
                                         interview_id=interview_id,
                                         url_list=url_list,
                                         is_mp4=is_mp4,
                                         interview_language=interview_language)
```

```82:87:project_code/career/code/routers/interview_report_router.py
        return {"code": 0,
                "message": "success",
                "is_exists": is_exists,
                "data": "",
                "traceId": "",
                "serverTime": time.time()}
```

---

### 3. æŠ¥å‘Šç”Ÿæˆï¼šåå°å¼‚æ­¥æ‰§è¡Œï¼ˆ4-6åˆ†é’Ÿï¼‰

`AIInterviewAssessor.generate_report()` åœ¨åå°æ‰§è¡Œï¼š
- æŠ½å–è€ƒæ ¸ç»´åº¦
- é€é¡¹èƒ½åŠ›è¯„ä¼°
- å²—ä½é€‚é…åº¦åˆ†æ
- æ€§æ ¼åˆ†æ
- è–ªé…¬å¸‚åœºè¯„ä¼°
- ç”ŸæˆHRæŠ¥å‘Šå’Œå€™é€‰äººæŠ¥å‘Š
- å¤šæ¨¡æ€åˆ†æ

---

### 4. ç»“æœå›è°ƒï¼šä»£ç è‡ªåŠ¨å›è°ƒå¤–éƒ¨æ¥å£

æŠ¥å‘Šç”Ÿæˆå®Œæˆåï¼Œä»£ç ä¼šè‡ªåŠ¨å›è°ƒå¤–éƒ¨æ¥å£é€šçŸ¥ç»“æœã€‚

#### å½“å‰ä»£ç çŠ¶æ€ï¼ˆå¯èƒ½å­˜åœ¨é—®é¢˜ï¼‰

æŸ¥çœ‹å½“å‰ä»£ç ï¼Œå‘ç°ï¼š
- å¤±è´¥æ—¶ä¼šå›è°ƒå¤–éƒ¨æ¥å£
- æˆåŠŸæ—¶åªæ›´æ–°æ•°æ®åº“ï¼Œæ²¡æœ‰å›è°ƒ

```277:287:project_code/career/code/service/AIInterviewAssessor.py
        except Exception as e:
            logging.error(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼Œé”™è¯¯ï¼š{e}")
            re= json.dumps({
                "result": None,
                "code": 1,
                "interview_id": int(interview_id),
                "error": str(e)
            },ensure_ascii=False)
            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼ï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")
```

ä½†åœ¨å¤‡ä»½ä»£ç ä¸­ï¼ŒæˆåŠŸæ—¶ä¹Ÿæœ‰å›è°ƒï¼š

```294:302:cv_project_backup/career/code/service/AIInterviewAssessor.py
            re= json.dumps({
                "result": final_report,
                "code": 0,
                "interview_id": int(interview_id),
            },ensure_ascii=False)
            print(re)

            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šæˆåŠŸï¼Œæ€»è€—æ—¶{time.time()-zero_time}sï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")
```

å›è°ƒåœ°å€é…ç½®ï¼š

```29:29:project_code/career/code/config/config.yaml
    interview_report_post_url: "https://dev-api.zilieai.com/b/interview/v1/ai/interview/get/report"
```

---

## å®Œæ•´æµç¨‹å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. é¢è¯•ç»“æŸï¼ˆå®¢æˆ·ç«¯ï¼‰                                        â”‚
â”‚     ç”¨æˆ·å®Œæˆé¢è¯•ï¼Œç‚¹å‡»"ç»“æŸé¢è¯•"æˆ–è‡ªåŠ¨ç»“æŸ                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. å®¢æˆ·ç«¯è°ƒç”¨æ¥å£ï¼ˆä¸»åŠ¨è¯·æ±‚ï¼‰                                â”‚
â”‚     POST /interviewReport                                   â”‚
â”‚     {                                                       â”‚
â”‚       "interview_id": "123456",                            â”‚
â”‚       "transcript": [...],                                 â”‚
â”‚       "jd": "...",                                          â”‚
â”‚       "interview_language": "zhongwen",                    â”‚
â”‚       "p_url": [...] or "v_url": [...]                     â”‚
â”‚     }                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. æ¥å£ç«‹å³è¿”å›ï¼ˆä¸ç­‰å¾…ï¼‰                                    â”‚
â”‚     {                                                       â”‚
â”‚       "code": 0,                                           â”‚
â”‚       "message": "success",                                â”‚
â”‚       "data": ""                                           â”‚
â”‚     }                                                       â”‚
â”‚                                                             â”‚
â”‚     âœ… åŒæ—¶å¯åŠ¨ BackgroundTasks å¼‚æ­¥ç”ŸæˆæŠ¥å‘Š                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. åå°å¼‚æ­¥ç”ŸæˆæŠ¥å‘Šï¼ˆ4-6åˆ†é’Ÿï¼‰                              â”‚
â”‚     - æŠ½å–è€ƒæ ¸ç»´åº¦ (1æ¬¡AIè°ƒç”¨)                               â”‚
â”‚     - é€é¡¹èƒ½åŠ›è¯„ä¼° (Næ¬¡AIè°ƒç”¨)                               â”‚
â”‚     - å²—ä½é€‚é…åº¦åˆ†æ (1æ¬¡AIè°ƒç”¨)                             â”‚
â”‚     - æ€§æ ¼æ·±åº¦åˆ†æ (1æ¬¡AIè°ƒç”¨)                               â”‚
â”‚     - è–ªé…¬å¸‚åœºè¯„ä¼° (1æ¬¡AIè°ƒç”¨ï¼Œè”ç½‘æœç´¢)                     â”‚
â”‚     - ç”ŸæˆHRæ€»ç»“ (1æ¬¡AIè°ƒç”¨)                                 â”‚
â”‚     - å¤šæ¨¡æ€åˆ†æ (1æ¬¡AIè°ƒç”¨)                                 â”‚
â”‚     - ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š (1æ¬¡AIè°ƒç”¨)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. æŠ¥å‘Šç”Ÿæˆå®Œæˆ                                             â”‚
â”‚     âœ… æ›´æ–°æ•°æ®åº“ï¼ˆSimulateReportè¡¨ï¼‰                        â”‚
â”‚     âš ï¸  å½“å‰ä»£ç ï¼šæˆåŠŸæ—¶æ²¡æœ‰å›è°ƒå¤–éƒ¨æ¥å£                      â”‚
â”‚     âœ… å¤‡ä»½ä»£ç ï¼šæˆåŠŸæ—¶å›è°ƒå¤–éƒ¨æ¥å£                           â”‚
â”‚     âœ… å¤±è´¥æ—¶ï¼šå›è°ƒå¤–éƒ¨æ¥å£ï¼ˆcode=1ï¼‰                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. å›è°ƒå¤–éƒ¨æ¥å£ï¼ˆä»£ç è‡ªåŠ¨è°ƒç”¨ï¼‰                              â”‚
â”‚     POST https://dev-api.zilieai.com/b/interview/v1/...     â”‚
â”‚     {                                                       â”‚
â”‚       "result": {...},  // å®Œæ•´æŠ¥å‘Š                          â”‚
â”‚       "code": 0,          // 0=æˆåŠŸ, 1=å¤±è´¥                 â”‚
â”‚       "interview_id": 123456                                â”‚
â”‚     }                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## æ€»ç»“

### å›ç­”ä½ çš„é—®é¢˜

1. è§¦å‘æ—¶é—´ï¼šé¢è¯•ç»“æŸåï¼Œç”±å®¢æˆ·ç«¯ä¸»åŠ¨è°ƒç”¨ `/interviewReport` æ¥å£
2. è°ƒç”¨æ–¹å¼ï¼šå®¢æˆ·ç«¯å‘é€ POST è¯·æ±‚ï¼Œä¸æ˜¯ä»£ç è‡ªåŠ¨å›è°ƒ
3. æŠ¥å‘Šç”Ÿæˆï¼šæ¥å£ç«‹å³è¿”å›ï¼Œåå°å¼‚æ­¥ç”Ÿæˆï¼ˆ4-6åˆ†é’Ÿï¼‰
4. ç»“æœé€šçŸ¥ï¼šæŠ¥å‘Šç”Ÿæˆå®Œæˆåï¼Œä»£ç ä¼šè‡ªåŠ¨å›è°ƒå¤–éƒ¨æ¥å£ï¼ˆ`post_url`ï¼‰

### å‘ç°çš„é—®é¢˜

å½“å‰ä»£ç ä¸­ï¼ŒæŠ¥å‘Šç”ŸæˆæˆåŠŸæ—¶åªæ›´æ–°äº†æ•°æ®åº“ï¼Œæ²¡æœ‰å›è°ƒå¤–éƒ¨æ¥å£ã€‚å¤‡ä»½ä»£ç ä¸­æœ‰æˆåŠŸå›è°ƒã€‚å»ºè®®æ£€æŸ¥æ˜¯å¦éœ€è¦è¡¥å……æˆåŠŸå›è°ƒé€»è¾‘ã€‚

éœ€è¦æˆ‘å¸®ä½ ä¿®å¤è¿™ä¸ªé—®é¢˜å—ï¼Ÿ

```python
@router.post('/interviewReport')
async def interview_report(request: Request,background_task:BackgroundTasks) -> Dict[str, Any]:
```

```python
                background_task.add_task(ai_report.generate_report,
                                         transcript_json_str=transcript,
                                         jd=jd,
                                         interview_id=interview_id,
                                         url_list=url_list,
                                         is_mp4=is_mp4,
                                         interview_language=interview_language)
```

```python
        return {"code": 0,
                "message": "success",
                "is_exists": is_exists,
                "data": "",
                "traceId": "",
                "serverTime": time.time()}
```

```python
        except Exception as e:
            logging.error(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼Œé”™è¯¯ï¼š{e}")
            re= json.dumps({
                "result": None,
                "code": 1,
                "interview_id": int(interview_id),
                "error": str(e)
            },ensure_ascii=False)
            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼ï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")
```

```python
            re= json.dumps({
                "result": final_report,
                "code": 0,
                "interview_id": int(interview_id),
            },ensure_ascii=False)
            print(re)

            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šæˆåŠŸï¼Œæ€»è€—æ—¶{time.time()-zero_time}sï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")
```

```yaml
    interview_report_post_url: "https://dev-api.zilieai.com/b/interview/v1/ai/interview/get/report"
```

```plaintext
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. é¢è¯•ç»“æŸï¼ˆå®¢æˆ·ç«¯ï¼‰                                        â”‚
â”‚     ç”¨æˆ·å®Œæˆé¢è¯•ï¼Œç‚¹å‡»"ç»“æŸé¢è¯•"æˆ–è‡ªåŠ¨ç»“æŸ                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. å®¢æˆ·ç«¯è°ƒç”¨æ¥å£ï¼ˆä¸»åŠ¨è¯·æ±‚ï¼‰                                â”‚
â”‚     POST /interviewReport                                   â”‚
â”‚     {                                                       â”‚
â”‚       "interview_id": "123456",                            â”‚
â”‚       "transcript": [...],                                 â”‚
â”‚       "jd": "...",                                          â”‚
â”‚       "interview_language": "zhongwen",                    â”‚
â”‚       "p_url": [...] or "v_url": [...]                     â”‚
â”‚     }                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. æ¥å£ç«‹å³è¿”å›ï¼ˆä¸ç­‰å¾…ï¼‰                                    â”‚
â”‚     {                                                       â”‚
â”‚       "code": 0,                                           â”‚
â”‚       "message": "success",                                â”‚
â”‚       "data": ""                                           â”‚
â”‚     }                                                       â”‚
â”‚                                                             â”‚
â”‚     âœ… åŒæ—¶å¯åŠ¨ BackgroundTasks å¼‚æ­¥ç”ŸæˆæŠ¥å‘Š                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. åå°å¼‚æ­¥ç”ŸæˆæŠ¥å‘Šï¼ˆ4-6åˆ†é’Ÿï¼‰                              â”‚
â”‚     - æŠ½å–è€ƒæ ¸ç»´åº¦ (1æ¬¡AIè°ƒç”¨)                               â”‚
â”‚     - é€é¡¹èƒ½åŠ›è¯„ä¼° (Næ¬¡AIè°ƒç”¨)                               â”‚
â”‚     - å²—ä½é€‚é…åº¦åˆ†æ (1æ¬¡AIè°ƒç”¨)                             â”‚
â”‚     - æ€§æ ¼æ·±åº¦åˆ†æ (1æ¬¡AIè°ƒç”¨)                               â”‚
â”‚     - è–ªé…¬å¸‚åœºè¯„ä¼° (1æ¬¡AIè°ƒç”¨ï¼Œè”ç½‘æœç´¢)                     â”‚
â”‚     - ç”ŸæˆHRæ€»ç»“ (1æ¬¡AIè°ƒç”¨)                                 â”‚
â”‚     - å¤šæ¨¡æ€åˆ†æ (1æ¬¡AIè°ƒç”¨)                                 â”‚
â”‚     - ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š (1æ¬¡AIè°ƒç”¨)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. æŠ¥å‘Šç”Ÿæˆå®Œæˆ                                             â”‚
â”‚     âœ… æ›´æ–°æ•°æ®åº“ï¼ˆSimulateReportè¡¨ï¼‰                        â”‚
â”‚     âš ï¸  å½“å‰ä»£ç ï¼šæˆåŠŸæ—¶æ²¡æœ‰å›è°ƒå¤–éƒ¨æ¥å£                      â”‚
â”‚     âœ… å¤‡ä»½ä»£ç ï¼šæˆåŠŸæ—¶å›è°ƒå¤–éƒ¨æ¥å£                           â”‚
â”‚     âœ… å¤±è´¥æ—¶ï¼šå›è°ƒå¤–éƒ¨æ¥å£ï¼ˆcode=1ï¼‰                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. å›è°ƒå¤–éƒ¨æ¥å£ï¼ˆä»£ç è‡ªåŠ¨è°ƒç”¨ï¼‰                              â”‚
â”‚     POST https://dev-api.zilieai.com/b/interview/v1/...     â”‚
â”‚     {                                                       â”‚
â”‚       "result": {...},  // å®Œæ•´æŠ¥å‘Š                          â”‚
â”‚       "code": 0,          // 0=æˆåŠŸ, 1=å¤±è´¥                 â”‚
â”‚       "interview_id": 123456                                â”‚
â”‚     }                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

**User**

@virtual-interview-minimal-spec.md (85-106) å‰é¢æˆ‘è·Ÿä½ æåˆ°çš„è¿™äº›å†…å®¹é¢è¯•æŠ¥å‘Šè¿™äº›å­—æ®µå¹¶ä¸æ˜¯è¯´æˆ‘çš„virtual-interviewè¿™ä¸ªæ¥å£æ‰€è¿”å›çš„?è¿™ä¹ˆç†è§£å‡†ç¡®å—ï¼Ÿä»¥åŠä½ æœ‰ä»€ä¹ˆè¡¥å……æˆ–è€…ä¿®æ­£çš„æ„è§å—ï¼Ÿ

---

**Cursor**

æŸ¥çœ‹ç›¸å…³æ–‡ä»¶ï¼Œç¡®è®¤é¢è¯•æŠ¥å‘Šå­—æ®µä¸ `virtual-interview` æ¥å£çš„å…³ç³»ã€‚


ç¡®è®¤ï¼šä½ çš„ç†è§£æ˜¯æ­£ç¡®çš„ã€‚é¢è¯•æŠ¥å‘Šå­—æ®µä¸æ˜¯ `virtual-interview` æ¥å£è¿”å›çš„ã€‚æŸ¥çœ‹ä»£ç éªŒè¯ï¼š


## ä½ çš„ç†è§£æ˜¯æ­£ç¡®çš„

### `/virturlInterview` æ¥å£çš„å®é™…è¿”å›

ä»ä»£ç å¯ä»¥çœ‹åˆ°ï¼Œ`virtual-interview` æ¥å£åªè¿”å›æµå¼å¯¹è¯å†…å®¹ï¼š

```315:317:project_code/career/code/service/virtual_interview.py
                    yield f"data: {json.dumps({'type': 'chunk', 'content': content}, ensure_ascii=False)}\n\n"

            yield f"data: {json.dumps({'type': 'DONE', 'content': '[DONE]'}, ensure_ascii=False)}\n\n"
```

è¿”å›æ ¼å¼ï¼š
- æµå¼å¯¹è¯ç‰‡æ®µï¼š`{"type": "chunk", "content": "å¯¹è¯å†…å®¹"}`
- ç»“æŸæ ‡è®°ï¼š`{"type": "DONE", "content": "[DONE]"}`

ä¸åŒ…å«é¢è¯•æŠ¥å‘Šå­—æ®µã€‚

---

### é¢è¯•æŠ¥å‘Šæ˜¯å¦ä¸€ä¸ªæ¥å£

é¢è¯•æŠ¥å‘Šæ˜¯é€šè¿‡ `/interviewReport` æ¥å£å•ç‹¬ç”Ÿæˆçš„ï¼Œä¸æ˜¯ `virtual-interview` æ¥å£çš„è¿”å›ã€‚

---

## æ–‡æ¡£é—®é¢˜ä¸ä¿®æ­£å»ºè®®

`virtual-interview-minimal-spec.md` ç¬¬85-106è¡ŒæŠŠé¢è¯•æŠ¥å‘Šå­—æ®µæ”¾åœ¨äº† `virtual-interview` æ¥å£çš„å“åº”ç¤ºä¾‹ä¸­ï¼Œè¿™ä¼šé€ æˆè¯¯è§£ã€‚

### å»ºè®®ä¿®æ­£

#### æ–¹æ¡ˆ1ï¼šæ˜ç¡®åŒºåˆ†ä¸¤ä¸ªæ¥å£ï¼ˆæ¨èï¼‰

```markdown
### å“åº”ï¼š

#### virtual-interview æ¥å£å“åº”ï¼ˆæµå¼å¯¹è¯ï¼‰
```json
// æµå¼å“åº”ï¼ˆSSEæ ¼å¼ï¼‰
{
  "type": "chunk",
  "content": "å¯¹è¯å†…å®¹ç‰‡æ®µ"
}

// ç»“æŸæ ‡è®°
{
  "type": "DONE",
  "content": "[DONE]"
}
```

#### é¢è¯•æŠ¥å‘Šæ¥å£å“åº”ï¼ˆå•ç‹¬æ¥å£ï¼‰
é¢è¯•æŠ¥å‘Šé€šè¿‡ `/interviewReport` æ¥å£å•ç‹¬ç”Ÿæˆï¼Œè¯¦è§ `evaluation-report-ultra-simple-spec.md`

// æœ€ç»ˆé¢è¯•æŠ¥å‘Šï¼ˆé€šè¿‡ /interviewReport æ¥å£è¿”å›ï¼‰
{
  "overall_assessment": {
    "match_score": 85.5,
    "conclusion": "T2-èƒœä»»ï¼Œç¬¦åˆé¢„æœŸ",
    ...
  },
  ...
}
```

#### æ–¹æ¡ˆ2ï¼šåˆ é™¤é¢è¯•æŠ¥å‘Šéƒ¨åˆ†ï¼ˆæ›´ç®€æ´ï¼‰

å¦‚æœè¿™ä¸ªæ–‡æ¡£åªæè¿° `virtual-interview` æ¥å£ï¼Œå»ºè®®åˆ é™¤ç¬¬85-106è¡Œçš„é¢è¯•æŠ¥å‘Šç¤ºä¾‹ï¼Œæ”¹ä¸ºï¼š

```markdown
### å“åº”ï¼š
```json
// æµå¼å“åº”ï¼ˆSSEæ ¼å¼ï¼‰
{
  "type": "chunk",
  "content": "å¯¹è¯å†…å®¹ç‰‡æ®µ"
}

// ç»“æŸæ ‡è®°
{
  "type": "DONE",
  "content": "[DONE]"
}
```

**æ³¨æ„**ï¼šé¢è¯•è¯„ä¼°æŠ¥å‘Šé€šè¿‡ `/interviewReport` æ¥å£å•ç‹¬ç”Ÿæˆï¼Œè¯¦è§è¯„ä¼°æŠ¥å‘Šè§„æ ¼æ–‡æ¡£ã€‚
```

---

## è¡¥å……è¯´æ˜

### ä¸¤ä¸ªæ¥å£çš„å…³ç³»

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. virtual-interview æ¥å£                      â”‚
â”‚     POST /virturlInterview                      â”‚
â”‚     - è¿”å›ï¼šæµå¼å¯¹è¯å†…å®¹ï¼ˆå®æ—¶ï¼‰                 â”‚
â”‚     - ç”¨é€”ï¼šé¢è¯•è¿‡ç¨‹ä¸­çš„å¯¹è¯äº¤äº’                â”‚
â”‚     - ç»“æŸï¼šè¿”å› [DONE] æ ‡è®°                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â”‚ é¢è¯•ç»“æŸå
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. interviewReport æ¥å£                        â”‚
â”‚     POST /interviewReport                       â”‚
â”‚     - è¿”å›ï¼šç«‹å³è¿”å›æˆåŠŸï¼Œåå°å¼‚æ­¥ç”ŸæˆæŠ¥å‘Š        â”‚
â”‚     - ç”¨é€”ï¼šç”Ÿæˆå®Œæ•´çš„é¢è¯•è¯„ä¼°æŠ¥å‘Š               â”‚
â”‚     - æŠ¥å‘Šï¼šé€šè¿‡å›è°ƒæ¥å£è¿”å›å®Œæ•´æŠ¥å‘Š              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å…³é”®åŒºåˆ«

| ç‰¹æ€§ | `/virturlInterview` | `/interviewReport` |
|------|-------------------|-------------------|
| **è¿”å›å†…å®¹** | æµå¼å¯¹è¯æ–‡æœ¬ | å®Œæ•´è¯„ä¼°æŠ¥å‘Šï¼ˆJSONï¼‰ |
| **è¿”å›æ—¶æœº** | å®æ—¶ï¼ˆæ¯æ¬¡å¯¹è¯ï¼‰ | é¢è¯•ç»“æŸåï¼ˆå¼‚æ­¥ï¼‰ |
| **å“åº”æ ¼å¼** | SSEæµå¼ | ç«‹å³è¿”å› + åå°å›è°ƒ |
| **åŒ…å«å­—æ®µ** | åªæœ‰å¯¹è¯å†…å®¹ | è¯„åˆ†ã€åˆ†æã€å»ºè®®ç­‰å®Œæ•´æŠ¥å‘Š |

---

## æ€»ç»“

1. ä½ çš„ç†è§£æ­£ç¡®ï¼šé¢è¯•æŠ¥å‘Šå­—æ®µä¸å±äº `virtual-interview` æ¥å£çš„è¿”å›ã€‚
2. æ–‡æ¡£éœ€è¦ä¿®æ­£ï¼šå»ºè®®æ˜ç¡®åŒºåˆ†ä¸¤ä¸ªæ¥å£ï¼Œæˆ–åˆ é™¤æ··æ·†çš„éƒ¨åˆ†ã€‚
3. å»ºè®®ï¼šé‡‡ç”¨æ–¹æ¡ˆ2ï¼ˆåˆ é™¤+è¯´æ˜ï¼‰ï¼Œä¿æŒæ–‡æ¡£èŒè´£æ¸…æ™°ã€‚

éœ€è¦æˆ‘å¸®ä½ ä¿®æ­£è¿™ä¸ªæ–‡æ¡£å—ï¼Ÿ

```python
                    yield f"data: {json.dumps({'type': 'chunk', 'content': content}, ensure_ascii=False)}\n\n"

            yield f"data: {json.dumps({'type': 'DONE', 'content': '[DONE]'}, ensure_ascii=False)}\n\n"
```

```markdown
### å“åº”ï¼š

#### virtual-interview æ¥å£å“åº”ï¼ˆæµå¼å¯¹è¯ï¼‰
// æµå¼å“åº”ï¼ˆSSEæ ¼å¼ï¼‰
{
  "type": "chunk",
  "content": "å¯¹è¯å†…å®¹ç‰‡æ®µ"
}

// ç»“æŸæ ‡è®°
{
  "type": "DONE",
  "content": "[DONE]"
}#### é¢è¯•æŠ¥å‘Šæ¥å£å“åº”ï¼ˆå•ç‹¬æ¥å£ï¼‰
é¢è¯•æŠ¥å‘Šé€šè¿‡ `/interviewReport` æ¥å£å•ç‹¬ç”Ÿæˆï¼Œè¯¦è§ `evaluation-report-ultra-simple-spec.md`

// æœ€ç»ˆé¢è¯•æŠ¥å‘Šï¼ˆé€šè¿‡ /interviewReport æ¥å£è¿”å›ï¼‰
{
  "overall_assessment": {
    "match_score": 85.5,
    "conclusion": "T2-èƒœä»»ï¼Œç¬¦åˆé¢„æœŸ",
    ...
  },
  ...
}
```

```plaintext
### å“åº”ï¼š
// æµå¼å“åº”ï¼ˆSSEæ ¼å¼ï¼‰
{
  "type": "chunk",
  "content": "å¯¹è¯å†…å®¹ç‰‡æ®µ"
}

// ç»“æŸæ ‡è®°
{
  "type": "DONE",
  "content": "[DONE]"
}**æ³¨æ„**ï¼šé¢è¯•è¯„ä¼°æŠ¥å‘Šé€šè¿‡ `/interviewReport` æ¥å£å•ç‹¬ç”Ÿæˆï¼Œè¯¦è§è¯„ä¼°æŠ¥å‘Šè§„æ ¼æ–‡æ¡£ã€‚é¢è¯•è¯„ä¼°æŠ¥å‘Šé€šè¿‡ `/interviewReport` æ¥å£å•ç‹¬ç”Ÿæˆï¼Œè¯¦è§è¯„ä¼°æŠ¥å‘Šè§„æ ¼æ–‡æ¡£ã€‚
```

```markdown
### å“åº”ï¼š
// æµå¼å“åº”ï¼ˆSSEæ ¼å¼ï¼‰
{
  "type": "chunk",
  "content": "å¯¹è¯å†…å®¹ç‰‡æ®µ"
}

// ç»“æŸæ ‡è®°
{
  "type": "DONE",
  "content": "[DONE]"
}**æ³¨æ„**ï¼šé¢è¯•è¯„ä¼°æŠ¥å‘Šé€šè¿‡ `/interviewReport` æ¥å£å•ç‹¬ç”Ÿæˆï¼Œè¯¦è§è¯„ä¼°æŠ¥å‘Šè§„æ ¼æ–‡æ¡£ã€‚é¢è¯•è¯„ä¼°æŠ¥å‘Šé€šè¿‡ `/interviewReport` æ¥å£å•ç‹¬ç”Ÿæˆï¼Œè¯¦è§è¯„ä¼°æŠ¥å‘Šè§„æ ¼æ–‡æ¡£ã€‚
```

```plaintext
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. virtual-interview æ¥å£                      â”‚
â”‚     POST /virturlInterview                      â”‚
â”‚     - è¿”å›ï¼šæµå¼å¯¹è¯å†…å®¹ï¼ˆå®æ—¶ï¼‰                 â”‚
â”‚     - ç”¨é€”ï¼šé¢è¯•è¿‡ç¨‹ä¸­çš„å¯¹è¯äº¤äº’                â”‚
â”‚     - ç»“æŸï¼šè¿”å› [DONE] æ ‡è®°                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â”‚ é¢è¯•ç»“æŸå
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. interviewReport æ¥å£                        â”‚
â”‚     POST /interviewReport                       â”‚
â”‚     - è¿”å›ï¼šç«‹å³è¿”å›æˆåŠŸï¼Œåå°å¼‚æ­¥ç”ŸæˆæŠ¥å‘Š        â”‚
â”‚     - ç”¨é€”ï¼šç”Ÿæˆå®Œæ•´çš„é¢è¯•è¯„ä¼°æŠ¥å‘Š               â”‚
â”‚     - æŠ¥å‘Šï¼šé€šè¿‡å›è°ƒæ¥å£è¿”å›å®Œæ•´æŠ¥å‘Š              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

**User**

@virtual-interview-spec.md æ‰€ä»¥ä½ çœ‹ä¸€ä¸‹è¿™ä¸ªmarkdownæ–‡æ¡£æ˜¯ä¸æ˜¯å†™çš„æœ‰é—®é¢˜ï¼Ÿå› ä¸ºå­˜åœ¨äº†ä¸€äº›ä¸å¿…è¦çš„å†…å®¹å‘€å°±æ˜¯å…¶ä»–æ¨¡å—çš„åŠŸèƒ½ï¼Œæ˜¯å—ï¼Ÿ

---

**Cursor**

ä½ è¯´å¾—å¯¹ï¼è®©æˆ‘åˆ†æä¸€ä¸‹è¿™ä¸ªæ–‡æ¡£çš„é—®é¢˜ï¼š

## é—®é¢˜åˆ†æ

`virtual-interview-spec.md` æ–‡æ¡£ç¡®å®å­˜åœ¨**èŒè´£æ··ä¹±**çš„é—®é¢˜ï¼š

### âŒ ä¸åº”è¯¥åŒ…å«çš„å†…å®¹

1. **ç¬¬2.5èŠ‚ "é¢è¯•è¯„ä¼°æŠ¥å‘ŠåŠŸèƒ½"**ï¼ˆç¬¬108-125è¡Œï¼‰
   - è¿™æ˜¯ `/interviewReport` æ¥å£çš„åŠŸèƒ½
   - ä¸å±äº virtual-interview æ¥å£çš„èŒƒå›´

2. **ç¬¬4.2.2èŠ‚ "é¢è¯•æŠ¥å‘Šæ ¼å¼"**ï¼ˆç¬¬205-227è¡Œï¼‰
   - è¯¦ç»†çš„æŠ¥å‘ŠJSONç»“æ„
   - è¿™æ˜¯æŠ¥å‘Šç”Ÿæˆæ¥å£è¿”å›çš„æ•°æ®

3. **æµç¨‹å›¾ä¸­çš„"ç”Ÿæˆé¢è¯•è¯„ä¼°æŠ¥å‘Š"**ï¼ˆç¬¬142è¡Œï¼‰
   - æ··æ·†äº†é¢è¯•å¯¹è¯å’ŒæŠ¥å‘Šç”Ÿæˆä¸¤ä¸ªç‹¬ç«‹æµç¨‹

### âœ… åº”è¯¥ä¿ç•™çš„å†…å®¹

- è™šæ‹ŸèŒä½ç”ŸæˆåŠŸèƒ½
- é¢è¯•è®¡åˆ’ç”ŸæˆåŠŸèƒ½
- æ™ºèƒ½å¯¹è¯æ‰§è¡ŒåŠŸèƒ½
- å¤šè¯­è¨€æ”¯æŒåŠŸèƒ½
- æµå¼å“åº”æ ¼å¼

---

## å»ºè®®ä¿®æ­£æ–¹æ¡ˆ

### ä¿®æ”¹1ï¼šåˆ é™¤"é¢è¯•è¯„ä¼°æŠ¥å‘ŠåŠŸèƒ½"ç« èŠ‚

å°†ç¬¬2.5èŠ‚æ›¿æ¢ä¸ºå¯¹æŠ¥å‘Šæ¥å£çš„ç®€å•è¯´æ˜ï¼š

```markdown
### 2.5 é¢è¯•æ•°æ®è®°å½•

#### 2.5.1 åŠŸèƒ½æè¿°
é¢è¯•è¿‡ç¨‹ä¸­è®°å½•å®Œæ•´çš„å¯¹è¯å†å²ï¼Œä¾›åç»­è¯„ä¼°æŠ¥å‘Šç”Ÿæˆä½¿ç”¨ã€‚

#### 2.5.2 è®°å½•å†…å®¹
- å®Œæ•´çš„å¯¹è¯è®°å½•ï¼ˆtranscriptï¼‰
- é¢è¯•æ—¶é•¿å’Œé—®é¢˜æ•°é‡
- ç”¨æˆ·å›ç­”çš„è´¨é‡è¯„åˆ†ï¼ˆå†…éƒ¨è®°å½•ï¼‰

**æ³¨æ„**ï¼šé¢è¯•è¯„ä¼°æŠ¥å‘Šé€šè¿‡ç‹¬ç«‹çš„ `/interviewReport` æ¥å£ç”Ÿæˆï¼Œè¯¦è§ `evaluation-report-ultra-simple-spec.md`ã€‚
```

### ä¿®æ”¹2ï¼šç®€åŒ–æµç¨‹å›¾

```mermaid
graph TD
    A[ç”¨æˆ·è¾“å…¥å€™é€‰äººç”»åƒå’ŒæœŸæœ›èŒä½] --> B[ç”Ÿæˆè™šæ‹ŸèŒä½åœºæ™¯]
    B --> C[ç”¨æˆ·ç¡®è®¤å¼€å§‹é¢è¯•]
    C --> D[é¦–æ¬¡é¢è¯•åˆå§‹åŒ–]
    D --> E[ç”Ÿæˆé¢è¯•è®¡åˆ’]
    E --> F[æå‡ºç¬¬ä¸€ä¸ªé¢è¯•é—®é¢˜]
    F --> G[ç”¨æˆ·å›ç­”é—®é¢˜]
    G --> H[AIåˆ†æå›ç­”å¹¶ç”Ÿæˆå›åº”]
    H --> I{åˆ¤æ–­æ˜¯å¦ç»“æŸé¢è¯•}
    I -->|ç»§ç»­| J[æå‡ºä¸‹ä¸€ä¸ªé—®é¢˜]
    J --> G
    I -->|ç»“æŸ| K[é¢è¯•ç»“æŸï¼Œè®°å½•å¯¹è¯å†å²]
    K --> L[å®¢æˆ·ç«¯è°ƒç”¨ /interviewReport æ¥å£ç”ŸæˆæŠ¥å‘Š]
```

### ä¿®æ”¹3ï¼šåˆ é™¤æŠ¥å‘Šæ ¼å¼ï¼Œä¿ç•™æµå¼å“åº”æ ¼å¼

```markdown
### 4.2 è¾“å‡ºæ•°æ®æ ¼å¼

#### 4.2.1 æµå¼å“åº”æ ¼å¼
```json
{
  "type": "chunk",
  "content": "å¯¹è¯å†…å®¹ç‰‡æ®µ"
}

// ç»“æŸæ ‡è®°
{
  "type": "DONE",
  "content": "[DONE]"
}
```

**æ³¨æ„**ï¼šé¢è¯•è¯„ä¼°æŠ¥å‘Šç”±ç‹¬ç«‹çš„ `/interviewReport` æ¥å£ç”Ÿæˆï¼Œä¸åœ¨æ­¤æ¥å£è¿”å›ã€‚
```

---

éœ€è¦æˆ‘å¸®ä½ ä¿®æ­£è¿™ä¸ªæ–‡æ¡£å—ï¼Ÿæˆ‘ä¼šï¼š
1. åˆ é™¤é¢è¯•æŠ¥å‘Šç›¸å…³çš„ç« èŠ‚
2. ç®€åŒ–æµç¨‹å›¾ï¼Œæ˜ç¡®æ¥å£è¾¹ç•Œ
3. åœ¨é€‚å½“ä½ç½®æ·»åŠ è¯´æ˜ï¼ŒæŒ‡å‘æŠ¥å‘Šç”Ÿæˆæ¥å£çš„æ–‡æ¡£

```markdown
### 2.5 é¢è¯•æ•°æ®è®°å½•

#### 2.5.1 åŠŸèƒ½æè¿°
é¢è¯•è¿‡ç¨‹ä¸­è®°å½•å®Œæ•´çš„å¯¹è¯å†å²ï¼Œä¾›åç»­è¯„ä¼°æŠ¥å‘Šç”Ÿæˆä½¿ç”¨ã€‚

#### 2.5.2 è®°å½•å†…å®¹
- å®Œæ•´çš„å¯¹è¯è®°å½•ï¼ˆtranscriptï¼‰
- é¢è¯•æ—¶é•¿å’Œé—®é¢˜æ•°é‡
- ç”¨æˆ·å›ç­”çš„è´¨é‡è¯„åˆ†ï¼ˆå†…éƒ¨è®°å½•ï¼‰

**æ³¨æ„**ï¼šé¢è¯•è¯„ä¼°æŠ¥å‘Šé€šè¿‡ç‹¬ç«‹çš„ `/interviewReport` æ¥å£ç”Ÿæˆï¼Œè¯¦è§ `evaluation-report-ultra-simple-spec.md`ã€‚
```

```plaintext
graph TD
    A[ç”¨æˆ·è¾“å…¥å€™é€‰äººç”»åƒå’ŒæœŸæœ›èŒä½] --> B[ç”Ÿæˆè™šæ‹ŸèŒä½åœºæ™¯]
    B --> C[ç”¨æˆ·ç¡®è®¤å¼€å§‹é¢è¯•]
    C --> D[é¦–æ¬¡é¢è¯•åˆå§‹åŒ–]
    D --> E[ç”Ÿæˆé¢è¯•è®¡åˆ’]
    E --> F[æå‡ºç¬¬ä¸€ä¸ªé¢è¯•é—®é¢˜]
    F --> G[ç”¨æˆ·å›ç­”é—®é¢˜]
    G --> H[AIåˆ†æå›ç­”å¹¶ç”Ÿæˆå›åº”]
    H --> I{åˆ¤æ–­æ˜¯å¦ç»“æŸé¢è¯•}
    I -->|ç»§ç»­| J[æå‡ºä¸‹ä¸€ä¸ªé—®é¢˜]
    J --> G
    I -->|ç»“æŸ| K[é¢è¯•ç»“æŸï¼Œè®°å½•å¯¹è¯å†å²]
    K --> L[å®¢æˆ·ç«¯è°ƒç”¨ /interviewReport æ¥å£ç”ŸæˆæŠ¥å‘Š]
```

```markdown
### 4.2 è¾“å‡ºæ•°æ®æ ¼å¼

#### 4.2.1 æµå¼å“åº”æ ¼å¼
{
  "type": "chunk",
  "content": "å¯¹è¯å†…å®¹ç‰‡æ®µ"
}

// ç»“æŸæ ‡è®°
{
  "type": "DONE",
  "content": "[DONE]"
}**æ³¨æ„**ï¼šé¢è¯•è¯„ä¼°æŠ¥å‘Šç”±ç‹¬ç«‹çš„ `/interviewReport` æ¥å£ç”Ÿæˆï¼Œä¸åœ¨æ­¤æ¥å£è¿”å›ã€‚
```

---

**User**

@AIInterviewAssessor.py å»æ‰é‡Œé¢æ‰€æœ‰çš„ä¸­æ–‡æ³¨é‡Šä»¥åŠdocstring,ä¸ç”¨ç¿»è¯‘æˆè‹±æ–‡ï¼Œæˆ‘ä¸éœ€è¦æ³¨é‡Šï¼Œä½†ä»£ç æ³¨é‡Šå…ˆä¸è¦å»æ‰ã€‚ 

---

**Cursor**

ç§»é™¤æ‰€æœ‰ä¸­æ–‡æ³¨é‡Šå’Œ docstringï¼Œä¿ç•™ä»£ç æ³¨é‡Šã€‚


```python
import json
import logging
import time
import os
from datetime import datetime
from typing import Dict, List, Any
import requests
from openai import OpenAI
from app.config import url_config
from app.database import get_session
from models import SimulateReport
from service.multimodal_report import style_report
from app.config import ai_config
from sqlmodel import update
qwen_api_key = ai_config['api_key']

config = url_config
post_url = config['interview_report_post_url']
qwen_api_uri = ai_config['api_uri']
model_name = ai_config['api_model']


class AIInterviewAssessor:
    def __init__(self):
        self.llm_client = OpenAI(
            api_key=qwen_api_key,
            base_url=qwen_api_uri,
        )
        self.language_dict={
            'zhongwen': ('ä¸­æ–‡', 'ä½ å¥½ï¼Œé¢è¯•å®˜ï¼è®©æˆ‘ä»¬ç”¨ä¸­æ–‡äº¤æµï¼', 'longxiaochun_v2'),
            'yingwen': ('è‹±æ–‡', "Hello, interviewer!Let's communicate in English!", 'longxiaochun_v2'),
            'riyu': ('æ—¥è¯­', 'ã“ã‚“ã«ã¡ã¯ã€é¢æ¥å®˜ï¼æ—¥æœ¬èªã§è©±ã—åˆã„ã¾ã—ã‚‡ã†ï¼', 'loongtomoka_v2'),
            'hanyu': ('éŸ©è¯­', 'ì•ˆë…•í•˜ì„¸ìš”, ë©´ì ‘ê´€ë‹˜!í•œêµ­ì–´ë¡œ ëŒ€í™”í•´ìš”!', 'loongkyong_v2'),
            'xibanyayu': ('è¥¿ç­ç‰™è¯­', 'Â¡Hola, entrevistador!Â¡Hablemos en espaÃ±ol!', 'sambert-camila-v1'),
            'yinniyu': ('å°å°¼è¯­', 'Halo, pewawancara!Ayo berkomunikasi dalam bahasa Indonesia!', 'sambert-indah-v1'),
            'fayu': ('æ³•è¯­', 'Bonjour, intervieweur !Parlons en franÃ§ais !', 'sambert-clara-v1'),
            'deyu': ('å¾·è¯­', 'Hallo, Interviewer!Lass uns auf Deutsch sprechen!', 'sambert-hanna-v1'),
            'taiyu': ('æ³°è¯­', 'à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¹ˆà¸°/à¸„à¸£à¸±à¸š, à¸œà¸¹à¹‰à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œ!à¸¡à¸²à¸à¸¹à¸”à¸„à¸¸à¸¢à¸à¸±à¸™à¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¸à¸±à¸™à¹€à¸–à¸­à¸°!', 'sambert-waan-v1')
        }
        self.interview_language='ä¸­æ–‡'
        
        # åŠ è½½æç¤ºè¯æ¨¡æ¿
        self._load_prompts()

    def _load_prompts(self):
        """
        åŠ è½½æç¤ºè¯æ¨¡æ¿æ–‡ä»¶
        """
        base_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
        prompts_dir = os.path.join(base_dir, 'prompts', 'evaluation_report')
        
        with open(os.path.join(prompts_dir, 'extract_competencies.txt'), 'r', encoding='utf-8') as f:
            self.prompt_extract_competencies = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_single_competency.txt'), 'r', encoding='utf-8') as f:
            self.prompt_analyze_single_competency = f.read()
        
        with open(os.path.join(prompts_dir, 'generate_final_summary.txt'), 'r', encoding='utf-8') as f:
            self.prompt_generate_final_summary = f.read()
        
        with open(os.path.join(prompts_dir, 'user_report.txt'), 'r', encoding='utf-8') as f:
            self.prompt_user_report = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_job_match_and_career.txt'), 'r', encoding='utf-8') as f:
            self.prompt_job_match_and_career = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_personality.txt'), 'r', encoding='utf-8') as f:
            self.prompt_personality = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_salary_market.txt'), 'r', encoding='utf-8') as f:
            self.prompt_salary_market = f.read()

    def _call_llm(self, prompt: str, system_message: str, enable_search: bool = False) -> str | None:

        params = {
            "seed": 6,
            "model": model_name,
            "temperature": 0.3,
            "response_format": {"type": "json_object"},
            "messages": [{"role": "system", "content": system_message},
                        {"role": "user", "content": prompt}]
        }
        
        # è”ç½‘æœç´¢åŠŸèƒ½æš‚æ—¶ç¦ç”¨ï¼ˆAPIæ ¼å¼é—®é¢˜ï¼‰
        # if enable_search:
        #     params["tools"] = [{"type": "web_search"}]
        
        try:
            response = self.llm_client.chat.completions.create(**params)
            content_text = response.choices[0].message.content
            return content_text
        except Exception as e:
            logging.error(f"ï¼ï¼ï¼LLMè°ƒç”¨å¤±è´¥ï¼š{e}")
            return None

    def _extract_competencies(self, jd: str,transcript_text:str) -> Dict[str, List[str]]:
        """
        æŠ½å–è€ƒæ ¸ç»´åº¦
        """
        system_message = self.prompt_extract_competencies.format(interview_language=self.interview_language)

        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """

        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_single_competency(self, competency: str, transcript_text: str) -> Dict[str, Any]:
        """
        å¾ªç¯è¯„ä»·å•ä¸ªç»´åº¦ï¼Œå¸¦æ‰“åˆ†
        """
        system_message = self.prompt_analyze_single_competency.format(
            competency=competency,
            interview_language=self.interview_language
        )
        prompt = f"""
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _generate_final_summary(self, detailed_analysis_str: str) -> Dict[str, Any]:
        """
        ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        """
        system_message = self.prompt_generate_final_summary.format(interview_language=self.interview_language)

        prompt = f"""
        --- èƒ½åŠ›åˆ†ææ•°æ® ---
        {detailed_analysis_str}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_job_match_and_career(self, detailed_analysis_str: str, jd: str, transcript_text: str) -> Dict[str, Any]:
        """
        å²—ä½é€‚é…åº¦åˆ†æ + èŒä¸šå‘å±•è§„åˆ’
        """
        system_message = self.prompt_job_match_and_career.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_personality(self, jd: str, transcript_text: str) -> Dict[str, Any]:
        """
        æ€§æ ¼æ·±åº¦åˆ†æ
        """
        system_message = self.prompt_personality.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_salary_market(self, jd: str, transcript_text: str, detailed_analysis_str: str) -> Dict[str, Any]:
        """
        è–ªé…¬å¸‚åœºè¯„ä¼°ï¼ˆä½¿ç”¨æ¨¡å‹è‡ªèº«èƒ½åŠ›ï¼‰
        """
        system_message = self.prompt_salary_market.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        """
        
        response_str = self._call_llm(prompt, system_message, enable_search=False)
        if not response_str:
            return {}
        
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(f"è–ªé…¬åˆ†æJSONè§£æå¤±è´¥: {e}")
            return {}

    def _user_report(self, jd: str, transcript_text: str, hr_report, personality, salary) -> dict[str, Any]:
        """
        å€™é€‰äººé¢è¯•å¤ç›˜ï¼Œå€™é€‰äººä¸“ç”¨é¢è¯•æŠ¥å‘Š
        """
        system_message = self.prompt_user_report.format(interview_language=self.interview_language)
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        
        --- é¢è¯•å®˜çš„è¯„ä»· ---
        {hr_report}
        
        --- æ€§æ ¼åˆ†æ ---
        {json.dumps(personality, ensure_ascii=False)}
        
        --- è–ªé…¬åˆ†æ ---
        {json.dumps(salary, ensure_ascii=False)}
        
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _format_transcript(self, transcript_json: List[Dict]) -> str:
        lines = []
        for entry in transcript_json:
            role_cn = "é¢è¯•å®˜" if entry['role'] == 'interviewer' else "å€™é€‰äºº"
            lines.append(f"[å½“å‰å¯¹è¯è½®æ•°ï¼š{entry['timestamp']}] {role_cn}: {entry['content']}")
        return "\n".join(lines)

    def generate_report(self, transcript_json_str: str, jd: str,interview_id:str,url_list:list[str],is_mp4:bool,interview_language:str)   :
        try:
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- æ¥æ”¶åˆ°é¢è¯•è®°å½•ï¼Œå¼€å§‹åˆ†æ")
            zero_time = time.time()
            self.interview_language=self.language_dict[interview_language][0]
            transcript_data = json.loads(transcript_json_str)
            try:
                transcript_text = self._format_transcript(transcript_data)
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•æ–‡æœ¬è®°å½•è§£æå‡ºé”™ï¼Œ{e}ï¼Œå¼€å§‹ä½¿ç”¨æºæ•°æ®")
                transcript_text = transcript_data

            # 1. æå–èƒ½åŠ›æ¨¡å‹
            competencies = self._extract_competencies(jd,transcript_text)
            all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            if not all_competency_keys :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} -- è€ƒæ ¸ç»´åº¦æŠ½å–å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                competencies = self._extract_competencies(jd, transcript_text)
                all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è€ƒæ ¸ç»´åº¦æŠ½å–æˆåŠŸï¼š{competencies}")

            # 2. é€é¡¹è¯„ä¼°å„é¡¹èƒ½åŠ›
            detailed_analysis = []
            total_score = 0

            for competency in all_competency_keys:
                start_time=time.time()
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ­£åœ¨åˆ†æ '{competency}'...")
                analysis_result = self._analyze_single_competency(competency, transcript_text)
                if not analysis_result :
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†æç»´åº¦ï¼š{competency} å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    analysis_result = self._analyze_single_competency(competency, transcript_text)
                analysis_result['competency'] = competency
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†ææˆåŠŸï¼š{competency}ï¼Œè€—æ—¶{time.time()-start_time}s ")
                detailed_analysis.append(analysis_result)
                total_score += analysis_result.get('score', 0)

            detailed_analysis_str = json.dumps(detailed_analysis, indent=2, ensure_ascii=False)
            
            # 3. å²—ä½é€‚é…åº¦åˆ†æ + èŒä¸šå‘å±•è§„åˆ’
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æ...")
            job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            if not job_match:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æå®Œæˆ")
            
            # 4. æ€§æ ¼æ·±åº¦åˆ†æ
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹æ€§æ ¼æ·±åº¦åˆ†æ...")
            personality = self._analyze_personality(jd, transcript_text)
            if not personality:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                personality = self._analyze_personality(jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼æ·±åº¦åˆ†æå®Œæˆ")
            
            # 5. è–ªé…¬å¸‚åœºè¯„ä¼°
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹è–ªé…¬å¸‚åœºè¯„ä¼°...")
            try:
                salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
                    logging.warning(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬å¸‚åœºè¯„ä¼°å®Œæˆ")
            except Exception as e:
                logging.error(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¼‚å¸¸: {e}")
                salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
            
            # 6. ç”ŸæˆHRæ€»ç»“
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”ŸæˆHRæ€»ç»“...")
            final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ–‡æœ¬æŠ¥å‘Šæ€»ç»“å¤±è´¥ï¼Œå†æ¬¡å°è¯• - ")
                final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å†æ¬¡å°è¯•æ€»ç»“å¤±è´¥ï¼Œä¸»åŠ¨è¿”å›codeï¼š1 çŠ¶æ€ - ")
                a=1/0
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  HRæ€»ç»“ç”Ÿæˆå®Œæˆ")

            # 7. å¤šæ¨¡æ€åˆ†æ
            overall_score = round(total_score / len(all_competency_keys), 1) if all_competency_keys else -1
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å¤šæ¨¡æ€é£æ ¼åˆ†æ...")
            style=style_report(url_list=url_list,interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            if not style:
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€æŠ¥å‘Šè¯„ä¼°å‡ºé”™ï¼Œå¯åŠ¨ä¿åº•æœºåˆ¶...")
                style=style_report(url_list=[],interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€é£æ ¼åˆ†æå®Œæˆ")

            # 8. ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š
            hr_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
            }
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š...")
            user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            if not user_report:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šå·²ç”Ÿæˆ")

            # 9. èšåˆæœ€ç»ˆæŠ¥å‘Š
            final_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
                "competency_model_used": competencies,
                "job_match_analysis": job_match,
                "personality_analysis": personality,
                "salary_analysis": salary,
                "style_report": style,
                "user_report": user_report
            }

            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æœ€ç»ˆæŠ¥å‘Šå·²ç”Ÿæˆ...")

            content_json = json.dumps(final_report, ensure_ascii=False)
            try:
                with get_session() as session:
                    stmt = (
                        update(SimulateReport)
                        .where(SimulateReport.interview_id == interview_id)
                        .values(
                            content=content_json,
                            updated_at=datetime.now()
                        )
                    )

                    session.exec(stmt)
                    session.flush()
                    logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-é¢è¯•æŠ¥å‘Šæ›´æ–°æˆåŠŸ")
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-å…¥åº“å¤±è´¥ï¼Œé”™è¯¯: {str(e)}")

            re = json.dumps({
                "result": final_report,
                "code": 0,
                "interview_id": int(interview_id),
            }, ensure_ascii=False)

            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šæˆåŠŸï¼Œæ€»è€—æ—¶{time.time()-zero_time}sï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")

        except Exception as e:
            logging.error(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼Œé”™è¯¯ï¼š{e}")
            re= json.dumps({
                "result": None,
                "code": 1,
                "interview_id": int(interview_id),
                "error": str(e)
            },ensure_ascii=False)
            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼ï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")
            return None

```

```python
import json
import logging
import time
import os
from datetime import datetime
from typing import Dict, List, Any
import requests
from openai import OpenAI
from app.config import url_config
from app.database import get_session
from models import SimulateReport
from service.multimodal_report import style_report
from app.config import ai_config
from sqlmodel import update
qwen_api_key = ai_config['api_key']

config = url_config
post_url = config['interview_report_post_url']
qwen_api_uri = ai_config['api_uri']
model_name = ai_config['api_model']


class AIInterviewAssessor:
    def __init__(self):
        self.llm_client = OpenAI(
            api_key=qwen_api_key,
            base_url=qwen_api_uri,
        )
        self.language_dict={
            'zhongwen': ('ä¸­æ–‡', 'ä½ å¥½ï¼Œé¢è¯•å®˜ï¼è®©æˆ‘ä»¬ç”¨ä¸­æ–‡äº¤æµï¼', 'longxiaochun_v2'),
            'yingwen': ('è‹±æ–‡', "Hello, interviewer!Let's communicate in English!", 'longxiaochun_v2'),
            'riyu': ('æ—¥è¯­', 'ã“ã‚“ã«ã¡ã¯ã€é¢æ¥å®˜ï¼æ—¥æœ¬èªã§è©±ã—åˆã„ã¾ã—ã‚‡ã†ï¼', 'loongtomoka_v2'),
            'hanyu': ('éŸ©è¯­', 'ì•ˆë…•í•˜ì„¸ìš”, ë©´ì ‘ê´€ë‹˜!í•œêµ­ì–´ë¡œ ëŒ€í™”í•´ìš”!', 'loongkyong_v2'),
            'xibanyayu': ('è¥¿ç­ç‰™è¯­', 'Â¡Hola, entrevistador!Â¡Hablemos en espaÃ±ol!', 'sambert-camila-v1'),
            'yinniyu': ('å°å°¼è¯­', 'Halo, pewawancara!Ayo berkomunikasi dalam bahasa Indonesia!', 'sambert-indah-v1'),
            'fayu': ('æ³•è¯­', 'Bonjour, intervieweur !Parlons en franÃ§ais !', 'sambert-clara-v1'),
            'deyu': ('å¾·è¯­', 'Hallo, Interviewer!Lass uns auf Deutsch sprechen!', 'sambert-hanna-v1'),
            'taiyu': ('æ³°è¯­', 'à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¹ˆà¸°/à¸„à¸£à¸±à¸š, à¸œà¸¹à¹‰à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œ!à¸¡à¸²à¸à¸¹à¸”à¸„à¸¸à¸¢à¸à¸±à¸™à¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¸à¸±à¸™à¹€à¸–à¸­à¸°!', 'sambert-waan-v1')
        }
        self.interview_language='ä¸­æ–‡'
        
        self._load_prompts()

    def _load_prompts(self):
        """
        åŠ è½½æç¤ºè¯æ¨¡æ¿æ–‡ä»¶
        """
        base_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
        prompts_dir = os.path.join(base_dir, 'prompts', 'evaluation_report')
        
        with open(os.path.join(prompts_dir, 'extract_competencies.txt'), 'r', encoding='utf-8') as f:
            self.prompt_extract_competencies = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_single_competency.txt'), 'r', encoding='utf-8') as f:
            self.prompt_analyze_single_competency = f.read()
        
        with open(os.path.join(prompts_dir, 'generate_final_summary.txt'), 'r', encoding='utf-8') as f:
            self.prompt_generate_final_summary = f.read()
        
        with open(os.path.join(prompts_dir, 'user_report.txt'), 'r', encoding='utf-8') as f:
            self.prompt_user_report = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_job_match_and_career.txt'), 'r', encoding='utf-8') as f:
            self.prompt_job_match_and_career = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_personality.txt'), 'r', encoding='utf-8') as f:
            self.prompt_personality = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_salary_market.txt'), 'r', encoding='utf-8') as f:
            self.prompt_salary_market = f.read()

    def _call_llm(self, prompt: str, system_message: str, enable_search: bool = False) -> str | None:

        params = {
            "seed": 6,
            "model": model_name,
            "temperature": 0.3,
            "response_format": {"type": "json_object"},
            "messages": [{"role": "system", "content": system_message},
                        {"role": "user", "content": prompt}]
        }
        
        # è”ç½‘æœç´¢åŠŸèƒ½æš‚æ—¶ç¦ç”¨ï¼ˆAPIæ ¼å¼é—®é¢˜ï¼‰
        # if enable_search:
        #     params["tools"] = [{"type": "web_search"}]
        
        try:
            response = self.llm_client.chat.completions.create(**params)
            content_text = response.choices[0].message.content
            return content_text
        except Exception as e:
            logging.error(f"ï¼ï¼ï¼LLMè°ƒç”¨å¤±è´¥ï¼š{e}")
            return None

    def _extract_competencies(self, jd: str,transcript_text:str) -> Dict[str, List[str]]:
        """
        æŠ½å–è€ƒæ ¸ç»´åº¦
        """
        system_message = self.prompt_extract_competencies.format(interview_language=self.interview_language)

        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """

        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_single_competency(self, competency: str, transcript_text: str) -> Dict[str, Any]:
        """
        å¾ªç¯è¯„ä»·å•ä¸ªç»´åº¦ï¼Œå¸¦æ‰“åˆ†
        """
        system_message = self.prompt_analyze_single_competency.format(
            competency=competency,
            interview_language=self.interview_language
        )
        prompt = f"""
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _generate_final_summary(self, detailed_analysis_str: str) -> Dict[str, Any]:
        """
        ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        """
        system_message = self.prompt_generate_final_summary.format(interview_language=self.interview_language)

        prompt = f"""
        --- èƒ½åŠ›åˆ†ææ•°æ® ---
        {detailed_analysis_str}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_job_match_and_career(self, detailed_analysis_str: str, jd: str, transcript_text: str) -> Dict[str, Any]:
        """
        å²—ä½é€‚é…åº¦åˆ†æ + èŒä¸šå‘å±•è§„åˆ’
        """
        system_message = self.prompt_job_match_and_career.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_personality(self, jd: str, transcript_text: str) -> Dict[str, Any]:
        """
        æ€§æ ¼æ·±åº¦åˆ†æ
        """
        system_message = self.prompt_personality.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_salary_market(self, jd: str, transcript_text: str, detailed_analysis_str: str) -> Dict[str, Any]:
        """
        è–ªé…¬å¸‚åœºè¯„ä¼°ï¼ˆä½¿ç”¨æ¨¡å‹è‡ªèº«èƒ½åŠ›ï¼‰
        """
        system_message = self.prompt_salary_market.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        """
        
        response_str = self._call_llm(prompt, system_message, enable_search=False)
        if not response_str:
            return {}
        
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(f"è–ªé…¬åˆ†æJSONè§£æå¤±è´¥: {e}")
            return {}

    def _user_report(self, jd: str, transcript_text: str, hr_report, personality, salary) -> dict[str, Any]:
        """
        å€™é€‰äººé¢è¯•å¤ç›˜ï¼Œå€™é€‰äººä¸“ç”¨é¢è¯•æŠ¥å‘Š
        """
        system_message = self.prompt_user_report.format(interview_language=self.interview_language)
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        
        --- é¢è¯•å®˜çš„è¯„ä»· ---
        {hr_report}
        
        --- æ€§æ ¼åˆ†æ ---
        {json.dumps(personality, ensure_ascii=False)}
        
        --- è–ªé…¬åˆ†æ ---
        {json.dumps(salary, ensure_ascii=False)}
        
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _format_transcript(self, transcript_json: List[Dict]) -> str:
        lines = []
        for entry in transcript_json:
            role_cn = "é¢è¯•å®˜" if entry['role'] == 'interviewer' else "å€™é€‰äºº"
            lines.append(f"[å½“å‰å¯¹è¯è½®æ•°ï¼š{entry['timestamp']}] {role_cn}: {entry['content']}")
        return "\n".join(lines)

    def generate_report(self, transcript_json_str: str, jd: str,interview_id:str,url_list:list[str],is_mp4:bool,interview_language:str)   :
        try:
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- æ¥æ”¶åˆ°é¢è¯•è®°å½•ï¼Œå¼€å§‹åˆ†æ")
            zero_time = time.time()
            self.interview_language=self.language_dict[interview_language][0]
            transcript_data = json.loads(transcript_json_str)
            try:
                transcript_text = self._format_transcript(transcript_data)
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•æ–‡æœ¬è®°å½•è§£æå‡ºé”™ï¼Œ{e}ï¼Œå¼€å§‹ä½¿ç”¨æºæ•°æ®")
                transcript_text = transcript_data

            # 1. æå–èƒ½åŠ›æ¨¡å‹
            competencies = self._extract_competencies(jd,transcript_text)
            all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            if not all_competency_keys :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} -- è€ƒæ ¸ç»´åº¦æŠ½å–å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                competencies = self._extract_competencies(jd, transcript_text)
                all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è€ƒæ ¸ç»´åº¦æŠ½å–æˆåŠŸï¼š{competencies}")

            # 2. é€é¡¹è¯„ä¼°å„é¡¹èƒ½åŠ›
            detailed_analysis = []
            total_score = 0

            for competency in all_competency_keys:
                start_time=time.time()
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ­£åœ¨åˆ†æ '{competency}'...")
                analysis_result = self._analyze_single_competency(competency, transcript_text)
                if not analysis_result :
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†æç»´åº¦ï¼š{competency} å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    analysis_result = self._analyze_single_competency(competency, transcript_text)
                analysis_result['competency'] = competency
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†ææˆåŠŸï¼š{competency}ï¼Œè€—æ—¶{time.time()-start_time}s ")
                detailed_analysis.append(analysis_result)
                total_score += analysis_result.get('score', 0)

            detailed_analysis_str = json.dumps(detailed_analysis, indent=2, ensure_ascii=False)
            
            # 3. å²—ä½é€‚é…åº¦åˆ†æ + èŒä¸šå‘å±•è§„åˆ’
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æ...")
            job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            if not job_match:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æå®Œæˆ")
            
            # 4. æ€§æ ¼æ·±åº¦åˆ†æ
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹æ€§æ ¼æ·±åº¦åˆ†æ...")
            personality = self._analyze_personality(jd, transcript_text)
            if not personality:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                personality = self._analyze_personality(jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼æ·±åº¦åˆ†æå®Œæˆ")
            
            # 5. è–ªé…¬å¸‚åœºè¯„ä¼°
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹è–ªé…¬å¸‚åœºè¯„ä¼°...")
            try:
                salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
                    logging.warning(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬å¸‚åœºè¯„ä¼°å®Œæˆ")
            except Exception as e:
                logging.error(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¼‚å¸¸: {e}")
                salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
            
            # 6. ç”ŸæˆHRæ€»ç»“
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”ŸæˆHRæ€»ç»“...")
            final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ–‡æœ¬æŠ¥å‘Šæ€»ç»“å¤±è´¥ï¼Œå†æ¬¡å°è¯• - ")
                final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å†æ¬¡å°è¯•æ€»ç»“å¤±è´¥ï¼Œä¸»åŠ¨è¿”å›codeï¼š1 çŠ¶æ€ - ")
                a=1/0
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  HRæ€»ç»“ç”Ÿæˆå®Œæˆ")

            # 7. å¤šæ¨¡æ€åˆ†æ
            overall_score = round(total_score / len(all_competency_keys), 1) if all_competency_keys else -1
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å¤šæ¨¡æ€é£æ ¼åˆ†æ...")
            style=style_report(url_list=url_list,interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            if not style:
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€æŠ¥å‘Šè¯„ä¼°å‡ºé”™ï¼Œå¯åŠ¨ä¿åº•æœºåˆ¶...")
                style=style_report(url_list=[],interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€é£æ ¼åˆ†æå®Œæˆ")

            # 8. ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š
            hr_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
            }
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š...")
            user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            if not user_report:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šå·²ç”Ÿæˆ")

            # 9. èšåˆæœ€ç»ˆæŠ¥å‘Š
            final_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
                "competency_model_used": competencies,
                "job_match_analysis": job_match,
                "personality_analysis": personality,
                "salary_analysis": salary,
                "style_report": style,
                "user_report": user_report
            }

            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æœ€ç»ˆæŠ¥å‘Šå·²ç”Ÿæˆ...")

            content_json = json.dumps(final_report, ensure_ascii=False)
            try:
                with get_session() as session:
                    stmt = (
                        update(SimulateReport)
                        .where(SimulateReport.interview_id == interview_id)
                        .values(
                            content=content_json,
                            updated_at=datetime.now()
                        )
                    )

                    session.exec(stmt)
                    session.flush()
                    logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-é¢è¯•æŠ¥å‘Šæ›´æ–°æˆåŠŸ")
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-å…¥åº“å¤±è´¥ï¼Œé”™è¯¯: {str(e)}")

            re = json.dumps({
                "result": final_report,
                "code": 0,
                "interview_id": int(interview_id),
            }, ensure_ascii=False)

            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šæˆåŠŸï¼Œæ€»è€—æ—¶{time.time()-zero_time}sï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")

        except Exception as e:
            logging.error(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼Œé”™è¯¯ï¼š{e}")
            re= json.dumps({
                "result": None,
                "code": 1,
                "interview_id": int(interview_id),
                "error": str(e)
            },ensure_ascii=False)
            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼ï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")
            return None

```

```python
import json
import logging
import time
import os
from datetime import datetime
from typing import Dict, List, Any
import requests
from openai import OpenAI
from app.config import url_config
from app.database import get_session
from models import SimulateReport
from service.multimodal_report import style_report
from app.config import ai_config
from sqlmodel import update
qwen_api_key = ai_config['api_key']

config = url_config
post_url = config['interview_report_post_url']
qwen_api_uri = ai_config['api_uri']
model_name = ai_config['api_model']


class AIInterviewAssessor:
    def __init__(self):
        self.llm_client = OpenAI(
            api_key=qwen_api_key,
            base_url=qwen_api_uri,
        )
        self.language_dict={
            'zhongwen': ('ä¸­æ–‡', 'ä½ å¥½ï¼Œé¢è¯•å®˜ï¼è®©æˆ‘ä»¬ç”¨ä¸­æ–‡äº¤æµï¼', 'longxiaochun_v2'),
            'yingwen': ('è‹±æ–‡', "Hello, interviewer!Let's communicate in English!", 'longxiaochun_v2'),
            'riyu': ('æ—¥è¯­', 'ã“ã‚“ã«ã¡ã¯ã€é¢æ¥å®˜ï¼æ—¥æœ¬èªã§è©±ã—åˆã„ã¾ã—ã‚‡ã†ï¼', 'loongtomoka_v2'),
            'hanyu': ('éŸ©è¯­', 'ì•ˆë…•í•˜ì„¸ìš”, ë©´ì ‘ê´€ë‹˜!í•œêµ­ì–´ë¡œ ëŒ€í™”í•´ìš”!', 'loongkyong_v2'),
            'xibanyayu': ('è¥¿ç­ç‰™è¯­', 'Â¡Hola, entrevistador!Â¡Hablemos en espaÃ±ol!', 'sambert-camila-v1'),
            'yinniyu': ('å°å°¼è¯­', 'Halo, pewawancara!Ayo berkomunikasi dalam bahasa Indonesia!', 'sambert-indah-v1'),
            'fayu': ('æ³•è¯­', 'Bonjour, intervieweur !Parlons en franÃ§ais !', 'sambert-clara-v1'),
            'deyu': ('å¾·è¯­', 'Hallo, Interviewer!Lass uns auf Deutsch sprechen!', 'sambert-hanna-v1'),
            'taiyu': ('æ³°è¯­', 'à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¹ˆà¸°/à¸„à¸£à¸±à¸š, à¸œà¸¹à¹‰à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œ!à¸¡à¸²à¸à¸¹à¸”à¸„à¸¸à¸¢à¸à¸±à¸™à¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¸à¸±à¸™à¹€à¸–à¸­à¸°!', 'sambert-waan-v1')
        }
        self.interview_language='ä¸­æ–‡'
        
        self._load_prompts()

    def _load_prompts(self):
        base_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
        prompts_dir = os.path.join(base_dir, 'prompts', 'evaluation_report')
        
        with open(os.path.join(prompts_dir, 'extract_competencies.txt'), 'r', encoding='utf-8') as f:
            self.prompt_extract_competencies = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_single_competency.txt'), 'r', encoding='utf-8') as f:
            self.prompt_analyze_single_competency = f.read()
        
        with open(os.path.join(prompts_dir, 'generate_final_summary.txt'), 'r', encoding='utf-8') as f:
            self.prompt_generate_final_summary = f.read()
        
        with open(os.path.join(prompts_dir, 'user_report.txt'), 'r', encoding='utf-8') as f:
            self.prompt_user_report = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_job_match_and_career.txt'), 'r', encoding='utf-8') as f:
            self.prompt_job_match_and_career = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_personality.txt'), 'r', encoding='utf-8') as f:
            self.prompt_personality = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_salary_market.txt'), 'r', encoding='utf-8') as f:
            self.prompt_salary_market = f.read()

    def _call_llm(self, prompt: str, system_message: str, enable_search: bool = False) -> str | None:

        params = {
            "seed": 6,
            "model": model_name,
            "temperature": 0.3,
            "response_format": {"type": "json_object"},
            "messages": [{"role": "system", "content": system_message},
                        {"role": "user", "content": prompt}]
        }
        
        # è”ç½‘æœç´¢åŠŸèƒ½æš‚æ—¶ç¦ç”¨ï¼ˆAPIæ ¼å¼é—®é¢˜ï¼‰
        # if enable_search:
        #     params["tools"] = [{"type": "web_search"}]
        
        try:
            response = self.llm_client.chat.completions.create(**params)
            content_text = response.choices[0].message.content
            return content_text
        except Exception as e:
            logging.error(f"ï¼ï¼ï¼LLMè°ƒç”¨å¤±è´¥ï¼š{e}")
            return None

    def _extract_competencies(self, jd: str,transcript_text:str) -> Dict[str, List[str]]:
        """
        æŠ½å–è€ƒæ ¸ç»´åº¦
        """
        system_message = self.prompt_extract_competencies.format(interview_language=self.interview_language)

        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """

        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_single_competency(self, competency: str, transcript_text: str) -> Dict[str, Any]:
        """
        å¾ªç¯è¯„ä»·å•ä¸ªç»´åº¦ï¼Œå¸¦æ‰“åˆ†
        """
        system_message = self.prompt_analyze_single_competency.format(
            competency=competency,
            interview_language=self.interview_language
        )
        prompt = f"""
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _generate_final_summary(self, detailed_analysis_str: str) -> Dict[str, Any]:
        """
        ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        """
        system_message = self.prompt_generate_final_summary.format(interview_language=self.interview_language)

        prompt = f"""
        --- èƒ½åŠ›åˆ†ææ•°æ® ---
        {detailed_analysis_str}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_job_match_and_career(self, detailed_analysis_str: str, jd: str, transcript_text: str) -> Dict[str, Any]:
        """
        å²—ä½é€‚é…åº¦åˆ†æ + èŒä¸šå‘å±•è§„åˆ’
        """
        system_message = self.prompt_job_match_and_career.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_personality(self, jd: str, transcript_text: str) -> Dict[str, Any]:
        """
        æ€§æ ¼æ·±åº¦åˆ†æ
        """
        system_message = self.prompt_personality.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_salary_market(self, jd: str, transcript_text: str, detailed_analysis_str: str) -> Dict[str, Any]:
        """
        è–ªé…¬å¸‚åœºè¯„ä¼°ï¼ˆä½¿ç”¨æ¨¡å‹è‡ªèº«èƒ½åŠ›ï¼‰
        """
        system_message = self.prompt_salary_market.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        """
        
        response_str = self._call_llm(prompt, system_message, enable_search=False)
        if not response_str:
            return {}
        
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(f"è–ªé…¬åˆ†æJSONè§£æå¤±è´¥: {e}")
            return {}

    def _user_report(self, jd: str, transcript_text: str, hr_report, personality, salary) -> dict[str, Any]:
        """
        å€™é€‰äººé¢è¯•å¤ç›˜ï¼Œå€™é€‰äººä¸“ç”¨é¢è¯•æŠ¥å‘Š
        """
        system_message = self.prompt_user_report.format(interview_language=self.interview_language)
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        
        --- é¢è¯•å®˜çš„è¯„ä»· ---
        {hr_report}
        
        --- æ€§æ ¼åˆ†æ ---
        {json.dumps(personality, ensure_ascii=False)}
        
        --- è–ªé…¬åˆ†æ ---
        {json.dumps(salary, ensure_ascii=False)}
        
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _format_transcript(self, transcript_json: List[Dict]) -> str:
        lines = []
        for entry in transcript_json:
            role_cn = "é¢è¯•å®˜" if entry['role'] == 'interviewer' else "å€™é€‰äºº"
            lines.append(f"[å½“å‰å¯¹è¯è½®æ•°ï¼š{entry['timestamp']}] {role_cn}: {entry['content']}")
        return "\n".join(lines)

    def generate_report(self, transcript_json_str: str, jd: str,interview_id:str,url_list:list[str],is_mp4:bool,interview_language:str)   :
        try:
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- æ¥æ”¶åˆ°é¢è¯•è®°å½•ï¼Œå¼€å§‹åˆ†æ")
            zero_time = time.time()
            self.interview_language=self.language_dict[interview_language][0]
            transcript_data = json.loads(transcript_json_str)
            try:
                transcript_text = self._format_transcript(transcript_data)
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•æ–‡æœ¬è®°å½•è§£æå‡ºé”™ï¼Œ{e}ï¼Œå¼€å§‹ä½¿ç”¨æºæ•°æ®")
                transcript_text = transcript_data

            # 1. æå–èƒ½åŠ›æ¨¡å‹
            competencies = self._extract_competencies(jd,transcript_text)
            all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            if not all_competency_keys :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} -- è€ƒæ ¸ç»´åº¦æŠ½å–å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                competencies = self._extract_competencies(jd, transcript_text)
                all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è€ƒæ ¸ç»´åº¦æŠ½å–æˆåŠŸï¼š{competencies}")

            # 2. é€é¡¹è¯„ä¼°å„é¡¹èƒ½åŠ›
            detailed_analysis = []
            total_score = 0

            for competency in all_competency_keys:
                start_time=time.time()
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ­£åœ¨åˆ†æ '{competency}'...")
                analysis_result = self._analyze_single_competency(competency, transcript_text)
                if not analysis_result :
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†æç»´åº¦ï¼š{competency} å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    analysis_result = self._analyze_single_competency(competency, transcript_text)
                analysis_result['competency'] = competency
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†ææˆåŠŸï¼š{competency}ï¼Œè€—æ—¶{time.time()-start_time}s ")
                detailed_analysis.append(analysis_result)
                total_score += analysis_result.get('score', 0)

            detailed_analysis_str = json.dumps(detailed_analysis, indent=2, ensure_ascii=False)
            
            # 3. å²—ä½é€‚é…åº¦åˆ†æ + èŒä¸šå‘å±•è§„åˆ’
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æ...")
            job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            if not job_match:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æå®Œæˆ")
            
            # 4. æ€§æ ¼æ·±åº¦åˆ†æ
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹æ€§æ ¼æ·±åº¦åˆ†æ...")
            personality = self._analyze_personality(jd, transcript_text)
            if not personality:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                personality = self._analyze_personality(jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼æ·±åº¦åˆ†æå®Œæˆ")
            
            # 5. è–ªé…¬å¸‚åœºè¯„ä¼°
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹è–ªé…¬å¸‚åœºè¯„ä¼°...")
            try:
                salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
                    logging.warning(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬å¸‚åœºè¯„ä¼°å®Œæˆ")
            except Exception as e:
                logging.error(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¼‚å¸¸: {e}")
                salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
            
            # 6. ç”ŸæˆHRæ€»ç»“
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”ŸæˆHRæ€»ç»“...")
            final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ–‡æœ¬æŠ¥å‘Šæ€»ç»“å¤±è´¥ï¼Œå†æ¬¡å°è¯• - ")
                final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å†æ¬¡å°è¯•æ€»ç»“å¤±è´¥ï¼Œä¸»åŠ¨è¿”å›codeï¼š1 çŠ¶æ€ - ")
                a=1/0
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  HRæ€»ç»“ç”Ÿæˆå®Œæˆ")

            # 7. å¤šæ¨¡æ€åˆ†æ
            overall_score = round(total_score / len(all_competency_keys), 1) if all_competency_keys else -1
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å¤šæ¨¡æ€é£æ ¼åˆ†æ...")
            style=style_report(url_list=url_list,interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            if not style:
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€æŠ¥å‘Šè¯„ä¼°å‡ºé”™ï¼Œå¯åŠ¨ä¿åº•æœºåˆ¶...")
                style=style_report(url_list=[],interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€é£æ ¼åˆ†æå®Œæˆ")

            # 8. ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š
            hr_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
            }
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š...")
            user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            if not user_report:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šå·²ç”Ÿæˆ")

            # 9. èšåˆæœ€ç»ˆæŠ¥å‘Š
            final_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
                "competency_model_used": competencies,
                "job_match_analysis": job_match,
                "personality_analysis": personality,
                "salary_analysis": salary,
                "style_report": style,
                "user_report": user_report
            }

            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æœ€ç»ˆæŠ¥å‘Šå·²ç”Ÿæˆ...")

            content_json = json.dumps(final_report, ensure_ascii=False)
            try:
                with get_session() as session:
                    stmt = (
                        update(SimulateReport)
                        .where(SimulateReport.interview_id == interview_id)
                        .values(
                            content=content_json,
                            updated_at=datetime.now()
                        )
                    )

                    session.exec(stmt)
                    session.flush()
                    logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-é¢è¯•æŠ¥å‘Šæ›´æ–°æˆåŠŸ")
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-å…¥åº“å¤±è´¥ï¼Œé”™è¯¯: {str(e)}")

            re = json.dumps({
                "result": final_report,
                "code": 0,
                "interview_id": int(interview_id),
            }, ensure_ascii=False)

            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šæˆåŠŸï¼Œæ€»è€—æ—¶{time.time()-zero_time}sï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")

        except Exception as e:
            logging.error(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼Œé”™è¯¯ï¼š{e}")
            re= json.dumps({
                "result": None,
                "code": 1,
                "interview_id": int(interview_id),
                "error": str(e)
            },ensure_ascii=False)
            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼ï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")
            return None

```

```python
import json
import logging
import time
import os
from datetime import datetime
from typing import Dict, List, Any
import requests
from openai import OpenAI
from app.config import url_config
from app.database import get_session
from models import SimulateReport
from service.multimodal_report import style_report
from app.config import ai_config
from sqlmodel import update
qwen_api_key = ai_config['api_key']

config = url_config
post_url = config['interview_report_post_url']
qwen_api_uri = ai_config['api_uri']
model_name = ai_config['api_model']


class AIInterviewAssessor:
    def __init__(self):
        self.llm_client = OpenAI(
            api_key=qwen_api_key,
            base_url=qwen_api_uri,
        )
        self.language_dict={
            'zhongwen': ('ä¸­æ–‡', 'ä½ å¥½ï¼Œé¢è¯•å®˜ï¼è®©æˆ‘ä»¬ç”¨ä¸­æ–‡äº¤æµï¼', 'longxiaochun_v2'),
            'yingwen': ('è‹±æ–‡', "Hello, interviewer!Let's communicate in English!", 'longxiaochun_v2'),
            'riyu': ('æ—¥è¯­', 'ã“ã‚“ã«ã¡ã¯ã€é¢æ¥å®˜ï¼æ—¥æœ¬èªã§è©±ã—åˆã„ã¾ã—ã‚‡ã†ï¼', 'loongtomoka_v2'),
            'hanyu': ('éŸ©è¯­', 'ì•ˆë…•í•˜ì„¸ìš”, ë©´ì ‘ê´€ë‹˜!í•œêµ­ì–´ë¡œ ëŒ€í™”í•´ìš”!', 'loongkyong_v2'),
            'xibanyayu': ('è¥¿ç­ç‰™è¯­', 'Â¡Hola, entrevistador!Â¡Hablemos en espaÃ±ol!', 'sambert-camila-v1'),
            'yinniyu': ('å°å°¼è¯­', 'Halo, pewawancara!Ayo berkomunikasi dalam bahasa Indonesia!', 'sambert-indah-v1'),
            'fayu': ('æ³•è¯­', 'Bonjour, intervieweur !Parlons en franÃ§ais !', 'sambert-clara-v1'),
            'deyu': ('å¾·è¯­', 'Hallo, Interviewer!Lass uns auf Deutsch sprechen!', 'sambert-hanna-v1'),
            'taiyu': ('æ³°è¯­', 'à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¹ˆà¸°/à¸„à¸£à¸±à¸š, à¸œà¸¹à¹‰à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œ!à¸¡à¸²à¸à¸¹à¸”à¸„à¸¸à¸¢à¸à¸±à¸™à¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¸à¸±à¸™à¹€à¸–à¸­à¸°!', 'sambert-waan-v1')
        }
        self.interview_language='ä¸­æ–‡'
        
        self._load_prompts()

    def _load_prompts(self):
        base_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
        prompts_dir = os.path.join(base_dir, 'prompts', 'evaluation_report')
        
        with open(os.path.join(prompts_dir, 'extract_competencies.txt'), 'r', encoding='utf-8') as f:
            self.prompt_extract_competencies = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_single_competency.txt'), 'r', encoding='utf-8') as f:
            self.prompt_analyze_single_competency = f.read()
        
        with open(os.path.join(prompts_dir, 'generate_final_summary.txt'), 'r', encoding='utf-8') as f:
            self.prompt_generate_final_summary = f.read()
        
        with open(os.path.join(prompts_dir, 'user_report.txt'), 'r', encoding='utf-8') as f:
            self.prompt_user_report = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_job_match_and_career.txt'), 'r', encoding='utf-8') as f:
            self.prompt_job_match_and_career = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_personality.txt'), 'r', encoding='utf-8') as f:
            self.prompt_personality = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_salary_market.txt'), 'r', encoding='utf-8') as f:
            self.prompt_salary_market = f.read()

    def _call_llm(self, prompt: str, system_message: str, enable_search: bool = False) -> str | None:

        params = {
            "seed": 6,
            "model": model_name,
            "temperature": 0.3,
            "response_format": {"type": "json_object"},
            "messages": [{"role": "system", "content": system_message},
                        {"role": "user", "content": prompt}]
        }
        
        # if enable_search:
        #     params["tools"] = [{"type": "web_search"}]
        
        try:
            response = self.llm_client.chat.completions.create(**params)
            content_text = response.choices[0].message.content
            return content_text
        except Exception as e:
            logging.error(f"ï¼ï¼ï¼LLMè°ƒç”¨å¤±è´¥ï¼š{e}")
            return None

    def _extract_competencies(self, jd: str,transcript_text:str) -> Dict[str, List[str]]:
        """
        æŠ½å–è€ƒæ ¸ç»´åº¦
        """
        system_message = self.prompt_extract_competencies.format(interview_language=self.interview_language)

        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """

        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_single_competency(self, competency: str, transcript_text: str) -> Dict[str, Any]:
        """
        å¾ªç¯è¯„ä»·å•ä¸ªç»´åº¦ï¼Œå¸¦æ‰“åˆ†
        """
        system_message = self.prompt_analyze_single_competency.format(
            competency=competency,
            interview_language=self.interview_language
        )
        prompt = f"""
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _generate_final_summary(self, detailed_analysis_str: str) -> Dict[str, Any]:
        """
        ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        """
        system_message = self.prompt_generate_final_summary.format(interview_language=self.interview_language)

        prompt = f"""
        --- èƒ½åŠ›åˆ†ææ•°æ® ---
        {detailed_analysis_str}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_job_match_and_career(self, detailed_analysis_str: str, jd: str, transcript_text: str) -> Dict[str, Any]:
        """
        å²—ä½é€‚é…åº¦åˆ†æ + èŒä¸šå‘å±•è§„åˆ’
        """
        system_message = self.prompt_job_match_and_career.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_personality(self, jd: str, transcript_text: str) -> Dict[str, Any]:
        """
        æ€§æ ¼æ·±åº¦åˆ†æ
        """
        system_message = self.prompt_personality.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_salary_market(self, jd: str, transcript_text: str, detailed_analysis_str: str) -> Dict[str, Any]:
        """
        è–ªé…¬å¸‚åœºè¯„ä¼°ï¼ˆä½¿ç”¨æ¨¡å‹è‡ªèº«èƒ½åŠ›ï¼‰
        """
        system_message = self.prompt_salary_market.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        """
        
        response_str = self._call_llm(prompt, system_message, enable_search=False)
        if not response_str:
            return {}
        
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(f"è–ªé…¬åˆ†æJSONè§£æå¤±è´¥: {e}")
            return {}

    def _user_report(self, jd: str, transcript_text: str, hr_report, personality, salary) -> dict[str, Any]:
        """
        å€™é€‰äººé¢è¯•å¤ç›˜ï¼Œå€™é€‰äººä¸“ç”¨é¢è¯•æŠ¥å‘Š
        """
        system_message = self.prompt_user_report.format(interview_language=self.interview_language)
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        
        --- é¢è¯•å®˜çš„è¯„ä»· ---
        {hr_report}
        
        --- æ€§æ ¼åˆ†æ ---
        {json.dumps(personality, ensure_ascii=False)}
        
        --- è–ªé…¬åˆ†æ ---
        {json.dumps(salary, ensure_ascii=False)}
        
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _format_transcript(self, transcript_json: List[Dict]) -> str:
        lines = []
        for entry in transcript_json:
            role_cn = "é¢è¯•å®˜" if entry['role'] == 'interviewer' else "å€™é€‰äºº"
            lines.append(f"[å½“å‰å¯¹è¯è½®æ•°ï¼š{entry['timestamp']}] {role_cn}: {entry['content']}")
        return "\n".join(lines)

    def generate_report(self, transcript_json_str: str, jd: str,interview_id:str,url_list:list[str],is_mp4:bool,interview_language:str)   :
        try:
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- æ¥æ”¶åˆ°é¢è¯•è®°å½•ï¼Œå¼€å§‹åˆ†æ")
            zero_time = time.time()
            self.interview_language=self.language_dict[interview_language][0]
            transcript_data = json.loads(transcript_json_str)
            try:
                transcript_text = self._format_transcript(transcript_data)
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•æ–‡æœ¬è®°å½•è§£æå‡ºé”™ï¼Œ{e}ï¼Œå¼€å§‹ä½¿ç”¨æºæ•°æ®")
                transcript_text = transcript_data

            # 1. æå–èƒ½åŠ›æ¨¡å‹
            competencies = self._extract_competencies(jd,transcript_text)
            all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            if not all_competency_keys :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} -- è€ƒæ ¸ç»´åº¦æŠ½å–å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                competencies = self._extract_competencies(jd, transcript_text)
                all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è€ƒæ ¸ç»´åº¦æŠ½å–æˆåŠŸï¼š{competencies}")

            # 2. é€é¡¹è¯„ä¼°å„é¡¹èƒ½åŠ›
            detailed_analysis = []
            total_score = 0

            for competency in all_competency_keys:
                start_time=time.time()
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ­£åœ¨åˆ†æ '{competency}'...")
                analysis_result = self._analyze_single_competency(competency, transcript_text)
                if not analysis_result :
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†æç»´åº¦ï¼š{competency} å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    analysis_result = self._analyze_single_competency(competency, transcript_text)
                analysis_result['competency'] = competency
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†ææˆåŠŸï¼š{competency}ï¼Œè€—æ—¶{time.time()-start_time}s ")
                detailed_analysis.append(analysis_result)
                total_score += analysis_result.get('score', 0)

            detailed_analysis_str = json.dumps(detailed_analysis, indent=2, ensure_ascii=False)
            
            # 3. å²—ä½é€‚é…åº¦åˆ†æ + èŒä¸šå‘å±•è§„åˆ’
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æ...")
            job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            if not job_match:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æå®Œæˆ")
            
            # 4. æ€§æ ¼æ·±åº¦åˆ†æ
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹æ€§æ ¼æ·±åº¦åˆ†æ...")
            personality = self._analyze_personality(jd, transcript_text)
            if not personality:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                personality = self._analyze_personality(jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼æ·±åº¦åˆ†æå®Œæˆ")
            
            # 5. è–ªé…¬å¸‚åœºè¯„ä¼°
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹è–ªé…¬å¸‚åœºè¯„ä¼°...")
            try:
                salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
                    logging.warning(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬å¸‚åœºè¯„ä¼°å®Œæˆ")
            except Exception as e:
                logging.error(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¼‚å¸¸: {e}")
                salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
            
            # 6. ç”ŸæˆHRæ€»ç»“
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”ŸæˆHRæ€»ç»“...")
            final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ–‡æœ¬æŠ¥å‘Šæ€»ç»“å¤±è´¥ï¼Œå†æ¬¡å°è¯• - ")
                final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å†æ¬¡å°è¯•æ€»ç»“å¤±è´¥ï¼Œä¸»åŠ¨è¿”å›codeï¼š1 çŠ¶æ€ - ")
                a=1/0
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  HRæ€»ç»“ç”Ÿæˆå®Œæˆ")

            # 7. å¤šæ¨¡æ€åˆ†æ
            overall_score = round(total_score / len(all_competency_keys), 1) if all_competency_keys else -1
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å¤šæ¨¡æ€é£æ ¼åˆ†æ...")
            style=style_report(url_list=url_list,interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            if not style:
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€æŠ¥å‘Šè¯„ä¼°å‡ºé”™ï¼Œå¯åŠ¨ä¿åº•æœºåˆ¶...")
                style=style_report(url_list=[],interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€é£æ ¼åˆ†æå®Œæˆ")

            # 8. ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š
            hr_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
            }
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š...")
            user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            if not user_report:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šå·²ç”Ÿæˆ")

            # 9. èšåˆæœ€ç»ˆæŠ¥å‘Š
            final_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
                "competency_model_used": competencies,
                "job_match_analysis": job_match,
                "personality_analysis": personality,
                "salary_analysis": salary,
                "style_report": style,
                "user_report": user_report
            }

            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æœ€ç»ˆæŠ¥å‘Šå·²ç”Ÿæˆ...")

            content_json = json.dumps(final_report, ensure_ascii=False)
            try:
                with get_session() as session:
                    stmt = (
                        update(SimulateReport)
                        .where(SimulateReport.interview_id == interview_id)
                        .values(
                            content=content_json,
                            updated_at=datetime.now()
                        )
                    )

                    session.exec(stmt)
                    session.flush()
                    logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-é¢è¯•æŠ¥å‘Šæ›´æ–°æˆåŠŸ")
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-å…¥åº“å¤±è´¥ï¼Œé”™è¯¯: {str(e)}")

            re = json.dumps({
                "result": final_report,
                "code": 0,
                "interview_id": int(interview_id),
            }, ensure_ascii=False)

            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šæˆåŠŸï¼Œæ€»è€—æ—¶{time.time()-zero_time}sï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")

        except Exception as e:
            logging.error(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼Œé”™è¯¯ï¼š{e}")
            re= json.dumps({
                "result": None,
                "code": 1,
                "interview_id": int(interview_id),
                "error": str(e)
            },ensure_ascii=False)
            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼ï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")
            return None

```

```python
import json
import logging
import time
import os
from datetime import datetime
from typing import Dict, List, Any
import requests
from openai import OpenAI
from app.config import url_config
from app.database import get_session
from models import SimulateReport
from service.multimodal_report import style_report
from app.config import ai_config
from sqlmodel import update
qwen_api_key = ai_config['api_key']

config = url_config
post_url = config['interview_report_post_url']
qwen_api_uri = ai_config['api_uri']
model_name = ai_config['api_model']


class AIInterviewAssessor:
    def __init__(self):
        self.llm_client = OpenAI(
            api_key=qwen_api_key,
            base_url=qwen_api_uri,
        )
        self.language_dict={
            'zhongwen': ('ä¸­æ–‡', 'ä½ å¥½ï¼Œé¢è¯•å®˜ï¼è®©æˆ‘ä»¬ç”¨ä¸­æ–‡äº¤æµï¼', 'longxiaochun_v2'),
            'yingwen': ('è‹±æ–‡', "Hello, interviewer!Let's communicate in English!", 'longxiaochun_v2'),
            'riyu': ('æ—¥è¯­', 'ã“ã‚“ã«ã¡ã¯ã€é¢æ¥å®˜ï¼æ—¥æœ¬èªã§è©±ã—åˆã„ã¾ã—ã‚‡ã†ï¼', 'loongtomoka_v2'),
            'hanyu': ('éŸ©è¯­', 'ì•ˆë…•í•˜ì„¸ìš”, ë©´ì ‘ê´€ë‹˜!í•œêµ­ì–´ë¡œ ëŒ€í™”í•´ìš”!', 'loongkyong_v2'),
            'xibanyayu': ('è¥¿ç­ç‰™è¯­', 'Â¡Hola, entrevistador!Â¡Hablemos en espaÃ±ol!', 'sambert-camila-v1'),
            'yinniyu': ('å°å°¼è¯­', 'Halo, pewawancara!Ayo berkomunikasi dalam bahasa Indonesia!', 'sambert-indah-v1'),
            'fayu': ('æ³•è¯­', 'Bonjour, intervieweur !Parlons en franÃ§ais !', 'sambert-clara-v1'),
            'deyu': ('å¾·è¯­', 'Hallo, Interviewer!Lass uns auf Deutsch sprechen!', 'sambert-hanna-v1'),
            'taiyu': ('æ³°è¯­', 'à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¹ˆà¸°/à¸„à¸£à¸±à¸š, à¸œà¸¹à¹‰à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œ!à¸¡à¸²à¸à¸¹à¸”à¸„à¸¸à¸¢à¸à¸±à¸™à¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¸à¸±à¸™à¹€à¸–à¸­à¸°!', 'sambert-waan-v1')
        }
        self.interview_language='ä¸­æ–‡'
        
        self._load_prompts()

    def _load_prompts(self):
        base_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
        prompts_dir = os.path.join(base_dir, 'prompts', 'evaluation_report')
        
        with open(os.path.join(prompts_dir, 'extract_competencies.txt'), 'r', encoding='utf-8') as f:
            self.prompt_extract_competencies = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_single_competency.txt'), 'r', encoding='utf-8') as f:
            self.prompt_analyze_single_competency = f.read()
        
        with open(os.path.join(prompts_dir, 'generate_final_summary.txt'), 'r', encoding='utf-8') as f:
            self.prompt_generate_final_summary = f.read()
        
        with open(os.path.join(prompts_dir, 'user_report.txt'), 'r', encoding='utf-8') as f:
            self.prompt_user_report = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_job_match_and_career.txt'), 'r', encoding='utf-8') as f:
            self.prompt_job_match_and_career = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_personality.txt'), 'r', encoding='utf-8') as f:
            self.prompt_personality = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_salary_market.txt'), 'r', encoding='utf-8') as f:
            self.prompt_salary_market = f.read()

    def _call_llm(self, prompt: str, system_message: str, enable_search: bool = False) -> str | None:

        params = {
            "seed": 6,
            "model": model_name,
            "temperature": 0.3,
            "response_format": {"type": "json_object"},
            "messages": [{"role": "system", "content": system_message},
                        {"role": "user", "content": prompt}]
        }
        
        # if enable_search:
        #     params["tools"] = [{"type": "web_search"}]
        
        try:
            response = self.llm_client.chat.completions.create(**params)
            content_text = response.choices[0].message.content
            return content_text
        except Exception as e:
            logging.error(f"ï¼ï¼ï¼LLMè°ƒç”¨å¤±è´¥ï¼š{e}")
            return None

    def _extract_competencies(self, jd: str,transcript_text:str) -> Dict[str, List[str]]:
        system_message = self.prompt_extract_competencies.format(interview_language=self.interview_language)

        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """

        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_single_competency(self, competency: str, transcript_text: str) -> Dict[str, Any]:
        """
        å¾ªç¯è¯„ä»·å•ä¸ªç»´åº¦ï¼Œå¸¦æ‰“åˆ†
        """
        system_message = self.prompt_analyze_single_competency.format(
            competency=competency,
            interview_language=self.interview_language
        )
        prompt = f"""
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _generate_final_summary(self, detailed_analysis_str: str) -> Dict[str, Any]:
        """
        ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        """
        system_message = self.prompt_generate_final_summary.format(interview_language=self.interview_language)

        prompt = f"""
        --- èƒ½åŠ›åˆ†ææ•°æ® ---
        {detailed_analysis_str}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_job_match_and_career(self, detailed_analysis_str: str, jd: str, transcript_text: str) -> Dict[str, Any]:
        """
        å²—ä½é€‚é…åº¦åˆ†æ + èŒä¸šå‘å±•è§„åˆ’
        """
        system_message = self.prompt_job_match_and_career.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_personality(self, jd: str, transcript_text: str) -> Dict[str, Any]:
        """
        æ€§æ ¼æ·±åº¦åˆ†æ
        """
        system_message = self.prompt_personality.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_salary_market(self, jd: str, transcript_text: str, detailed_analysis_str: str) -> Dict[str, Any]:
        """
        è–ªé…¬å¸‚åœºè¯„ä¼°ï¼ˆä½¿ç”¨æ¨¡å‹è‡ªèº«èƒ½åŠ›ï¼‰
        """
        system_message = self.prompt_salary_market.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        """
        
        response_str = self._call_llm(prompt, system_message, enable_search=False)
        if not response_str:
            return {}
        
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(f"è–ªé…¬åˆ†æJSONè§£æå¤±è´¥: {e}")
            return {}

    def _user_report(self, jd: str, transcript_text: str, hr_report, personality, salary) -> dict[str, Any]:
        """
        å€™é€‰äººé¢è¯•å¤ç›˜ï¼Œå€™é€‰äººä¸“ç”¨é¢è¯•æŠ¥å‘Š
        """
        system_message = self.prompt_user_report.format(interview_language=self.interview_language)
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        
        --- é¢è¯•å®˜çš„è¯„ä»· ---
        {hr_report}
        
        --- æ€§æ ¼åˆ†æ ---
        {json.dumps(personality, ensure_ascii=False)}
        
        --- è–ªé…¬åˆ†æ ---
        {json.dumps(salary, ensure_ascii=False)}
        
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _format_transcript(self, transcript_json: List[Dict]) -> str:
        lines = []
        for entry in transcript_json:
            role_cn = "é¢è¯•å®˜" if entry['role'] == 'interviewer' else "å€™é€‰äºº"
            lines.append(f"[å½“å‰å¯¹è¯è½®æ•°ï¼š{entry['timestamp']}] {role_cn}: {entry['content']}")
        return "\n".join(lines)

    def generate_report(self, transcript_json_str: str, jd: str,interview_id:str,url_list:list[str],is_mp4:bool,interview_language:str)   :
        try:
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- æ¥æ”¶åˆ°é¢è¯•è®°å½•ï¼Œå¼€å§‹åˆ†æ")
            zero_time = time.time()
            self.interview_language=self.language_dict[interview_language][0]
            transcript_data = json.loads(transcript_json_str)
            try:
                transcript_text = self._format_transcript(transcript_data)
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•æ–‡æœ¬è®°å½•è§£æå‡ºé”™ï¼Œ{e}ï¼Œå¼€å§‹ä½¿ç”¨æºæ•°æ®")
                transcript_text = transcript_data

            # 1. æå–èƒ½åŠ›æ¨¡å‹
            competencies = self._extract_competencies(jd,transcript_text)
            all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            if not all_competency_keys :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} -- è€ƒæ ¸ç»´åº¦æŠ½å–å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                competencies = self._extract_competencies(jd, transcript_text)
                all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è€ƒæ ¸ç»´åº¦æŠ½å–æˆåŠŸï¼š{competencies}")

            # 2. é€é¡¹è¯„ä¼°å„é¡¹èƒ½åŠ›
            detailed_analysis = []
            total_score = 0

            for competency in all_competency_keys:
                start_time=time.time()
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ­£åœ¨åˆ†æ '{competency}'...")
                analysis_result = self._analyze_single_competency(competency, transcript_text)
                if not analysis_result :
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†æç»´åº¦ï¼š{competency} å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    analysis_result = self._analyze_single_competency(competency, transcript_text)
                analysis_result['competency'] = competency
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†ææˆåŠŸï¼š{competency}ï¼Œè€—æ—¶{time.time()-start_time}s ")
                detailed_analysis.append(analysis_result)
                total_score += analysis_result.get('score', 0)

            detailed_analysis_str = json.dumps(detailed_analysis, indent=2, ensure_ascii=False)
            
            # 3. å²—ä½é€‚é…åº¦åˆ†æ + èŒä¸šå‘å±•è§„åˆ’
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æ...")
            job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            if not job_match:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æå®Œæˆ")
            
            # 4. æ€§æ ¼æ·±åº¦åˆ†æ
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹æ€§æ ¼æ·±åº¦åˆ†æ...")
            personality = self._analyze_personality(jd, transcript_text)
            if not personality:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                personality = self._analyze_personality(jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼æ·±åº¦åˆ†æå®Œæˆ")
            
            # 5. è–ªé…¬å¸‚åœºè¯„ä¼°
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹è–ªé…¬å¸‚åœºè¯„ä¼°...")
            try:
                salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
                    logging.warning(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬å¸‚åœºè¯„ä¼°å®Œæˆ")
            except Exception as e:
                logging.error(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¼‚å¸¸: {e}")
                salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
            
            # 6. ç”ŸæˆHRæ€»ç»“
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”ŸæˆHRæ€»ç»“...")
            final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ–‡æœ¬æŠ¥å‘Šæ€»ç»“å¤±è´¥ï¼Œå†æ¬¡å°è¯• - ")
                final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å†æ¬¡å°è¯•æ€»ç»“å¤±è´¥ï¼Œä¸»åŠ¨è¿”å›codeï¼š1 çŠ¶æ€ - ")
                a=1/0
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  HRæ€»ç»“ç”Ÿæˆå®Œæˆ")

            # 7. å¤šæ¨¡æ€åˆ†æ
            overall_score = round(total_score / len(all_competency_keys), 1) if all_competency_keys else -1
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å¤šæ¨¡æ€é£æ ¼åˆ†æ...")
            style=style_report(url_list=url_list,interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            if not style:
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€æŠ¥å‘Šè¯„ä¼°å‡ºé”™ï¼Œå¯åŠ¨ä¿åº•æœºåˆ¶...")
                style=style_report(url_list=[],interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€é£æ ¼åˆ†æå®Œæˆ")

            # 8. ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š
            hr_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
            }
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š...")
            user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            if not user_report:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šå·²ç”Ÿæˆ")

            # 9. èšåˆæœ€ç»ˆæŠ¥å‘Š
            final_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
                "competency_model_used": competencies,
                "job_match_analysis": job_match,
                "personality_analysis": personality,
                "salary_analysis": salary,
                "style_report": style,
                "user_report": user_report
            }

            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æœ€ç»ˆæŠ¥å‘Šå·²ç”Ÿæˆ...")

            content_json = json.dumps(final_report, ensure_ascii=False)
            try:
                with get_session() as session:
                    stmt = (
                        update(SimulateReport)
                        .where(SimulateReport.interview_id == interview_id)
                        .values(
                            content=content_json,
                            updated_at=datetime.now()
                        )
                    )

                    session.exec(stmt)
                    session.flush()
                    logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-é¢è¯•æŠ¥å‘Šæ›´æ–°æˆåŠŸ")
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-å…¥åº“å¤±è´¥ï¼Œé”™è¯¯: {str(e)}")

            re = json.dumps({
                "result": final_report,
                "code": 0,
                "interview_id": int(interview_id),
            }, ensure_ascii=False)

            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šæˆåŠŸï¼Œæ€»è€—æ—¶{time.time()-zero_time}sï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")

        except Exception as e:
            logging.error(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼Œé”™è¯¯ï¼š{e}")
            re= json.dumps({
                "result": None,
                "code": 1,
                "interview_id": int(interview_id),
                "error": str(e)
            },ensure_ascii=False)
            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼ï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")
            return None

```

```python
import json
import logging
import time
import os
from datetime import datetime
from typing import Dict, List, Any
import requests
from openai import OpenAI
from app.config import url_config
from app.database import get_session
from models import SimulateReport
from service.multimodal_report import style_report
from app.config import ai_config
from sqlmodel import update
qwen_api_key = ai_config['api_key']

config = url_config
post_url = config['interview_report_post_url']
qwen_api_uri = ai_config['api_uri']
model_name = ai_config['api_model']


class AIInterviewAssessor:
    def __init__(self):
        self.llm_client = OpenAI(
            api_key=qwen_api_key,
            base_url=qwen_api_uri,
        )
        self.language_dict={
            'zhongwen': ('ä¸­æ–‡', 'ä½ å¥½ï¼Œé¢è¯•å®˜ï¼è®©æˆ‘ä»¬ç”¨ä¸­æ–‡äº¤æµï¼', 'longxiaochun_v2'),
            'yingwen': ('è‹±æ–‡', "Hello, interviewer!Let's communicate in English!", 'longxiaochun_v2'),
            'riyu': ('æ—¥è¯­', 'ã“ã‚“ã«ã¡ã¯ã€é¢æ¥å®˜ï¼æ—¥æœ¬èªã§è©±ã—åˆã„ã¾ã—ã‚‡ã†ï¼', 'loongtomoka_v2'),
            'hanyu': ('éŸ©è¯­', 'ì•ˆë…•í•˜ì„¸ìš”, ë©´ì ‘ê´€ë‹˜!í•œêµ­ì–´ë¡œ ëŒ€í™”í•´ìš”!', 'loongkyong_v2'),
            'xibanyayu': ('è¥¿ç­ç‰™è¯­', 'Â¡Hola, entrevistador!Â¡Hablemos en espaÃ±ol!', 'sambert-camila-v1'),
            'yinniyu': ('å°å°¼è¯­', 'Halo, pewawancara!Ayo berkomunikasi dalam bahasa Indonesia!', 'sambert-indah-v1'),
            'fayu': ('æ³•è¯­', 'Bonjour, intervieweur !Parlons en franÃ§ais !', 'sambert-clara-v1'),
            'deyu': ('å¾·è¯­', 'Hallo, Interviewer!Lass uns auf Deutsch sprechen!', 'sambert-hanna-v1'),
            'taiyu': ('æ³°è¯­', 'à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¹ˆà¸°/à¸„à¸£à¸±à¸š, à¸œà¸¹à¹‰à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œ!à¸¡à¸²à¸à¸¹à¸”à¸„à¸¸à¸¢à¸à¸±à¸™à¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¸à¸±à¸™à¹€à¸–à¸­à¸°!', 'sambert-waan-v1')
        }
        self.interview_language='ä¸­æ–‡'
        
        self._load_prompts()

    def _load_prompts(self):
        base_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
        prompts_dir = os.path.join(base_dir, 'prompts', 'evaluation_report')
        
        with open(os.path.join(prompts_dir, 'extract_competencies.txt'), 'r', encoding='utf-8') as f:
            self.prompt_extract_competencies = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_single_competency.txt'), 'r', encoding='utf-8') as f:
            self.prompt_analyze_single_competency = f.read()
        
        with open(os.path.join(prompts_dir, 'generate_final_summary.txt'), 'r', encoding='utf-8') as f:
            self.prompt_generate_final_summary = f.read()
        
        with open(os.path.join(prompts_dir, 'user_report.txt'), 'r', encoding='utf-8') as f:
            self.prompt_user_report = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_job_match_and_career.txt'), 'r', encoding='utf-8') as f:
            self.prompt_job_match_and_career = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_personality.txt'), 'r', encoding='utf-8') as f:
            self.prompt_personality = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_salary_market.txt'), 'r', encoding='utf-8') as f:
            self.prompt_salary_market = f.read()

    def _call_llm(self, prompt: str, system_message: str, enable_search: bool = False) -> str | None:

        params = {
            "seed": 6,
            "model": model_name,
            "temperature": 0.3,
            "response_format": {"type": "json_object"},
            "messages": [{"role": "system", "content": system_message},
                        {"role": "user", "content": prompt}]
        }
        
        # if enable_search:
        #     params["tools"] = [{"type": "web_search"}]
        
        try:
            response = self.llm_client.chat.completions.create(**params)
            content_text = response.choices[0].message.content
            return content_text
        except Exception as e:
            logging.error(f"ï¼ï¼ï¼LLMè°ƒç”¨å¤±è´¥ï¼š{e}")
            return None

    def _extract_competencies(self, jd: str,transcript_text:str) -> Dict[str, List[str]]:
        system_message = self.prompt_extract_competencies.format(interview_language=self.interview_language)

        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """

        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_single_competency(self, competency: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_analyze_single_competency.format(
            competency=competency,
            interview_language=self.interview_language
        )
        prompt = f"""
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _generate_final_summary(self, detailed_analysis_str: str) -> Dict[str, Any]:
        """
        ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        """
        system_message = self.prompt_generate_final_summary.format(interview_language=self.interview_language)

        prompt = f"""
        --- èƒ½åŠ›åˆ†ææ•°æ® ---
        {detailed_analysis_str}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_job_match_and_career(self, detailed_analysis_str: str, jd: str, transcript_text: str) -> Dict[str, Any]:
        """
        å²—ä½é€‚é…åº¦åˆ†æ + èŒä¸šå‘å±•è§„åˆ’
        """
        system_message = self.prompt_job_match_and_career.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_personality(self, jd: str, transcript_text: str) -> Dict[str, Any]:
        """
        æ€§æ ¼æ·±åº¦åˆ†æ
        """
        system_message = self.prompt_personality.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_salary_market(self, jd: str, transcript_text: str, detailed_analysis_str: str) -> Dict[str, Any]:
        """
        è–ªé…¬å¸‚åœºè¯„ä¼°ï¼ˆä½¿ç”¨æ¨¡å‹è‡ªèº«èƒ½åŠ›ï¼‰
        """
        system_message = self.prompt_salary_market.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        """
        
        response_str = self._call_llm(prompt, system_message, enable_search=False)
        if not response_str:
            return {}
        
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(f"è–ªé…¬åˆ†æJSONè§£æå¤±è´¥: {e}")
            return {}

    def _user_report(self, jd: str, transcript_text: str, hr_report, personality, salary) -> dict[str, Any]:
        """
        å€™é€‰äººé¢è¯•å¤ç›˜ï¼Œå€™é€‰äººä¸“ç”¨é¢è¯•æŠ¥å‘Š
        """
        system_message = self.prompt_user_report.format(interview_language=self.interview_language)
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        
        --- é¢è¯•å®˜çš„è¯„ä»· ---
        {hr_report}
        
        --- æ€§æ ¼åˆ†æ ---
        {json.dumps(personality, ensure_ascii=False)}
        
        --- è–ªé…¬åˆ†æ ---
        {json.dumps(salary, ensure_ascii=False)}
        
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _format_transcript(self, transcript_json: List[Dict]) -> str:
        lines = []
        for entry in transcript_json:
            role_cn = "é¢è¯•å®˜" if entry['role'] == 'interviewer' else "å€™é€‰äºº"
            lines.append(f"[å½“å‰å¯¹è¯è½®æ•°ï¼š{entry['timestamp']}] {role_cn}: {entry['content']}")
        return "\n".join(lines)

    def generate_report(self, transcript_json_str: str, jd: str,interview_id:str,url_list:list[str],is_mp4:bool,interview_language:str)   :
        try:
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- æ¥æ”¶åˆ°é¢è¯•è®°å½•ï¼Œå¼€å§‹åˆ†æ")
            zero_time = time.time()
            self.interview_language=self.language_dict[interview_language][0]
            transcript_data = json.loads(transcript_json_str)
            try:
                transcript_text = self._format_transcript(transcript_data)
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•æ–‡æœ¬è®°å½•è§£æå‡ºé”™ï¼Œ{e}ï¼Œå¼€å§‹ä½¿ç”¨æºæ•°æ®")
                transcript_text = transcript_data

            # 1. æå–èƒ½åŠ›æ¨¡å‹
            competencies = self._extract_competencies(jd,transcript_text)
            all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            if not all_competency_keys :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} -- è€ƒæ ¸ç»´åº¦æŠ½å–å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                competencies = self._extract_competencies(jd, transcript_text)
                all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è€ƒæ ¸ç»´åº¦æŠ½å–æˆåŠŸï¼š{competencies}")

            # 2. é€é¡¹è¯„ä¼°å„é¡¹èƒ½åŠ›
            detailed_analysis = []
            total_score = 0

            for competency in all_competency_keys:
                start_time=time.time()
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ­£åœ¨åˆ†æ '{competency}'...")
                analysis_result = self._analyze_single_competency(competency, transcript_text)
                if not analysis_result :
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†æç»´åº¦ï¼š{competency} å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    analysis_result = self._analyze_single_competency(competency, transcript_text)
                analysis_result['competency'] = competency
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†ææˆåŠŸï¼š{competency}ï¼Œè€—æ—¶{time.time()-start_time}s ")
                detailed_analysis.append(analysis_result)
                total_score += analysis_result.get('score', 0)

            detailed_analysis_str = json.dumps(detailed_analysis, indent=2, ensure_ascii=False)
            
            # 3. å²—ä½é€‚é…åº¦åˆ†æ + èŒä¸šå‘å±•è§„åˆ’
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æ...")
            job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            if not job_match:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æå®Œæˆ")
            
            # 4. æ€§æ ¼æ·±åº¦åˆ†æ
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹æ€§æ ¼æ·±åº¦åˆ†æ...")
            personality = self._analyze_personality(jd, transcript_text)
            if not personality:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                personality = self._analyze_personality(jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼æ·±åº¦åˆ†æå®Œæˆ")
            
            # 5. è–ªé…¬å¸‚åœºè¯„ä¼°
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹è–ªé…¬å¸‚åœºè¯„ä¼°...")
            try:
                salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
                    logging.warning(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬å¸‚åœºè¯„ä¼°å®Œæˆ")
            except Exception as e:
                logging.error(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¼‚å¸¸: {e}")
                salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
            
            # 6. ç”ŸæˆHRæ€»ç»“
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”ŸæˆHRæ€»ç»“...")
            final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ–‡æœ¬æŠ¥å‘Šæ€»ç»“å¤±è´¥ï¼Œå†æ¬¡å°è¯• - ")
                final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å†æ¬¡å°è¯•æ€»ç»“å¤±è´¥ï¼Œä¸»åŠ¨è¿”å›codeï¼š1 çŠ¶æ€ - ")
                a=1/0
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  HRæ€»ç»“ç”Ÿæˆå®Œæˆ")

            # 7. å¤šæ¨¡æ€åˆ†æ
            overall_score = round(total_score / len(all_competency_keys), 1) if all_competency_keys else -1
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å¤šæ¨¡æ€é£æ ¼åˆ†æ...")
            style=style_report(url_list=url_list,interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            if not style:
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€æŠ¥å‘Šè¯„ä¼°å‡ºé”™ï¼Œå¯åŠ¨ä¿åº•æœºåˆ¶...")
                style=style_report(url_list=[],interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€é£æ ¼åˆ†æå®Œæˆ")

            # 8. ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š
            hr_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
            }
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š...")
            user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            if not user_report:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šå·²ç”Ÿæˆ")

            # 9. èšåˆæœ€ç»ˆæŠ¥å‘Š
            final_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
                "competency_model_used": competencies,
                "job_match_analysis": job_match,
                "personality_analysis": personality,
                "salary_analysis": salary,
                "style_report": style,
                "user_report": user_report
            }

            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æœ€ç»ˆæŠ¥å‘Šå·²ç”Ÿæˆ...")

            content_json = json.dumps(final_report, ensure_ascii=False)
            try:
                with get_session() as session:
                    stmt = (
                        update(SimulateReport)
                        .where(SimulateReport.interview_id == interview_id)
                        .values(
                            content=content_json,
                            updated_at=datetime.now()
                        )
                    )

                    session.exec(stmt)
                    session.flush()
                    logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-é¢è¯•æŠ¥å‘Šæ›´æ–°æˆåŠŸ")
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-å…¥åº“å¤±è´¥ï¼Œé”™è¯¯: {str(e)}")

            re = json.dumps({
                "result": final_report,
                "code": 0,
                "interview_id": int(interview_id),
            }, ensure_ascii=False)

            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šæˆåŠŸï¼Œæ€»è€—æ—¶{time.time()-zero_time}sï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")

        except Exception as e:
            logging.error(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼Œé”™è¯¯ï¼š{e}")
            re= json.dumps({
                "result": None,
                "code": 1,
                "interview_id": int(interview_id),
                "error": str(e)
            },ensure_ascii=False)
            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼ï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")
            return None

```

```python
import json
import logging
import time
import os
from datetime import datetime
from typing import Dict, List, Any
import requests
from openai import OpenAI
from app.config import url_config
from app.database import get_session
from models import SimulateReport
from service.multimodal_report import style_report
from app.config import ai_config
from sqlmodel import update
qwen_api_key = ai_config['api_key']

config = url_config
post_url = config['interview_report_post_url']
qwen_api_uri = ai_config['api_uri']
model_name = ai_config['api_model']


class AIInterviewAssessor:
    def __init__(self):
        self.llm_client = OpenAI(
            api_key=qwen_api_key,
            base_url=qwen_api_uri,
        )
        self.language_dict={
            'zhongwen': ('ä¸­æ–‡', 'ä½ å¥½ï¼Œé¢è¯•å®˜ï¼è®©æˆ‘ä»¬ç”¨ä¸­æ–‡äº¤æµï¼', 'longxiaochun_v2'),
            'yingwen': ('è‹±æ–‡', "Hello, interviewer!Let's communicate in English!", 'longxiaochun_v2'),
            'riyu': ('æ—¥è¯­', 'ã“ã‚“ã«ã¡ã¯ã€é¢æ¥å®˜ï¼æ—¥æœ¬èªã§è©±ã—åˆã„ã¾ã—ã‚‡ã†ï¼', 'loongtomoka_v2'),
            'hanyu': ('éŸ©è¯­', 'ì•ˆë…•í•˜ì„¸ìš”, ë©´ì ‘ê´€ë‹˜!í•œêµ­ì–´ë¡œ ëŒ€í™”í•´ìš”!', 'loongkyong_v2'),
            'xibanyayu': ('è¥¿ç­ç‰™è¯­', 'Â¡Hola, entrevistador!Â¡Hablemos en espaÃ±ol!', 'sambert-camila-v1'),
            'yinniyu': ('å°å°¼è¯­', 'Halo, pewawancara!Ayo berkomunikasi dalam bahasa Indonesia!', 'sambert-indah-v1'),
            'fayu': ('æ³•è¯­', 'Bonjour, intervieweur !Parlons en franÃ§ais !', 'sambert-clara-v1'),
            'deyu': ('å¾·è¯­', 'Hallo, Interviewer!Lass uns auf Deutsch sprechen!', 'sambert-hanna-v1'),
            'taiyu': ('æ³°è¯­', 'à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¹ˆà¸°/à¸„à¸£à¸±à¸š, à¸œà¸¹à¹‰à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œ!à¸¡à¸²à¸à¸¹à¸”à¸„à¸¸à¸¢à¸à¸±à¸™à¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¸à¸±à¸™à¹€à¸–à¸­à¸°!', 'sambert-waan-v1')
        }
        self.interview_language='ä¸­æ–‡'
        
        self._load_prompts()

    def _load_prompts(self):
        base_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
        prompts_dir = os.path.join(base_dir, 'prompts', 'evaluation_report')
        
        with open(os.path.join(prompts_dir, 'extract_competencies.txt'), 'r', encoding='utf-8') as f:
            self.prompt_extract_competencies = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_single_competency.txt'), 'r', encoding='utf-8') as f:
            self.prompt_analyze_single_competency = f.read()
        
        with open(os.path.join(prompts_dir, 'generate_final_summary.txt'), 'r', encoding='utf-8') as f:
            self.prompt_generate_final_summary = f.read()
        
        with open(os.path.join(prompts_dir, 'user_report.txt'), 'r', encoding='utf-8') as f:
            self.prompt_user_report = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_job_match_and_career.txt'), 'r', encoding='utf-8') as f:
            self.prompt_job_match_and_career = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_personality.txt'), 'r', encoding='utf-8') as f:
            self.prompt_personality = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_salary_market.txt'), 'r', encoding='utf-8') as f:
            self.prompt_salary_market = f.read()

    def _call_llm(self, prompt: str, system_message: str, enable_search: bool = False) -> str | None:

        params = {
            "seed": 6,
            "model": model_name,
            "temperature": 0.3,
            "response_format": {"type": "json_object"},
            "messages": [{"role": "system", "content": system_message},
                        {"role": "user", "content": prompt}]
        }
        
        # if enable_search:
        #     params["tools"] = [{"type": "web_search"}]
        
        try:
            response = self.llm_client.chat.completions.create(**params)
            content_text = response.choices[0].message.content
            return content_text
        except Exception as e:
            logging.error(f"ï¼ï¼ï¼LLMè°ƒç”¨å¤±è´¥ï¼š{e}")
            return None

    def _extract_competencies(self, jd: str,transcript_text:str) -> Dict[str, List[str]]:
        system_message = self.prompt_extract_competencies.format(interview_language=self.interview_language)

        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """

        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_single_competency(self, competency: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_analyze_single_competency.format(
            competency=competency,
            interview_language=self.interview_language
        )
        prompt = f"""
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _generate_final_summary(self, detailed_analysis_str: str) -> Dict[str, Any]:
        system_message = self.prompt_generate_final_summary.format(interview_language=self.interview_language)

        prompt = f"""
        --- èƒ½åŠ›åˆ†ææ•°æ® ---
        {detailed_analysis_str}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_job_match_and_career(self, detailed_analysis_str: str, jd: str, transcript_text: str) -> Dict[str, Any]:
        """
        å²—ä½é€‚é…åº¦åˆ†æ + èŒä¸šå‘å±•è§„åˆ’
        """
        system_message = self.prompt_job_match_and_career.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_personality(self, jd: str, transcript_text: str) -> Dict[str, Any]:
        """
        æ€§æ ¼æ·±åº¦åˆ†æ
        """
        system_message = self.prompt_personality.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_salary_market(self, jd: str, transcript_text: str, detailed_analysis_str: str) -> Dict[str, Any]:
        """
        è–ªé…¬å¸‚åœºè¯„ä¼°ï¼ˆä½¿ç”¨æ¨¡å‹è‡ªèº«èƒ½åŠ›ï¼‰
        """
        system_message = self.prompt_salary_market.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        """
        
        response_str = self._call_llm(prompt, system_message, enable_search=False)
        if not response_str:
            return {}
        
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(f"è–ªé…¬åˆ†æJSONè§£æå¤±è´¥: {e}")
            return {}

    def _user_report(self, jd: str, transcript_text: str, hr_report, personality, salary) -> dict[str, Any]:
        """
        å€™é€‰äººé¢è¯•å¤ç›˜ï¼Œå€™é€‰äººä¸“ç”¨é¢è¯•æŠ¥å‘Š
        """
        system_message = self.prompt_user_report.format(interview_language=self.interview_language)
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        
        --- é¢è¯•å®˜çš„è¯„ä»· ---
        {hr_report}
        
        --- æ€§æ ¼åˆ†æ ---
        {json.dumps(personality, ensure_ascii=False)}
        
        --- è–ªé…¬åˆ†æ ---
        {json.dumps(salary, ensure_ascii=False)}
        
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _format_transcript(self, transcript_json: List[Dict]) -> str:
        lines = []
        for entry in transcript_json:
            role_cn = "é¢è¯•å®˜" if entry['role'] == 'interviewer' else "å€™é€‰äºº"
            lines.append(f"[å½“å‰å¯¹è¯è½®æ•°ï¼š{entry['timestamp']}] {role_cn}: {entry['content']}")
        return "\n".join(lines)

    def generate_report(self, transcript_json_str: str, jd: str,interview_id:str,url_list:list[str],is_mp4:bool,interview_language:str)   :
        try:
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- æ¥æ”¶åˆ°é¢è¯•è®°å½•ï¼Œå¼€å§‹åˆ†æ")
            zero_time = time.time()
            self.interview_language=self.language_dict[interview_language][0]
            transcript_data = json.loads(transcript_json_str)
            try:
                transcript_text = self._format_transcript(transcript_data)
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•æ–‡æœ¬è®°å½•è§£æå‡ºé”™ï¼Œ{e}ï¼Œå¼€å§‹ä½¿ç”¨æºæ•°æ®")
                transcript_text = transcript_data

            # 1. æå–èƒ½åŠ›æ¨¡å‹
            competencies = self._extract_competencies(jd,transcript_text)
            all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            if not all_competency_keys :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} -- è€ƒæ ¸ç»´åº¦æŠ½å–å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                competencies = self._extract_competencies(jd, transcript_text)
                all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è€ƒæ ¸ç»´åº¦æŠ½å–æˆåŠŸï¼š{competencies}")

            # 2. é€é¡¹è¯„ä¼°å„é¡¹èƒ½åŠ›
            detailed_analysis = []
            total_score = 0

            for competency in all_competency_keys:
                start_time=time.time()
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ­£åœ¨åˆ†æ '{competency}'...")
                analysis_result = self._analyze_single_competency(competency, transcript_text)
                if not analysis_result :
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†æç»´åº¦ï¼š{competency} å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    analysis_result = self._analyze_single_competency(competency, transcript_text)
                analysis_result['competency'] = competency
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†ææˆåŠŸï¼š{competency}ï¼Œè€—æ—¶{time.time()-start_time}s ")
                detailed_analysis.append(analysis_result)
                total_score += analysis_result.get('score', 0)

            detailed_analysis_str = json.dumps(detailed_analysis, indent=2, ensure_ascii=False)
            
            # 3. å²—ä½é€‚é…åº¦åˆ†æ + èŒä¸šå‘å±•è§„åˆ’
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æ...")
            job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            if not job_match:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æå®Œæˆ")
            
            # 4. æ€§æ ¼æ·±åº¦åˆ†æ
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹æ€§æ ¼æ·±åº¦åˆ†æ...")
            personality = self._analyze_personality(jd, transcript_text)
            if not personality:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                personality = self._analyze_personality(jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼æ·±åº¦åˆ†æå®Œæˆ")
            
            # 5. è–ªé…¬å¸‚åœºè¯„ä¼°
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹è–ªé…¬å¸‚åœºè¯„ä¼°...")
            try:
                salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
                    logging.warning(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬å¸‚åœºè¯„ä¼°å®Œæˆ")
            except Exception as e:
                logging.error(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¼‚å¸¸: {e}")
                salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
            
            # 6. ç”ŸæˆHRæ€»ç»“
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”ŸæˆHRæ€»ç»“...")
            final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ–‡æœ¬æŠ¥å‘Šæ€»ç»“å¤±è´¥ï¼Œå†æ¬¡å°è¯• - ")
                final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å†æ¬¡å°è¯•æ€»ç»“å¤±è´¥ï¼Œä¸»åŠ¨è¿”å›codeï¼š1 çŠ¶æ€ - ")
                a=1/0
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  HRæ€»ç»“ç”Ÿæˆå®Œæˆ")

            # 7. å¤šæ¨¡æ€åˆ†æ
            overall_score = round(total_score / len(all_competency_keys), 1) if all_competency_keys else -1
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å¤šæ¨¡æ€é£æ ¼åˆ†æ...")
            style=style_report(url_list=url_list,interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            if not style:
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€æŠ¥å‘Šè¯„ä¼°å‡ºé”™ï¼Œå¯åŠ¨ä¿åº•æœºåˆ¶...")
                style=style_report(url_list=[],interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€é£æ ¼åˆ†æå®Œæˆ")

            # 8. ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š
            hr_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
            }
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š...")
            user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            if not user_report:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šå·²ç”Ÿæˆ")

            # 9. èšåˆæœ€ç»ˆæŠ¥å‘Š
            final_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
                "competency_model_used": competencies,
                "job_match_analysis": job_match,
                "personality_analysis": personality,
                "salary_analysis": salary,
                "style_report": style,
                "user_report": user_report
            }

            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æœ€ç»ˆæŠ¥å‘Šå·²ç”Ÿæˆ...")

            content_json = json.dumps(final_report, ensure_ascii=False)
            try:
                with get_session() as session:
                    stmt = (
                        update(SimulateReport)
                        .where(SimulateReport.interview_id == interview_id)
                        .values(
                            content=content_json,
                            updated_at=datetime.now()
                        )
                    )

                    session.exec(stmt)
                    session.flush()
                    logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-é¢è¯•æŠ¥å‘Šæ›´æ–°æˆåŠŸ")
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-å…¥åº“å¤±è´¥ï¼Œé”™è¯¯: {str(e)}")

            re = json.dumps({
                "result": final_report,
                "code": 0,
                "interview_id": int(interview_id),
            }, ensure_ascii=False)

            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šæˆåŠŸï¼Œæ€»è€—æ—¶{time.time()-zero_time}sï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")

        except Exception as e:
            logging.error(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼Œé”™è¯¯ï¼š{e}")
            re= json.dumps({
                "result": None,
                "code": 1,
                "interview_id": int(interview_id),
                "error": str(e)
            },ensure_ascii=False)
            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼ï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")
            return None

```

```python
import json
import logging
import time
import os
from datetime import datetime
from typing import Dict, List, Any
import requests
from openai import OpenAI
from app.config import url_config
from app.database import get_session
from models import SimulateReport
from service.multimodal_report import style_report
from app.config import ai_config
from sqlmodel import update
qwen_api_key = ai_config['api_key']

config = url_config
post_url = config['interview_report_post_url']
qwen_api_uri = ai_config['api_uri']
model_name = ai_config['api_model']


class AIInterviewAssessor:
    def __init__(self):
        self.llm_client = OpenAI(
            api_key=qwen_api_key,
            base_url=qwen_api_uri,
        )
        self.language_dict={
            'zhongwen': ('ä¸­æ–‡', 'ä½ å¥½ï¼Œé¢è¯•å®˜ï¼è®©æˆ‘ä»¬ç”¨ä¸­æ–‡äº¤æµï¼', 'longxiaochun_v2'),
            'yingwen': ('è‹±æ–‡', "Hello, interviewer!Let's communicate in English!", 'longxiaochun_v2'),
            'riyu': ('æ—¥è¯­', 'ã“ã‚“ã«ã¡ã¯ã€é¢æ¥å®˜ï¼æ—¥æœ¬èªã§è©±ã—åˆã„ã¾ã—ã‚‡ã†ï¼', 'loongtomoka_v2'),
            'hanyu': ('éŸ©è¯­', 'ì•ˆë…•í•˜ì„¸ìš”, ë©´ì ‘ê´€ë‹˜!í•œêµ­ì–´ë¡œ ëŒ€í™”í•´ìš”!', 'loongkyong_v2'),
            'xibanyayu': ('è¥¿ç­ç‰™è¯­', 'Â¡Hola, entrevistador!Â¡Hablemos en espaÃ±ol!', 'sambert-camila-v1'),
            'yinniyu': ('å°å°¼è¯­', 'Halo, pewawancara!Ayo berkomunikasi dalam bahasa Indonesia!', 'sambert-indah-v1'),
            'fayu': ('æ³•è¯­', 'Bonjour, intervieweur !Parlons en franÃ§ais !', 'sambert-clara-v1'),
            'deyu': ('å¾·è¯­', 'Hallo, Interviewer!Lass uns auf Deutsch sprechen!', 'sambert-hanna-v1'),
            'taiyu': ('æ³°è¯­', 'à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¹ˆà¸°/à¸„à¸£à¸±à¸š, à¸œà¸¹à¹‰à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œ!à¸¡à¸²à¸à¸¹à¸”à¸„à¸¸à¸¢à¸à¸±à¸™à¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¸à¸±à¸™à¹€à¸–à¸­à¸°!', 'sambert-waan-v1')
        }
        self.interview_language='ä¸­æ–‡'
        
        self._load_prompts()

    def _load_prompts(self):
        base_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
        prompts_dir = os.path.join(base_dir, 'prompts', 'evaluation_report')
        
        with open(os.path.join(prompts_dir, 'extract_competencies.txt'), 'r', encoding='utf-8') as f:
            self.prompt_extract_competencies = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_single_competency.txt'), 'r', encoding='utf-8') as f:
            self.prompt_analyze_single_competency = f.read()
        
        with open(os.path.join(prompts_dir, 'generate_final_summary.txt'), 'r', encoding='utf-8') as f:
            self.prompt_generate_final_summary = f.read()
        
        with open(os.path.join(prompts_dir, 'user_report.txt'), 'r', encoding='utf-8') as f:
            self.prompt_user_report = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_job_match_and_career.txt'), 'r', encoding='utf-8') as f:
            self.prompt_job_match_and_career = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_personality.txt'), 'r', encoding='utf-8') as f:
            self.prompt_personality = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_salary_market.txt'), 'r', encoding='utf-8') as f:
            self.prompt_salary_market = f.read()

    def _call_llm(self, prompt: str, system_message: str, enable_search: bool = False) -> str | None:

        params = {
            "seed": 6,
            "model": model_name,
            "temperature": 0.3,
            "response_format": {"type": "json_object"},
            "messages": [{"role": "system", "content": system_message},
                        {"role": "user", "content": prompt}]
        }
        
        # if enable_search:
        #     params["tools"] = [{"type": "web_search"}]
        
        try:
            response = self.llm_client.chat.completions.create(**params)
            content_text = response.choices[0].message.content
            return content_text
        except Exception as e:
            logging.error(f"ï¼ï¼ï¼LLMè°ƒç”¨å¤±è´¥ï¼š{e}")
            return None

    def _extract_competencies(self, jd: str,transcript_text:str) -> Dict[str, List[str]]:
        system_message = self.prompt_extract_competencies.format(interview_language=self.interview_language)

        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """

        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_single_competency(self, competency: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_analyze_single_competency.format(
            competency=competency,
            interview_language=self.interview_language
        )
        prompt = f"""
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _generate_final_summary(self, detailed_analysis_str: str) -> Dict[str, Any]:
        system_message = self.prompt_generate_final_summary.format(interview_language=self.interview_language)

        prompt = f"""
        --- èƒ½åŠ›åˆ†ææ•°æ® ---
        {detailed_analysis_str}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_job_match_and_career(self, detailed_analysis_str: str, jd: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_job_match_and_career.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_personality(self, jd: str, transcript_text: str) -> Dict[str, Any]:
        """
        æ€§æ ¼æ·±åº¦åˆ†æ
        """
        system_message = self.prompt_personality.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_salary_market(self, jd: str, transcript_text: str, detailed_analysis_str: str) -> Dict[str, Any]:
        """
        è–ªé…¬å¸‚åœºè¯„ä¼°ï¼ˆä½¿ç”¨æ¨¡å‹è‡ªèº«èƒ½åŠ›ï¼‰
        """
        system_message = self.prompt_salary_market.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        """
        
        response_str = self._call_llm(prompt, system_message, enable_search=False)
        if not response_str:
            return {}
        
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(f"è–ªé…¬åˆ†æJSONè§£æå¤±è´¥: {e}")
            return {}

    def _user_report(self, jd: str, transcript_text: str, hr_report, personality, salary) -> dict[str, Any]:
        """
        å€™é€‰äººé¢è¯•å¤ç›˜ï¼Œå€™é€‰äººä¸“ç”¨é¢è¯•æŠ¥å‘Š
        """
        system_message = self.prompt_user_report.format(interview_language=self.interview_language)
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        
        --- é¢è¯•å®˜çš„è¯„ä»· ---
        {hr_report}
        
        --- æ€§æ ¼åˆ†æ ---
        {json.dumps(personality, ensure_ascii=False)}
        
        --- è–ªé…¬åˆ†æ ---
        {json.dumps(salary, ensure_ascii=False)}
        
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _format_transcript(self, transcript_json: List[Dict]) -> str:
        lines = []
        for entry in transcript_json:
            role_cn = "é¢è¯•å®˜" if entry['role'] == 'interviewer' else "å€™é€‰äºº"
            lines.append(f"[å½“å‰å¯¹è¯è½®æ•°ï¼š{entry['timestamp']}] {role_cn}: {entry['content']}")
        return "\n".join(lines)

    def generate_report(self, transcript_json_str: str, jd: str,interview_id:str,url_list:list[str],is_mp4:bool,interview_language:str)   :
        try:
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- æ¥æ”¶åˆ°é¢è¯•è®°å½•ï¼Œå¼€å§‹åˆ†æ")
            zero_time = time.time()
            self.interview_language=self.language_dict[interview_language][0]
            transcript_data = json.loads(transcript_json_str)
            try:
                transcript_text = self._format_transcript(transcript_data)
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•æ–‡æœ¬è®°å½•è§£æå‡ºé”™ï¼Œ{e}ï¼Œå¼€å§‹ä½¿ç”¨æºæ•°æ®")
                transcript_text = transcript_data

            # 1. æå–èƒ½åŠ›æ¨¡å‹
            competencies = self._extract_competencies(jd,transcript_text)
            all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            if not all_competency_keys :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} -- è€ƒæ ¸ç»´åº¦æŠ½å–å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                competencies = self._extract_competencies(jd, transcript_text)
                all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è€ƒæ ¸ç»´åº¦æŠ½å–æˆåŠŸï¼š{competencies}")

            # 2. é€é¡¹è¯„ä¼°å„é¡¹èƒ½åŠ›
            detailed_analysis = []
            total_score = 0

            for competency in all_competency_keys:
                start_time=time.time()
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ­£åœ¨åˆ†æ '{competency}'...")
                analysis_result = self._analyze_single_competency(competency, transcript_text)
                if not analysis_result :
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†æç»´åº¦ï¼š{competency} å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    analysis_result = self._analyze_single_competency(competency, transcript_text)
                analysis_result['competency'] = competency
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†ææˆåŠŸï¼š{competency}ï¼Œè€—æ—¶{time.time()-start_time}s ")
                detailed_analysis.append(analysis_result)
                total_score += analysis_result.get('score', 0)

            detailed_analysis_str = json.dumps(detailed_analysis, indent=2, ensure_ascii=False)
            
            # 3. å²—ä½é€‚é…åº¦åˆ†æ + èŒä¸šå‘å±•è§„åˆ’
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æ...")
            job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            if not job_match:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æå®Œæˆ")
            
            # 4. æ€§æ ¼æ·±åº¦åˆ†æ
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹æ€§æ ¼æ·±åº¦åˆ†æ...")
            personality = self._analyze_personality(jd, transcript_text)
            if not personality:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                personality = self._analyze_personality(jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼æ·±åº¦åˆ†æå®Œæˆ")
            
            # 5. è–ªé…¬å¸‚åœºè¯„ä¼°
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹è–ªé…¬å¸‚åœºè¯„ä¼°...")
            try:
                salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
                    logging.warning(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬å¸‚åœºè¯„ä¼°å®Œæˆ")
            except Exception as e:
                logging.error(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¼‚å¸¸: {e}")
                salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
            
            # 6. ç”ŸæˆHRæ€»ç»“
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”ŸæˆHRæ€»ç»“...")
            final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ–‡æœ¬æŠ¥å‘Šæ€»ç»“å¤±è´¥ï¼Œå†æ¬¡å°è¯• - ")
                final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å†æ¬¡å°è¯•æ€»ç»“å¤±è´¥ï¼Œä¸»åŠ¨è¿”å›codeï¼š1 çŠ¶æ€ - ")
                a=1/0
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  HRæ€»ç»“ç”Ÿæˆå®Œæˆ")

            # 7. å¤šæ¨¡æ€åˆ†æ
            overall_score = round(total_score / len(all_competency_keys), 1) if all_competency_keys else -1
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å¤šæ¨¡æ€é£æ ¼åˆ†æ...")
            style=style_report(url_list=url_list,interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            if not style:
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€æŠ¥å‘Šè¯„ä¼°å‡ºé”™ï¼Œå¯åŠ¨ä¿åº•æœºåˆ¶...")
                style=style_report(url_list=[],interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€é£æ ¼åˆ†æå®Œæˆ")

            # 8. ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š
            hr_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
            }
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š...")
            user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            if not user_report:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šå·²ç”Ÿæˆ")

            # 9. èšåˆæœ€ç»ˆæŠ¥å‘Š
            final_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
                "competency_model_used": competencies,
                "job_match_analysis": job_match,
                "personality_analysis": personality,
                "salary_analysis": salary,
                "style_report": style,
                "user_report": user_report
            }

            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æœ€ç»ˆæŠ¥å‘Šå·²ç”Ÿæˆ...")

            content_json = json.dumps(final_report, ensure_ascii=False)
            try:
                with get_session() as session:
                    stmt = (
                        update(SimulateReport)
                        .where(SimulateReport.interview_id == interview_id)
                        .values(
                            content=content_json,
                            updated_at=datetime.now()
                        )
                    )

                    session.exec(stmt)
                    session.flush()
                    logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-é¢è¯•æŠ¥å‘Šæ›´æ–°æˆåŠŸ")
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-å…¥åº“å¤±è´¥ï¼Œé”™è¯¯: {str(e)}")

            re = json.dumps({
                "result": final_report,
                "code": 0,
                "interview_id": int(interview_id),
            }, ensure_ascii=False)

            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šæˆåŠŸï¼Œæ€»è€—æ—¶{time.time()-zero_time}sï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")

        except Exception as e:
            logging.error(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼Œé”™è¯¯ï¼š{e}")
            re= json.dumps({
                "result": None,
                "code": 1,
                "interview_id": int(interview_id),
                "error": str(e)
            },ensure_ascii=False)
            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼ï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")
            return None

```

```python
import json
import logging
import time
import os
from datetime import datetime
from typing import Dict, List, Any
import requests
from openai import OpenAI
from app.config import url_config
from app.database import get_session
from models import SimulateReport
from service.multimodal_report import style_report
from app.config import ai_config
from sqlmodel import update
qwen_api_key = ai_config['api_key']

config = url_config
post_url = config['interview_report_post_url']
qwen_api_uri = ai_config['api_uri']
model_name = ai_config['api_model']


class AIInterviewAssessor:
    def __init__(self):
        self.llm_client = OpenAI(
            api_key=qwen_api_key,
            base_url=qwen_api_uri,
        )
        self.language_dict={
            'zhongwen': ('ä¸­æ–‡', 'ä½ å¥½ï¼Œé¢è¯•å®˜ï¼è®©æˆ‘ä»¬ç”¨ä¸­æ–‡äº¤æµï¼', 'longxiaochun_v2'),
            'yingwen': ('è‹±æ–‡', "Hello, interviewer!Let's communicate in English!", 'longxiaochun_v2'),
            'riyu': ('æ—¥è¯­', 'ã“ã‚“ã«ã¡ã¯ã€é¢æ¥å®˜ï¼æ—¥æœ¬èªã§è©±ã—åˆã„ã¾ã—ã‚‡ã†ï¼', 'loongtomoka_v2'),
            'hanyu': ('éŸ©è¯­', 'ì•ˆë…•í•˜ì„¸ìš”, ë©´ì ‘ê´€ë‹˜!í•œêµ­ì–´ë¡œ ëŒ€í™”í•´ìš”!', 'loongkyong_v2'),
            'xibanyayu': ('è¥¿ç­ç‰™è¯­', 'Â¡Hola, entrevistador!Â¡Hablemos en espaÃ±ol!', 'sambert-camila-v1'),
            'yinniyu': ('å°å°¼è¯­', 'Halo, pewawancara!Ayo berkomunikasi dalam bahasa Indonesia!', 'sambert-indah-v1'),
            'fayu': ('æ³•è¯­', 'Bonjour, intervieweur !Parlons en franÃ§ais !', 'sambert-clara-v1'),
            'deyu': ('å¾·è¯­', 'Hallo, Interviewer!Lass uns auf Deutsch sprechen!', 'sambert-hanna-v1'),
            'taiyu': ('æ³°è¯­', 'à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¹ˆà¸°/à¸„à¸£à¸±à¸š, à¸œà¸¹à¹‰à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œ!à¸¡à¸²à¸à¸¹à¸”à¸„à¸¸à¸¢à¸à¸±à¸™à¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¸à¸±à¸™à¹€à¸–à¸­à¸°!', 'sambert-waan-v1')
        }
        self.interview_language='ä¸­æ–‡'
        
        self._load_prompts()

    def _load_prompts(self):
        base_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
        prompts_dir = os.path.join(base_dir, 'prompts', 'evaluation_report')
        
        with open(os.path.join(prompts_dir, 'extract_competencies.txt'), 'r', encoding='utf-8') as f:
            self.prompt_extract_competencies = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_single_competency.txt'), 'r', encoding='utf-8') as f:
            self.prompt_analyze_single_competency = f.read()
        
        with open(os.path.join(prompts_dir, 'generate_final_summary.txt'), 'r', encoding='utf-8') as f:
            self.prompt_generate_final_summary = f.read()
        
        with open(os.path.join(prompts_dir, 'user_report.txt'), 'r', encoding='utf-8') as f:
            self.prompt_user_report = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_job_match_and_career.txt'), 'r', encoding='utf-8') as f:
            self.prompt_job_match_and_career = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_personality.txt'), 'r', encoding='utf-8') as f:
            self.prompt_personality = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_salary_market.txt'), 'r', encoding='utf-8') as f:
            self.prompt_salary_market = f.read()

    def _call_llm(self, prompt: str, system_message: str, enable_search: bool = False) -> str | None:

        params = {
            "seed": 6,
            "model": model_name,
            "temperature": 0.3,
            "response_format": {"type": "json_object"},
            "messages": [{"role": "system", "content": system_message},
                        {"role": "user", "content": prompt}]
        }
        
        # è”ç½‘æœç´¢åŠŸèƒ½æš‚æ—¶ç¦ç”¨ï¼ˆAPIæ ¼å¼é—®é¢˜ï¼‰
        # if enable_search:
        #     params["tools"] = [{"type": "web_search"}]
        
        try:
            response = self.llm_client.chat.completions.create(**params)
            content_text = response.choices[0].message.content
            return content_text
        except Exception as e:
            logging.error(f"ï¼ï¼ï¼LLMè°ƒç”¨å¤±è´¥ï¼š{e}")
            return None

    def _extract_competencies(self, jd: str,transcript_text:str) -> Dict[str, List[str]]:
        system_message = self.prompt_extract_competencies.format(interview_language=self.interview_language)

        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """

        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_single_competency(self, competency: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_analyze_single_competency.format(
            competency=competency,
            interview_language=self.interview_language
        )
        prompt = f"""
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _generate_final_summary(self, detailed_analysis_str: str) -> Dict[str, Any]:
        system_message = self.prompt_generate_final_summary.format(interview_language=self.interview_language)

        prompt = f"""
        --- èƒ½åŠ›åˆ†ææ•°æ® ---
        {detailed_analysis_str}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_job_match_and_career(self, detailed_analysis_str: str, jd: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_job_match_and_career.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_personality(self, jd: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_personality.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_salary_market(self, jd: str, transcript_text: str, detailed_analysis_str: str) -> Dict[str, Any]:
        """
        è–ªé…¬å¸‚åœºè¯„ä¼°ï¼ˆä½¿ç”¨æ¨¡å‹è‡ªèº«èƒ½åŠ›ï¼‰
        """
        system_message = self.prompt_salary_market.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        """
        
        response_str = self._call_llm(prompt, system_message, enable_search=False)
        if not response_str:
            return {}
        
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(f"è–ªé…¬åˆ†æJSONè§£æå¤±è´¥: {e}")
            return {}

    def _user_report(self, jd: str, transcript_text: str, hr_report, personality, salary) -> dict[str, Any]:
        """
        å€™é€‰äººé¢è¯•å¤ç›˜ï¼Œå€™é€‰äººä¸“ç”¨é¢è¯•æŠ¥å‘Š
        """
        system_message = self.prompt_user_report.format(interview_language=self.interview_language)
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        
        --- é¢è¯•å®˜çš„è¯„ä»· ---
        {hr_report}
        
        --- æ€§æ ¼åˆ†æ ---
        {json.dumps(personality, ensure_ascii=False)}
        
        --- è–ªé…¬åˆ†æ ---
        {json.dumps(salary, ensure_ascii=False)}
        
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _format_transcript(self, transcript_json: List[Dict]) -> str:
        lines = []
        for entry in transcript_json:
            role_cn = "é¢è¯•å®˜" if entry['role'] == 'interviewer' else "å€™é€‰äºº"
            lines.append(f"[å½“å‰å¯¹è¯è½®æ•°ï¼š{entry['timestamp']}] {role_cn}: {entry['content']}")
        return "\n".join(lines)

    def generate_report(self, transcript_json_str: str, jd: str,interview_id:str,url_list:list[str],is_mp4:bool,interview_language:str)   :
        try:
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- æ¥æ”¶åˆ°é¢è¯•è®°å½•ï¼Œå¼€å§‹åˆ†æ")
            zero_time = time.time()
            self.interview_language=self.language_dict[interview_language][0]
            transcript_data = json.loads(transcript_json_str)
            try:
                transcript_text = self._format_transcript(transcript_data)
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•æ–‡æœ¬è®°å½•è§£æå‡ºé”™ï¼Œ{e}ï¼Œå¼€å§‹ä½¿ç”¨æºæ•°æ®")
                transcript_text = transcript_data

            # 1. æå–èƒ½åŠ›æ¨¡å‹
            competencies = self._extract_competencies(jd,transcript_text)
            all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            if not all_competency_keys :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} -- è€ƒæ ¸ç»´åº¦æŠ½å–å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                competencies = self._extract_competencies(jd, transcript_text)
                all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è€ƒæ ¸ç»´åº¦æŠ½å–æˆåŠŸï¼š{competencies}")

            # 2. é€é¡¹è¯„ä¼°å„é¡¹èƒ½åŠ›
            detailed_analysis = []
            total_score = 0

            for competency in all_competency_keys:
                start_time=time.time()
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ­£åœ¨åˆ†æ '{competency}'...")
                analysis_result = self._analyze_single_competency(competency, transcript_text)
                if not analysis_result :
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†æç»´åº¦ï¼š{competency} å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    analysis_result = self._analyze_single_competency(competency, transcript_text)
                analysis_result['competency'] = competency
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†ææˆåŠŸï¼š{competency}ï¼Œè€—æ—¶{time.time()-start_time}s ")
                detailed_analysis.append(analysis_result)
                total_score += analysis_result.get('score', 0)

            detailed_analysis_str = json.dumps(detailed_analysis, indent=2, ensure_ascii=False)
            
            # 3. å²—ä½é€‚é…åº¦åˆ†æ + èŒä¸šå‘å±•è§„åˆ’
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æ...")
            job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            if not job_match:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æå®Œæˆ")
            
            # 4. æ€§æ ¼æ·±åº¦åˆ†æ
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹æ€§æ ¼æ·±åº¦åˆ†æ...")
            personality = self._analyze_personality(jd, transcript_text)
            if not personality:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                personality = self._analyze_personality(jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼æ·±åº¦åˆ†æå®Œæˆ")
            
            # 5. è–ªé…¬å¸‚åœºè¯„ä¼°
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹è–ªé…¬å¸‚åœºè¯„ä¼°...")
            try:
                salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
                    logging.warning(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬å¸‚åœºè¯„ä¼°å®Œæˆ")
            except Exception as e:
                logging.error(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¼‚å¸¸: {e}")
                salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
            
            # 6. ç”ŸæˆHRæ€»ç»“
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”ŸæˆHRæ€»ç»“...")
            final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ–‡æœ¬æŠ¥å‘Šæ€»ç»“å¤±è´¥ï¼Œå†æ¬¡å°è¯• - ")
                final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å†æ¬¡å°è¯•æ€»ç»“å¤±è´¥ï¼Œä¸»åŠ¨è¿”å›codeï¼š1 çŠ¶æ€ - ")
                a=1/0
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  HRæ€»ç»“ç”Ÿæˆå®Œæˆ")

            # 7. å¤šæ¨¡æ€åˆ†æ
            overall_score = round(total_score / len(all_competency_keys), 1) if all_competency_keys else -1
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å¤šæ¨¡æ€é£æ ¼åˆ†æ...")
            style=style_report(url_list=url_list,interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            if not style:
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€æŠ¥å‘Šè¯„ä¼°å‡ºé”™ï¼Œå¯åŠ¨ä¿åº•æœºåˆ¶...")
                style=style_report(url_list=[],interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€é£æ ¼åˆ†æå®Œæˆ")

            # 8. ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š
            hr_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
            }
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š...")
            user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            if not user_report:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šå·²ç”Ÿæˆ")

            # 9. èšåˆæœ€ç»ˆæŠ¥å‘Š
            final_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
                "competency_model_used": competencies,
                "job_match_analysis": job_match,
                "personality_analysis": personality,
                "salary_analysis": salary,
                "style_report": style,
                "user_report": user_report
            }

            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æœ€ç»ˆæŠ¥å‘Šå·²ç”Ÿæˆ...")

            content_json = json.dumps(final_report, ensure_ascii=False)
            try:
                with get_session() as session:
                    stmt = (
                        update(SimulateReport)
                        .where(SimulateReport.interview_id == interview_id)
                        .values(
                            content=content_json,
                            updated_at=datetime.now()
                        )
                    )

                    session.exec(stmt)
                    session.flush()
                    logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-é¢è¯•æŠ¥å‘Šæ›´æ–°æˆåŠŸ")
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-å…¥åº“å¤±è´¥ï¼Œé”™è¯¯: {str(e)}")

            re = json.dumps({
                "result": final_report,
                "code": 0,
                "interview_id": int(interview_id),
            }, ensure_ascii=False)

            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šæˆåŠŸï¼Œæ€»è€—æ—¶{time.time()-zero_time}sï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")

        except Exception as e:
            logging.error(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼Œé”™è¯¯ï¼š{e}")
            re= json.dumps({
                "result": None,
                "code": 1,
                "interview_id": int(interview_id),
                "error": str(e)
            },ensure_ascii=False)
            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼ï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")
            return None

```

```python
import json
import logging
import time
import os
from datetime import datetime
from typing import Dict, List, Any
import requests
from openai import OpenAI
from app.config import url_config
from app.database import get_session
from models import SimulateReport
from service.multimodal_report import style_report
from app.config import ai_config
from sqlmodel import update
qwen_api_key = ai_config['api_key']

config = url_config
post_url = config['interview_report_post_url']
qwen_api_uri = ai_config['api_uri']
model_name = ai_config['api_model']


class AIInterviewAssessor:
    def __init__(self):
        self.llm_client = OpenAI(
            api_key=qwen_api_key,
            base_url=qwen_api_uri,
        )
        self.language_dict={
            'zhongwen': ('ä¸­æ–‡', 'ä½ å¥½ï¼Œé¢è¯•å®˜ï¼è®©æˆ‘ä»¬ç”¨ä¸­æ–‡äº¤æµï¼', 'longxiaochun_v2'),
            'yingwen': ('è‹±æ–‡', "Hello, interviewer!Let's communicate in English!", 'longxiaochun_v2'),
            'riyu': ('æ—¥è¯­', 'ã“ã‚“ã«ã¡ã¯ã€é¢æ¥å®˜ï¼æ—¥æœ¬èªã§è©±ã—åˆã„ã¾ã—ã‚‡ã†ï¼', 'loongtomoka_v2'),
            'hanyu': ('éŸ©è¯­', 'ì•ˆë…•í•˜ì„¸ìš”, ë©´ì ‘ê´€ë‹˜!í•œêµ­ì–´ë¡œ ëŒ€í™”í•´ìš”!', 'loongkyong_v2'),
            'xibanyayu': ('è¥¿ç­ç‰™è¯­', 'Â¡Hola, entrevistador!Â¡Hablemos en espaÃ±ol!', 'sambert-camila-v1'),
            'yinniyu': ('å°å°¼è¯­', 'Halo, pewawancara!Ayo berkomunikasi dalam bahasa Indonesia!', 'sambert-indah-v1'),
            'fayu': ('æ³•è¯­', 'Bonjour, intervieweur !Parlons en franÃ§ais !', 'sambert-clara-v1'),
            'deyu': ('å¾·è¯­', 'Hallo, Interviewer!Lass uns auf Deutsch sprechen!', 'sambert-hanna-v1'),
            'taiyu': ('æ³°è¯­', 'à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¹ˆà¸°/à¸„à¸£à¸±à¸š, à¸œà¸¹à¹‰à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œ!à¸¡à¸²à¸à¸¹à¸”à¸„à¸¸à¸¢à¸à¸±à¸™à¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¸à¸±à¸™à¹€à¸–à¸­à¸°!', 'sambert-waan-v1')
        }
        self.interview_language='ä¸­æ–‡'
        
        self._load_prompts()

    def _load_prompts(self):
        base_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
        prompts_dir = os.path.join(base_dir, 'prompts', 'evaluation_report')
        
        with open(os.path.join(prompts_dir, 'extract_competencies.txt'), 'r', encoding='utf-8') as f:
            self.prompt_extract_competencies = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_single_competency.txt'), 'r', encoding='utf-8') as f:
            self.prompt_analyze_single_competency = f.read()
        
        with open(os.path.join(prompts_dir, 'generate_final_summary.txt'), 'r', encoding='utf-8') as f:
            self.prompt_generate_final_summary = f.read()
        
        with open(os.path.join(prompts_dir, 'user_report.txt'), 'r', encoding='utf-8') as f:
            self.prompt_user_report = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_job_match_and_career.txt'), 'r', encoding='utf-8') as f:
            self.prompt_job_match_and_career = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_personality.txt'), 'r', encoding='utf-8') as f:
            self.prompt_personality = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_salary_market.txt'), 'r', encoding='utf-8') as f:
            self.prompt_salary_market = f.read()

    def _call_llm(self, prompt: str, system_message: str, enable_search: bool = False) -> str | None:

        params = {
            "seed": 6,
            "model": model_name,
            "temperature": 0.3,
            "response_format": {"type": "json_object"},
            "messages": [{"role": "system", "content": system_message},
                        {"role": "user", "content": prompt}]
        }
        
        # è”ç½‘æœç´¢åŠŸèƒ½æš‚æ—¶ç¦ç”¨ï¼ˆAPIæ ¼å¼é—®é¢˜ï¼‰
        # if enable_search:
        #     params["tools"] = [{"type": "web_search"}]
        
        try:
            response = self.llm_client.chat.completions.create(**params)
            content_text = response.choices[0].message.content
            return content_text
        except Exception as e:
            logging.error(f"ï¼ï¼ï¼LLMè°ƒç”¨å¤±è´¥ï¼š{e}")
            return None

    def _extract_competencies(self, jd: str,transcript_text:str) -> Dict[str, List[str]]:
        system_message = self.prompt_extract_competencies.format(interview_language=self.interview_language)

        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """

        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_single_competency(self, competency: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_analyze_single_competency.format(
            competency=competency,
            interview_language=self.interview_language
        )
        prompt = f"""
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _generate_final_summary(self, detailed_analysis_str: str) -> Dict[str, Any]:
        system_message = self.prompt_generate_final_summary.format(interview_language=self.interview_language)

        prompt = f"""
        --- èƒ½åŠ›åˆ†ææ•°æ® ---
        {detailed_analysis_str}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_job_match_and_career(self, detailed_analysis_str: str, jd: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_job_match_and_career.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_personality(self, jd: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_personality.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_salary_market(self, jd: str, transcript_text: str, detailed_analysis_str: str) -> Dict[str, Any]:
        system_message = self.prompt_salary_market.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        """
        
        response_str = self._call_llm(prompt, system_message, enable_search=False)
        if not response_str:
            return {}
        
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(f"è–ªé…¬åˆ†æJSONè§£æå¤±è´¥: {e}")
            return {}

    def _user_report(self, jd: str, transcript_text: str, hr_report, personality, salary) -> dict[str, Any]:
        """
        å€™é€‰äººé¢è¯•å¤ç›˜ï¼Œå€™é€‰äººä¸“ç”¨é¢è¯•æŠ¥å‘Š
        """
        system_message = self.prompt_user_report.format(interview_language=self.interview_language)
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        
        --- é¢è¯•å®˜çš„è¯„ä»· ---
        {hr_report}
        
        --- æ€§æ ¼åˆ†æ ---
        {json.dumps(personality, ensure_ascii=False)}
        
        --- è–ªé…¬åˆ†æ ---
        {json.dumps(salary, ensure_ascii=False)}
        
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _format_transcript(self, transcript_json: List[Dict]) -> str:
        lines = []
        for entry in transcript_json:
            role_cn = "é¢è¯•å®˜" if entry['role'] == 'interviewer' else "å€™é€‰äºº"
            lines.append(f"[å½“å‰å¯¹è¯è½®æ•°ï¼š{entry['timestamp']}] {role_cn}: {entry['content']}")
        return "\n".join(lines)

    def generate_report(self, transcript_json_str: str, jd: str,interview_id:str,url_list:list[str],is_mp4:bool,interview_language:str)   :
        try:
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- æ¥æ”¶åˆ°é¢è¯•è®°å½•ï¼Œå¼€å§‹åˆ†æ")
            zero_time = time.time()
            self.interview_language=self.language_dict[interview_language][0]
            transcript_data = json.loads(transcript_json_str)
            try:
                transcript_text = self._format_transcript(transcript_data)
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•æ–‡æœ¬è®°å½•è§£æå‡ºé”™ï¼Œ{e}ï¼Œå¼€å§‹ä½¿ç”¨æºæ•°æ®")
                transcript_text = transcript_data

            # 1. æå–èƒ½åŠ›æ¨¡å‹
            competencies = self._extract_competencies(jd,transcript_text)
            all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            if not all_competency_keys :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} -- è€ƒæ ¸ç»´åº¦æŠ½å–å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                competencies = self._extract_competencies(jd, transcript_text)
                all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è€ƒæ ¸ç»´åº¦æŠ½å–æˆåŠŸï¼š{competencies}")

            # 2. é€é¡¹è¯„ä¼°å„é¡¹èƒ½åŠ›
            detailed_analysis = []
            total_score = 0

            for competency in all_competency_keys:
                start_time=time.time()
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ­£åœ¨åˆ†æ '{competency}'...")
                analysis_result = self._analyze_single_competency(competency, transcript_text)
                if not analysis_result :
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†æç»´åº¦ï¼š{competency} å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    analysis_result = self._analyze_single_competency(competency, transcript_text)
                analysis_result['competency'] = competency
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†ææˆåŠŸï¼š{competency}ï¼Œè€—æ—¶{time.time()-start_time}s ")
                detailed_analysis.append(analysis_result)
                total_score += analysis_result.get('score', 0)

            detailed_analysis_str = json.dumps(detailed_analysis, indent=2, ensure_ascii=False)
            
            # 3. å²—ä½é€‚é…åº¦åˆ†æ + èŒä¸šå‘å±•è§„åˆ’
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æ...")
            job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            if not job_match:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æå®Œæˆ")
            
            # 4. æ€§æ ¼æ·±åº¦åˆ†æ
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹æ€§æ ¼æ·±åº¦åˆ†æ...")
            personality = self._analyze_personality(jd, transcript_text)
            if not personality:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                personality = self._analyze_personality(jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼æ·±åº¦åˆ†æå®Œæˆ")
            
            # 5. è–ªé…¬å¸‚åœºè¯„ä¼°
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹è–ªé…¬å¸‚åœºè¯„ä¼°...")
            try:
                salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
                    logging.warning(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬å¸‚åœºè¯„ä¼°å®Œæˆ")
            except Exception as e:
                logging.error(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¼‚å¸¸: {e}")
                salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
            
            # 6. ç”ŸæˆHRæ€»ç»“
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”ŸæˆHRæ€»ç»“...")
            final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ–‡æœ¬æŠ¥å‘Šæ€»ç»“å¤±è´¥ï¼Œå†æ¬¡å°è¯• - ")
                final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å†æ¬¡å°è¯•æ€»ç»“å¤±è´¥ï¼Œä¸»åŠ¨è¿”å›codeï¼š1 çŠ¶æ€ - ")
                a=1/0
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  HRæ€»ç»“ç”Ÿæˆå®Œæˆ")

            # 7. å¤šæ¨¡æ€åˆ†æ
            overall_score = round(total_score / len(all_competency_keys), 1) if all_competency_keys else -1
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å¤šæ¨¡æ€é£æ ¼åˆ†æ...")
            style=style_report(url_list=url_list,interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            if not style:
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€æŠ¥å‘Šè¯„ä¼°å‡ºé”™ï¼Œå¯åŠ¨ä¿åº•æœºåˆ¶...")
                style=style_report(url_list=[],interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€é£æ ¼åˆ†æå®Œæˆ")

            # 8. ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š
            hr_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
            }
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š...")
            user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            if not user_report:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šå·²ç”Ÿæˆ")

            # 9. èšåˆæœ€ç»ˆæŠ¥å‘Š
            final_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
                "competency_model_used": competencies,
                "job_match_analysis": job_match,
                "personality_analysis": personality,
                "salary_analysis": salary,
                "style_report": style,
                "user_report": user_report
            }

            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æœ€ç»ˆæŠ¥å‘Šå·²ç”Ÿæˆ...")

            content_json = json.dumps(final_report, ensure_ascii=False)
            try:
                with get_session() as session:
                    stmt = (
                        update(SimulateReport)
                        .where(SimulateReport.interview_id == interview_id)
                        .values(
                            content=content_json,
                            updated_at=datetime.now()
                        )
                    )

                    session.exec(stmt)
                    session.flush()
                    logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-é¢è¯•æŠ¥å‘Šæ›´æ–°æˆåŠŸ")
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-å…¥åº“å¤±è´¥ï¼Œé”™è¯¯: {str(e)}")

            re = json.dumps({
                "result": final_report,
                "code": 0,
                "interview_id": int(interview_id),
            }, ensure_ascii=False)

            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šæˆåŠŸï¼Œæ€»è€—æ—¶{time.time()-zero_time}sï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")

        except Exception as e:
            logging.error(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼Œé”™è¯¯ï¼š{e}")
            re= json.dumps({
                "result": None,
                "code": 1,
                "interview_id": int(interview_id),
                "error": str(e)
            },ensure_ascii=False)
            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼ï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")
            return None

```

```python
import json
import logging
import time
import os
from datetime import datetime
from typing import Dict, List, Any
import requests
from openai import OpenAI
from app.config import url_config
from app.database import get_session
from models import SimulateReport
from service.multimodal_report import style_report
from app.config import ai_config
from sqlmodel import update
qwen_api_key = ai_config['api_key']

config = url_config
post_url = config['interview_report_post_url']
qwen_api_uri = ai_config['api_uri']
model_name = ai_config['api_model']


class AIInterviewAssessor:
    def __init__(self):
        self.llm_client = OpenAI(
            api_key=qwen_api_key,
            base_url=qwen_api_uri,
        )
        self.language_dict={
            'zhongwen': ('ä¸­æ–‡', 'ä½ å¥½ï¼Œé¢è¯•å®˜ï¼è®©æˆ‘ä»¬ç”¨ä¸­æ–‡äº¤æµï¼', 'longxiaochun_v2'),
            'yingwen': ('è‹±æ–‡', "Hello, interviewer!Let's communicate in English!", 'longxiaochun_v2'),
            'riyu': ('æ—¥è¯­', 'ã“ã‚“ã«ã¡ã¯ã€é¢æ¥å®˜ï¼æ—¥æœ¬èªã§è©±ã—åˆã„ã¾ã—ã‚‡ã†ï¼', 'loongtomoka_v2'),
            'hanyu': ('éŸ©è¯­', 'ì•ˆë…•í•˜ì„¸ìš”, ë©´ì ‘ê´€ë‹˜!í•œêµ­ì–´ë¡œ ëŒ€í™”í•´ìš”!', 'loongkyong_v2'),
            'xibanyayu': ('è¥¿ç­ç‰™è¯­', 'Â¡Hola, entrevistador!Â¡Hablemos en espaÃ±ol!', 'sambert-camila-v1'),
            'yinniyu': ('å°å°¼è¯­', 'Halo, pewawancara!Ayo berkomunikasi dalam bahasa Indonesia!', 'sambert-indah-v1'),
            'fayu': ('æ³•è¯­', 'Bonjour, intervieweur !Parlons en franÃ§ais !', 'sambert-clara-v1'),
            'deyu': ('å¾·è¯­', 'Hallo, Interviewer!Lass uns auf Deutsch sprechen!', 'sambert-hanna-v1'),
            'taiyu': ('æ³°è¯­', 'à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¹ˆà¸°/à¸„à¸£à¸±à¸š, à¸œà¸¹à¹‰à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œ!à¸¡à¸²à¸à¸¹à¸”à¸„à¸¸à¸¢à¸à¸±à¸™à¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¸à¸±à¸™à¹€à¸–à¸­à¸°!', 'sambert-waan-v1')
        }
        self.interview_language='ä¸­æ–‡'
        
        self._load_prompts()

    def _load_prompts(self):
        base_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
        prompts_dir = os.path.join(base_dir, 'prompts', 'evaluation_report')
        
        with open(os.path.join(prompts_dir, 'extract_competencies.txt'), 'r', encoding='utf-8') as f:
            self.prompt_extract_competencies = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_single_competency.txt'), 'r', encoding='utf-8') as f:
            self.prompt_analyze_single_competency = f.read()
        
        with open(os.path.join(prompts_dir, 'generate_final_summary.txt'), 'r', encoding='utf-8') as f:
            self.prompt_generate_final_summary = f.read()
        
        with open(os.path.join(prompts_dir, 'user_report.txt'), 'r', encoding='utf-8') as f:
            self.prompt_user_report = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_job_match_and_career.txt'), 'r', encoding='utf-8') as f:
            self.prompt_job_match_and_career = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_personality.txt'), 'r', encoding='utf-8') as f:
            self.prompt_personality = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_salary_market.txt'), 'r', encoding='utf-8') as f:
            self.prompt_salary_market = f.read()

    def _call_llm(self, prompt: str, system_message: str, enable_search: bool = False) -> str | None:

        params = {
            "seed": 6,
            "model": model_name,
            "temperature": 0.3,
            "response_format": {"type": "json_object"},
            "messages": [{"role": "system", "content": system_message},
                        {"role": "user", "content": prompt}]
        }
        
        # è”ç½‘æœç´¢åŠŸèƒ½æš‚æ—¶ç¦ç”¨ï¼ˆAPIæ ¼å¼é—®é¢˜ï¼‰
        # if enable_search:
        #     params["tools"] = [{"type": "web_search"}]
        
        try:
            response = self.llm_client.chat.completions.create(**params)
            content_text = response.choices[0].message.content
            return content_text
        except Exception as e:
            logging.error(f"ï¼ï¼ï¼LLMè°ƒç”¨å¤±è´¥ï¼š{e}")
            return None

    def _extract_competencies(self, jd: str,transcript_text:str) -> Dict[str, List[str]]:
        system_message = self.prompt_extract_competencies.format(interview_language=self.interview_language)

        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """

        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_single_competency(self, competency: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_analyze_single_competency.format(
            competency=competency,
            interview_language=self.interview_language
        )
        prompt = f"""
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _generate_final_summary(self, detailed_analysis_str: str) -> Dict[str, Any]:
        system_message = self.prompt_generate_final_summary.format(interview_language=self.interview_language)

        prompt = f"""
        --- èƒ½åŠ›åˆ†ææ•°æ® ---
        {detailed_analysis_str}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_job_match_and_career(self, detailed_analysis_str: str, jd: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_job_match_and_career.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_personality(self, jd: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_personality.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_salary_market(self, jd: str, transcript_text: str, detailed_analysis_str: str) -> Dict[str, Any]:
        system_message = self.prompt_salary_market.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        """
        
        response_str = self._call_llm(prompt, system_message, enable_search=False)
        if not response_str:
            return {}
        
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(f"è–ªé…¬åˆ†æJSONè§£æå¤±è´¥: {e}")
            return {}

    def _user_report(self, jd: str, transcript_text: str, hr_report, personality, salary) -> dict[str, Any]:
        system_message = self.prompt_user_report.format(interview_language=self.interview_language)
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        
        --- é¢è¯•å®˜çš„è¯„ä»· ---
        {hr_report}
        
        --- æ€§æ ¼åˆ†æ ---
        {json.dumps(personality, ensure_ascii=False)}
        
        --- è–ªé…¬åˆ†æ ---
        {json.dumps(salary, ensure_ascii=False)}
        
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _format_transcript(self, transcript_json: List[Dict]) -> str:
        lines = []
        for entry in transcript_json:
            role_cn = "é¢è¯•å®˜" if entry['role'] == 'interviewer' else "å€™é€‰äºº"
            lines.append(f"[å½“å‰å¯¹è¯è½®æ•°ï¼š{entry['timestamp']}] {role_cn}: {entry['content']}")
        return "\n".join(lines)

    def generate_report(self, transcript_json_str: str, jd: str,interview_id:str,url_list:list[str],is_mp4:bool,interview_language:str)   :
        try:
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- æ¥æ”¶åˆ°é¢è¯•è®°å½•ï¼Œå¼€å§‹åˆ†æ")
            zero_time = time.time()
            self.interview_language=self.language_dict[interview_language][0]
            transcript_data = json.loads(transcript_json_str)
            try:
                transcript_text = self._format_transcript(transcript_data)
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•æ–‡æœ¬è®°å½•è§£æå‡ºé”™ï¼Œ{e}ï¼Œå¼€å§‹ä½¿ç”¨æºæ•°æ®")
                transcript_text = transcript_data

            # 1. æå–èƒ½åŠ›æ¨¡å‹
            competencies = self._extract_competencies(jd,transcript_text)
            all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            if not all_competency_keys :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} -- è€ƒæ ¸ç»´åº¦æŠ½å–å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                competencies = self._extract_competencies(jd, transcript_text)
                all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è€ƒæ ¸ç»´åº¦æŠ½å–æˆåŠŸï¼š{competencies}")

            # 2. é€é¡¹è¯„ä¼°å„é¡¹èƒ½åŠ›
            detailed_analysis = []
            total_score = 0

            for competency in all_competency_keys:
                start_time=time.time()
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ­£åœ¨åˆ†æ '{competency}'...")
                analysis_result = self._analyze_single_competency(competency, transcript_text)
                if not analysis_result :
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†æç»´åº¦ï¼š{competency} å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    analysis_result = self._analyze_single_competency(competency, transcript_text)
                analysis_result['competency'] = competency
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†ææˆåŠŸï¼š{competency}ï¼Œè€—æ—¶{time.time()-start_time}s ")
                detailed_analysis.append(analysis_result)
                total_score += analysis_result.get('score', 0)

            detailed_analysis_str = json.dumps(detailed_analysis, indent=2, ensure_ascii=False)
            
            # 3. å²—ä½é€‚é…åº¦åˆ†æ + èŒä¸šå‘å±•è§„åˆ’
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æ...")
            job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            if not job_match:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æå®Œæˆ")
            
            # 4. æ€§æ ¼æ·±åº¦åˆ†æ
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹æ€§æ ¼æ·±åº¦åˆ†æ...")
            personality = self._analyze_personality(jd, transcript_text)
            if not personality:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                personality = self._analyze_personality(jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼æ·±åº¦åˆ†æå®Œæˆ")
            
            # 5. è–ªé…¬å¸‚åœºè¯„ä¼°
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹è–ªé…¬å¸‚åœºè¯„ä¼°...")
            try:
                salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
                    logging.warning(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬å¸‚åœºè¯„ä¼°å®Œæˆ")
            except Exception as e:
                logging.error(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¼‚å¸¸: {e}")
                salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
            
            # 6. ç”ŸæˆHRæ€»ç»“
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”ŸæˆHRæ€»ç»“...")
            final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ–‡æœ¬æŠ¥å‘Šæ€»ç»“å¤±è´¥ï¼Œå†æ¬¡å°è¯• - ")
                final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å†æ¬¡å°è¯•æ€»ç»“å¤±è´¥ï¼Œä¸»åŠ¨è¿”å›codeï¼š1 çŠ¶æ€ - ")
                a=1/0
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  HRæ€»ç»“ç”Ÿæˆå®Œæˆ")

            # 7. å¤šæ¨¡æ€åˆ†æ
            overall_score = round(total_score / len(all_competency_keys), 1) if all_competency_keys else -1
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å¤šæ¨¡æ€é£æ ¼åˆ†æ...")
            style=style_report(url_list=url_list,interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            if not style:
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€æŠ¥å‘Šè¯„ä¼°å‡ºé”™ï¼Œå¯åŠ¨ä¿åº•æœºåˆ¶...")
                style=style_report(url_list=[],interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€é£æ ¼åˆ†æå®Œæˆ")

            # 8. ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š
            hr_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
            }
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š...")
            user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            if not user_report:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šå·²ç”Ÿæˆ")

            # 9. èšåˆæœ€ç»ˆæŠ¥å‘Š
            final_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
                "competency_model_used": competencies,
                "job_match_analysis": job_match,
                "personality_analysis": personality,
                "salary_analysis": salary,
                "style_report": style,
                "user_report": user_report
            }

            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æœ€ç»ˆæŠ¥å‘Šå·²ç”Ÿæˆ...")

            content_json = json.dumps(final_report, ensure_ascii=False)
            try:
                with get_session() as session:
                    stmt = (
                        update(SimulateReport)
                        .where(SimulateReport.interview_id == interview_id)
                        .values(
                            content=content_json,
                            updated_at=datetime.now()
                        )
                    )

                    session.exec(stmt)
                    session.flush()
                    logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-é¢è¯•æŠ¥å‘Šæ›´æ–°æˆåŠŸ")
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-å…¥åº“å¤±è´¥ï¼Œé”™è¯¯: {str(e)}")

            re = json.dumps({
                "result": final_report,
                "code": 0,
                "interview_id": int(interview_id),
            }, ensure_ascii=False)

            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šæˆåŠŸï¼Œæ€»è€—æ—¶{time.time()-zero_time}sï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")

        except Exception as e:
            logging.error(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼Œé”™è¯¯ï¼š{e}")
            re= json.dumps({
                "result": None,
                "code": 1,
                "interview_id": int(interview_id),
                "error": str(e)
            },ensure_ascii=False)
            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼ï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")
            return None

```

å·²ç§»é™¤æ‰€æœ‰ä¸­æ–‡ docstring å’Œä¸­æ–‡æ³¨é‡Šã€‚æ£€æŸ¥æ˜¯å¦è¿˜æœ‰é—æ¼ï¼š


æ£€æŸ¥å¹¶ç§»é™¤å‰©ä½™çš„ä¸­æ–‡æ³¨é‡Šï¼š


ç§»é™¤å‰©ä½™çš„ä¸­æ–‡æ³¨é‡Šï¼ˆåŒ…æ‹¬æ­¥éª¤ç¼–å·æ³¨é‡Šï¼‰ï¼š


```python
import json
import logging
import time
import os
from datetime import datetime
from typing import Dict, List, Any
import requests
from openai import OpenAI
from app.config import url_config
from app.database import get_session
from models import SimulateReport
from service.multimodal_report import style_report
from app.config import ai_config
from sqlmodel import update
qwen_api_key = ai_config['api_key']

config = url_config
post_url = config['interview_report_post_url']
qwen_api_uri = ai_config['api_uri']
model_name = ai_config['api_model']


class AIInterviewAssessor:
    def __init__(self):
        self.llm_client = OpenAI(
            api_key=qwen_api_key,
            base_url=qwen_api_uri,
        )
        self.language_dict={
            'zhongwen': ('ä¸­æ–‡', 'ä½ å¥½ï¼Œé¢è¯•å®˜ï¼è®©æˆ‘ä»¬ç”¨ä¸­æ–‡äº¤æµï¼', 'longxiaochun_v2'),
            'yingwen': ('è‹±æ–‡', "Hello, interviewer!Let's communicate in English!", 'longxiaochun_v2'),
            'riyu': ('æ—¥è¯­', 'ã“ã‚“ã«ã¡ã¯ã€é¢æ¥å®˜ï¼æ—¥æœ¬èªã§è©±ã—åˆã„ã¾ã—ã‚‡ã†ï¼', 'loongtomoka_v2'),
            'hanyu': ('éŸ©è¯­', 'ì•ˆë…•í•˜ì„¸ìš”, ë©´ì ‘ê´€ë‹˜!í•œêµ­ì–´ë¡œ ëŒ€í™”í•´ìš”!', 'loongkyong_v2'),
            'xibanyayu': ('è¥¿ç­ç‰™è¯­', 'Â¡Hola, entrevistador!Â¡Hablemos en espaÃ±ol!', 'sambert-camila-v1'),
            'yinniyu': ('å°å°¼è¯­', 'Halo, pewawancara!Ayo berkomunikasi dalam bahasa Indonesia!', 'sambert-indah-v1'),
            'fayu': ('æ³•è¯­', 'Bonjour, intervieweur !Parlons en franÃ§ais !', 'sambert-clara-v1'),
            'deyu': ('å¾·è¯­', 'Hallo, Interviewer!Lass uns auf Deutsch sprechen!', 'sambert-hanna-v1'),
            'taiyu': ('æ³°è¯­', 'à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¹ˆà¸°/à¸„à¸£à¸±à¸š, à¸œà¸¹à¹‰à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œ!à¸¡à¸²à¸à¸¹à¸”à¸„à¸¸à¸¢à¸à¸±à¸™à¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¸à¸±à¸™à¹€à¸–à¸­à¸°!', 'sambert-waan-v1')
        }
        self.interview_language='ä¸­æ–‡'
        
        self._load_prompts()

    def _load_prompts(self):
        base_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
        prompts_dir = os.path.join(base_dir, 'prompts', 'evaluation_report')
        
        with open(os.path.join(prompts_dir, 'extract_competencies.txt'), 'r', encoding='utf-8') as f:
            self.prompt_extract_competencies = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_single_competency.txt'), 'r', encoding='utf-8') as f:
            self.prompt_analyze_single_competency = f.read()
        
        with open(os.path.join(prompts_dir, 'generate_final_summary.txt'), 'r', encoding='utf-8') as f:
            self.prompt_generate_final_summary = f.read()
        
        with open(os.path.join(prompts_dir, 'user_report.txt'), 'r', encoding='utf-8') as f:
            self.prompt_user_report = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_job_match_and_career.txt'), 'r', encoding='utf-8') as f:
            self.prompt_job_match_and_career = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_personality.txt'), 'r', encoding='utf-8') as f:
            self.prompt_personality = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_salary_market.txt'), 'r', encoding='utf-8') as f:
            self.prompt_salary_market = f.read()

    def _call_llm(self, prompt: str, system_message: str, enable_search: bool = False) -> str | None:

        params = {
            "seed": 6,
            "model": model_name,
            "temperature": 0.3,
            "response_format": {"type": "json_object"},
            "messages": [{"role": "system", "content": system_message},
                        {"role": "user", "content": prompt}]
        }
        
        # if enable_search:
        #     params["tools"] = [{"type": "web_search"}]
        
        try:
            response = self.llm_client.chat.completions.create(**params)
            content_text = response.choices[0].message.content
            return content_text
        except Exception as e:
            logging.error(f"ï¼ï¼ï¼LLMè°ƒç”¨å¤±è´¥ï¼š{e}")
            return None

    def _extract_competencies(self, jd: str,transcript_text:str) -> Dict[str, List[str]]:
        system_message = self.prompt_extract_competencies.format(interview_language=self.interview_language)

        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """

        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_single_competency(self, competency: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_analyze_single_competency.format(
            competency=competency,
            interview_language=self.interview_language
        )
        prompt = f"""
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _generate_final_summary(self, detailed_analysis_str: str) -> Dict[str, Any]:
        system_message = self.prompt_generate_final_summary.format(interview_language=self.interview_language)

        prompt = f"""
        --- èƒ½åŠ›åˆ†ææ•°æ® ---
        {detailed_analysis_str}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_job_match_and_career(self, detailed_analysis_str: str, jd: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_job_match_and_career.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_personality(self, jd: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_personality.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_salary_market(self, jd: str, transcript_text: str, detailed_analysis_str: str) -> Dict[str, Any]:
        system_message = self.prompt_salary_market.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        """
        
        response_str = self._call_llm(prompt, system_message, enable_search=False)
        if not response_str:
            return {}
        
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(f"è–ªé…¬åˆ†æJSONè§£æå¤±è´¥: {e}")
            return {}

    def _user_report(self, jd: str, transcript_text: str, hr_report, personality, salary) -> dict[str, Any]:
        system_message = self.prompt_user_report.format(interview_language=self.interview_language)
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        
        --- é¢è¯•å®˜çš„è¯„ä»· ---
        {hr_report}
        
        --- æ€§æ ¼åˆ†æ ---
        {json.dumps(personality, ensure_ascii=False)}
        
        --- è–ªé…¬åˆ†æ ---
        {json.dumps(salary, ensure_ascii=False)}
        
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _format_transcript(self, transcript_json: List[Dict]) -> str:
        lines = []
        for entry in transcript_json:
            role_cn = "é¢è¯•å®˜" if entry['role'] == 'interviewer' else "å€™é€‰äºº"
            lines.append(f"[å½“å‰å¯¹è¯è½®æ•°ï¼š{entry['timestamp']}] {role_cn}: {entry['content']}")
        return "\n".join(lines)

    def generate_report(self, transcript_json_str: str, jd: str,interview_id:str,url_list:list[str],is_mp4:bool,interview_language:str)   :
        try:
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- æ¥æ”¶åˆ°é¢è¯•è®°å½•ï¼Œå¼€å§‹åˆ†æ")
            zero_time = time.time()
            self.interview_language=self.language_dict[interview_language][0]
            transcript_data = json.loads(transcript_json_str)
            try:
                transcript_text = self._format_transcript(transcript_data)
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•æ–‡æœ¬è®°å½•è§£æå‡ºé”™ï¼Œ{e}ï¼Œå¼€å§‹ä½¿ç”¨æºæ•°æ®")
                transcript_text = transcript_data

            # 1. æå–èƒ½åŠ›æ¨¡å‹
            competencies = self._extract_competencies(jd,transcript_text)
            all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            if not all_competency_keys :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} -- è€ƒæ ¸ç»´åº¦æŠ½å–å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                competencies = self._extract_competencies(jd, transcript_text)
                all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è€ƒæ ¸ç»´åº¦æŠ½å–æˆåŠŸï¼š{competencies}")

            # 2. é€é¡¹è¯„ä¼°å„é¡¹èƒ½åŠ›
            detailed_analysis = []
            total_score = 0

            for competency in all_competency_keys:
                start_time=time.time()
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ­£åœ¨åˆ†æ '{competency}'...")
                analysis_result = self._analyze_single_competency(competency, transcript_text)
                if not analysis_result :
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†æç»´åº¦ï¼š{competency} å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    analysis_result = self._analyze_single_competency(competency, transcript_text)
                analysis_result['competency'] = competency
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†ææˆåŠŸï¼š{competency}ï¼Œè€—æ—¶{time.time()-start_time}s ")
                detailed_analysis.append(analysis_result)
                total_score += analysis_result.get('score', 0)

            detailed_analysis_str = json.dumps(detailed_analysis, indent=2, ensure_ascii=False)
            
            # 3. å²—ä½é€‚é…åº¦åˆ†æ + èŒä¸šå‘å±•è§„åˆ’
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æ...")
            job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            if not job_match:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æå®Œæˆ")
            
            # 4. æ€§æ ¼æ·±åº¦åˆ†æ
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹æ€§æ ¼æ·±åº¦åˆ†æ...")
            personality = self._analyze_personality(jd, transcript_text)
            if not personality:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                personality = self._analyze_personality(jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼æ·±åº¦åˆ†æå®Œæˆ")
            
            # 5. è–ªé…¬å¸‚åœºè¯„ä¼°
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹è–ªé…¬å¸‚åœºè¯„ä¼°...")
            try:
                salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
                    logging.warning(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬å¸‚åœºè¯„ä¼°å®Œæˆ")
            except Exception as e:
                logging.error(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¼‚å¸¸: {e}")
                salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
            
            # 6. ç”ŸæˆHRæ€»ç»“
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”ŸæˆHRæ€»ç»“...")
            final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ–‡æœ¬æŠ¥å‘Šæ€»ç»“å¤±è´¥ï¼Œå†æ¬¡å°è¯• - ")
                final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å†æ¬¡å°è¯•æ€»ç»“å¤±è´¥ï¼Œä¸»åŠ¨è¿”å›codeï¼š1 çŠ¶æ€ - ")
                a=1/0
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  HRæ€»ç»“ç”Ÿæˆå®Œæˆ")

            # 7. å¤šæ¨¡æ€åˆ†æ
            overall_score = round(total_score / len(all_competency_keys), 1) if all_competency_keys else -1
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å¤šæ¨¡æ€é£æ ¼åˆ†æ...")
            style=style_report(url_list=url_list,interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            if not style:
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€æŠ¥å‘Šè¯„ä¼°å‡ºé”™ï¼Œå¯åŠ¨ä¿åº•æœºåˆ¶...")
                style=style_report(url_list=[],interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€é£æ ¼åˆ†æå®Œæˆ")

            # 8. ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š
            hr_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
            }
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š...")
            user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            if not user_report:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šå·²ç”Ÿæˆ")

            # 9. èšåˆæœ€ç»ˆæŠ¥å‘Š
            final_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
                "competency_model_used": competencies,
                "job_match_analysis": job_match,
                "personality_analysis": personality,
                "salary_analysis": salary,
                "style_report": style,
                "user_report": user_report
            }

            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æœ€ç»ˆæŠ¥å‘Šå·²ç”Ÿæˆ...")

            content_json = json.dumps(final_report, ensure_ascii=False)
            try:
                with get_session() as session:
                    stmt = (
                        update(SimulateReport)
                        .where(SimulateReport.interview_id == interview_id)
                        .values(
                            content=content_json,
                            updated_at=datetime.now()
                        )
                    )

                    session.exec(stmt)
                    session.flush()
                    logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-é¢è¯•æŠ¥å‘Šæ›´æ–°æˆåŠŸ")
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-å…¥åº“å¤±è´¥ï¼Œé”™è¯¯: {str(e)}")

            re = json.dumps({
                "result": final_report,
                "code": 0,
                "interview_id": int(interview_id),
            }, ensure_ascii=False)

            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šæˆåŠŸï¼Œæ€»è€—æ—¶{time.time()-zero_time}sï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")

        except Exception as e:
            logging.error(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼Œé”™è¯¯ï¼š{e}")
            re= json.dumps({
                "result": None,
                "code": 1,
                "interview_id": int(interview_id),
                "error": str(e)
            },ensure_ascii=False)
            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼ï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")
            return None

```

```python
import json
import logging
import time
import os
from datetime import datetime
from typing import Dict, List, Any
import requests
from openai import OpenAI
from app.config import url_config
from app.database import get_session
from models import SimulateReport
from service.multimodal_report import style_report
from app.config import ai_config
from sqlmodel import update
qwen_api_key = ai_config['api_key']

config = url_config
post_url = config['interview_report_post_url']
qwen_api_uri = ai_config['api_uri']
model_name = ai_config['api_model']


class AIInterviewAssessor:
    def __init__(self):
        self.llm_client = OpenAI(
            api_key=qwen_api_key,
            base_url=qwen_api_uri,
        )
        self.language_dict={
            'zhongwen': ('ä¸­æ–‡', 'ä½ å¥½ï¼Œé¢è¯•å®˜ï¼è®©æˆ‘ä»¬ç”¨ä¸­æ–‡äº¤æµï¼', 'longxiaochun_v2'),
            'yingwen': ('è‹±æ–‡', "Hello, interviewer!Let's communicate in English!", 'longxiaochun_v2'),
            'riyu': ('æ—¥è¯­', 'ã“ã‚“ã«ã¡ã¯ã€é¢æ¥å®˜ï¼æ—¥æœ¬èªã§è©±ã—åˆã„ã¾ã—ã‚‡ã†ï¼', 'loongtomoka_v2'),
            'hanyu': ('éŸ©è¯­', 'ì•ˆë…•í•˜ì„¸ìš”, ë©´ì ‘ê´€ë‹˜!í•œêµ­ì–´ë¡œ ëŒ€í™”í•´ìš”!', 'loongkyong_v2'),
            'xibanyayu': ('è¥¿ç­ç‰™è¯­', 'Â¡Hola, entrevistador!Â¡Hablemos en espaÃ±ol!', 'sambert-camila-v1'),
            'yinniyu': ('å°å°¼è¯­', 'Halo, pewawancara!Ayo berkomunikasi dalam bahasa Indonesia!', 'sambert-indah-v1'),
            'fayu': ('æ³•è¯­', 'Bonjour, intervieweur !Parlons en franÃ§ais !', 'sambert-clara-v1'),
            'deyu': ('å¾·è¯­', 'Hallo, Interviewer!Lass uns auf Deutsch sprechen!', 'sambert-hanna-v1'),
            'taiyu': ('æ³°è¯­', 'à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¹ˆà¸°/à¸„à¸£à¸±à¸š, à¸œà¸¹à¹‰à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œ!à¸¡à¸²à¸à¸¹à¸”à¸„à¸¸à¸¢à¸à¸±à¸™à¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¸à¸±à¸™à¹€à¸–à¸­à¸°!', 'sambert-waan-v1')
        }
        self.interview_language='ä¸­æ–‡'
        
        self._load_prompts()

    def _load_prompts(self):
        base_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
        prompts_dir = os.path.join(base_dir, 'prompts', 'evaluation_report')
        
        with open(os.path.join(prompts_dir, 'extract_competencies.txt'), 'r', encoding='utf-8') as f:
            self.prompt_extract_competencies = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_single_competency.txt'), 'r', encoding='utf-8') as f:
            self.prompt_analyze_single_competency = f.read()
        
        with open(os.path.join(prompts_dir, 'generate_final_summary.txt'), 'r', encoding='utf-8') as f:
            self.prompt_generate_final_summary = f.read()
        
        with open(os.path.join(prompts_dir, 'user_report.txt'), 'r', encoding='utf-8') as f:
            self.prompt_user_report = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_job_match_and_career.txt'), 'r', encoding='utf-8') as f:
            self.prompt_job_match_and_career = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_personality.txt'), 'r', encoding='utf-8') as f:
            self.prompt_personality = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_salary_market.txt'), 'r', encoding='utf-8') as f:
            self.prompt_salary_market = f.read()

    def _call_llm(self, prompt: str, system_message: str, enable_search: bool = False) -> str | None:

        params = {
            "seed": 6,
            "model": model_name,
            "temperature": 0.3,
            "response_format": {"type": "json_object"},
            "messages": [{"role": "system", "content": system_message},
                        {"role": "user", "content": prompt}]
        }
        
        # if enable_search:
        #     params["tools"] = [{"type": "web_search"}]
        
        try:
            response = self.llm_client.chat.completions.create(**params)
            content_text = response.choices[0].message.content
            return content_text
        except Exception as e:
            logging.error(f"ï¼ï¼ï¼LLMè°ƒç”¨å¤±è´¥ï¼š{e}")
            return None

    def _extract_competencies(self, jd: str,transcript_text:str) -> Dict[str, List[str]]:
        system_message = self.prompt_extract_competencies.format(interview_language=self.interview_language)

        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """

        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_single_competency(self, competency: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_analyze_single_competency.format(
            competency=competency,
            interview_language=self.interview_language
        )
        prompt = f"""
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _generate_final_summary(self, detailed_analysis_str: str) -> Dict[str, Any]:
        system_message = self.prompt_generate_final_summary.format(interview_language=self.interview_language)

        prompt = f"""
        --- èƒ½åŠ›åˆ†ææ•°æ® ---
        {detailed_analysis_str}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_job_match_and_career(self, detailed_analysis_str: str, jd: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_job_match_and_career.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_personality(self, jd: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_personality.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_salary_market(self, jd: str, transcript_text: str, detailed_analysis_str: str) -> Dict[str, Any]:
        system_message = self.prompt_salary_market.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        """
        
        response_str = self._call_llm(prompt, system_message, enable_search=False)
        if not response_str:
            return {}
        
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(f"è–ªé…¬åˆ†æJSONè§£æå¤±è´¥: {e}")
            return {}

    def _user_report(self, jd: str, transcript_text: str, hr_report, personality, salary) -> dict[str, Any]:
        system_message = self.prompt_user_report.format(interview_language=self.interview_language)
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        
        --- é¢è¯•å®˜çš„è¯„ä»· ---
        {hr_report}
        
        --- æ€§æ ¼åˆ†æ ---
        {json.dumps(personality, ensure_ascii=False)}
        
        --- è–ªé…¬åˆ†æ ---
        {json.dumps(salary, ensure_ascii=False)}
        
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _format_transcript(self, transcript_json: List[Dict]) -> str:
        lines = []
        for entry in transcript_json:
            role_cn = "é¢è¯•å®˜" if entry['role'] == 'interviewer' else "å€™é€‰äºº"
            lines.append(f"[å½“å‰å¯¹è¯è½®æ•°ï¼š{entry['timestamp']}] {role_cn}: {entry['content']}")
        return "\n".join(lines)

    def generate_report(self, transcript_json_str: str, jd: str,interview_id:str,url_list:list[str],is_mp4:bool,interview_language:str)   :
        try:
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- æ¥æ”¶åˆ°é¢è¯•è®°å½•ï¼Œå¼€å§‹åˆ†æ")
            zero_time = time.time()
            self.interview_language=self.language_dict[interview_language][0]
            transcript_data = json.loads(transcript_json_str)
            try:
                transcript_text = self._format_transcript(transcript_data)
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•æ–‡æœ¬è®°å½•è§£æå‡ºé”™ï¼Œ{e}ï¼Œå¼€å§‹ä½¿ç”¨æºæ•°æ®")
                transcript_text = transcript_data

            competencies = self._extract_competencies(jd,transcript_text)
            all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            if not all_competency_keys :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} -- è€ƒæ ¸ç»´åº¦æŠ½å–å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                competencies = self._extract_competencies(jd, transcript_text)
                all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è€ƒæ ¸ç»´åº¦æŠ½å–æˆåŠŸï¼š{competencies}")

            # 2. é€é¡¹è¯„ä¼°å„é¡¹èƒ½åŠ›
            detailed_analysis = []
            total_score = 0

            for competency in all_competency_keys:
                start_time=time.time()
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ­£åœ¨åˆ†æ '{competency}'...")
                analysis_result = self._analyze_single_competency(competency, transcript_text)
                if not analysis_result :
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†æç»´åº¦ï¼š{competency} å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    analysis_result = self._analyze_single_competency(competency, transcript_text)
                analysis_result['competency'] = competency
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†ææˆåŠŸï¼š{competency}ï¼Œè€—æ—¶{time.time()-start_time}s ")
                detailed_analysis.append(analysis_result)
                total_score += analysis_result.get('score', 0)

            detailed_analysis_str = json.dumps(detailed_analysis, indent=2, ensure_ascii=False)
            
            # 3. å²—ä½é€‚é…åº¦åˆ†æ + èŒä¸šå‘å±•è§„åˆ’
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æ...")
            job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            if not job_match:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æå®Œæˆ")
            
            # 4. æ€§æ ¼æ·±åº¦åˆ†æ
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹æ€§æ ¼æ·±åº¦åˆ†æ...")
            personality = self._analyze_personality(jd, transcript_text)
            if not personality:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                personality = self._analyze_personality(jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼æ·±åº¦åˆ†æå®Œæˆ")
            
            # 5. è–ªé…¬å¸‚åœºè¯„ä¼°
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹è–ªé…¬å¸‚åœºè¯„ä¼°...")
            try:
                salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
                    logging.warning(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬å¸‚åœºè¯„ä¼°å®Œæˆ")
            except Exception as e:
                logging.error(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¼‚å¸¸: {e}")
                salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
            
            # 6. ç”ŸæˆHRæ€»ç»“
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”ŸæˆHRæ€»ç»“...")
            final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ–‡æœ¬æŠ¥å‘Šæ€»ç»“å¤±è´¥ï¼Œå†æ¬¡å°è¯• - ")
                final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å†æ¬¡å°è¯•æ€»ç»“å¤±è´¥ï¼Œä¸»åŠ¨è¿”å›codeï¼š1 çŠ¶æ€ - ")
                a=1/0
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  HRæ€»ç»“ç”Ÿæˆå®Œæˆ")

            # 7. å¤šæ¨¡æ€åˆ†æ
            overall_score = round(total_score / len(all_competency_keys), 1) if all_competency_keys else -1
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å¤šæ¨¡æ€é£æ ¼åˆ†æ...")
            style=style_report(url_list=url_list,interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            if not style:
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€æŠ¥å‘Šè¯„ä¼°å‡ºé”™ï¼Œå¯åŠ¨ä¿åº•æœºåˆ¶...")
                style=style_report(url_list=[],interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€é£æ ¼åˆ†æå®Œæˆ")

            # 8. ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š
            hr_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
            }
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š...")
            user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            if not user_report:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šå·²ç”Ÿæˆ")

            # 9. èšåˆæœ€ç»ˆæŠ¥å‘Š
            final_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
                "competency_model_used": competencies,
                "job_match_analysis": job_match,
                "personality_analysis": personality,
                "salary_analysis": salary,
                "style_report": style,
                "user_report": user_report
            }

            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æœ€ç»ˆæŠ¥å‘Šå·²ç”Ÿæˆ...")

            content_json = json.dumps(final_report, ensure_ascii=False)
            try:
                with get_session() as session:
                    stmt = (
                        update(SimulateReport)
                        .where(SimulateReport.interview_id == interview_id)
                        .values(
                            content=content_json,
                            updated_at=datetime.now()
                        )
                    )

                    session.exec(stmt)
                    session.flush()
                    logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-é¢è¯•æŠ¥å‘Šæ›´æ–°æˆåŠŸ")
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-å…¥åº“å¤±è´¥ï¼Œé”™è¯¯: {str(e)}")

            re = json.dumps({
                "result": final_report,
                "code": 0,
                "interview_id": int(interview_id),
            }, ensure_ascii=False)

            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šæˆåŠŸï¼Œæ€»è€—æ—¶{time.time()-zero_time}sï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")

        except Exception as e:
            logging.error(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼Œé”™è¯¯ï¼š{e}")
            re= json.dumps({
                "result": None,
                "code": 1,
                "interview_id": int(interview_id),
                "error": str(e)
            },ensure_ascii=False)
            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼ï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")
            return None

```

```python
import json
import logging
import time
import os
from datetime import datetime
from typing import Dict, List, Any
import requests
from openai import OpenAI
from app.config import url_config
from app.database import get_session
from models import SimulateReport
from service.multimodal_report import style_report
from app.config import ai_config
from sqlmodel import update
qwen_api_key = ai_config['api_key']

config = url_config
post_url = config['interview_report_post_url']
qwen_api_uri = ai_config['api_uri']
model_name = ai_config['api_model']


class AIInterviewAssessor:
    def __init__(self):
        self.llm_client = OpenAI(
            api_key=qwen_api_key,
            base_url=qwen_api_uri,
        )
        self.language_dict={
            'zhongwen': ('ä¸­æ–‡', 'ä½ å¥½ï¼Œé¢è¯•å®˜ï¼è®©æˆ‘ä»¬ç”¨ä¸­æ–‡äº¤æµï¼', 'longxiaochun_v2'),
            'yingwen': ('è‹±æ–‡', "Hello, interviewer!Let's communicate in English!", 'longxiaochun_v2'),
            'riyu': ('æ—¥è¯­', 'ã“ã‚“ã«ã¡ã¯ã€é¢æ¥å®˜ï¼æ—¥æœ¬èªã§è©±ã—åˆã„ã¾ã—ã‚‡ã†ï¼', 'loongtomoka_v2'),
            'hanyu': ('éŸ©è¯­', 'ì•ˆë…•í•˜ì„¸ìš”, ë©´ì ‘ê´€ë‹˜!í•œêµ­ì–´ë¡œ ëŒ€í™”í•´ìš”!', 'loongkyong_v2'),
            'xibanyayu': ('è¥¿ç­ç‰™è¯­', 'Â¡Hola, entrevistador!Â¡Hablemos en espaÃ±ol!', 'sambert-camila-v1'),
            'yinniyu': ('å°å°¼è¯­', 'Halo, pewawancara!Ayo berkomunikasi dalam bahasa Indonesia!', 'sambert-indah-v1'),
            'fayu': ('æ³•è¯­', 'Bonjour, intervieweur !Parlons en franÃ§ais !', 'sambert-clara-v1'),
            'deyu': ('å¾·è¯­', 'Hallo, Interviewer!Lass uns auf Deutsch sprechen!', 'sambert-hanna-v1'),
            'taiyu': ('æ³°è¯­', 'à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¹ˆà¸°/à¸„à¸£à¸±à¸š, à¸œà¸¹à¹‰à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œ!à¸¡à¸²à¸à¸¹à¸”à¸„à¸¸à¸¢à¸à¸±à¸™à¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¸à¸±à¸™à¹€à¸–à¸­à¸°!', 'sambert-waan-v1')
        }
        self.interview_language='ä¸­æ–‡'
        
        self._load_prompts()

    def _load_prompts(self):
        base_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
        prompts_dir = os.path.join(base_dir, 'prompts', 'evaluation_report')
        
        with open(os.path.join(prompts_dir, 'extract_competencies.txt'), 'r', encoding='utf-8') as f:
            self.prompt_extract_competencies = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_single_competency.txt'), 'r', encoding='utf-8') as f:
            self.prompt_analyze_single_competency = f.read()
        
        with open(os.path.join(prompts_dir, 'generate_final_summary.txt'), 'r', encoding='utf-8') as f:
            self.prompt_generate_final_summary = f.read()
        
        with open(os.path.join(prompts_dir, 'user_report.txt'), 'r', encoding='utf-8') as f:
            self.prompt_user_report = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_job_match_and_career.txt'), 'r', encoding='utf-8') as f:
            self.prompt_job_match_and_career = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_personality.txt'), 'r', encoding='utf-8') as f:
            self.prompt_personality = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_salary_market.txt'), 'r', encoding='utf-8') as f:
            self.prompt_salary_market = f.read()

    def _call_llm(self, prompt: str, system_message: str, enable_search: bool = False) -> str | None:

        params = {
            "seed": 6,
            "model": model_name,
            "temperature": 0.3,
            "response_format": {"type": "json_object"},
            "messages": [{"role": "system", "content": system_message},
                        {"role": "user", "content": prompt}]
        }
        
        # if enable_search:
        #     params["tools"] = [{"type": "web_search"}]
        
        try:
            response = self.llm_client.chat.completions.create(**params)
            content_text = response.choices[0].message.content
            return content_text
        except Exception as e:
            logging.error(f"ï¼ï¼ï¼LLMè°ƒç”¨å¤±è´¥ï¼š{e}")
            return None

    def _extract_competencies(self, jd: str,transcript_text:str) -> Dict[str, List[str]]:
        system_message = self.prompt_extract_competencies.format(interview_language=self.interview_language)

        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """

        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_single_competency(self, competency: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_analyze_single_competency.format(
            competency=competency,
            interview_language=self.interview_language
        )
        prompt = f"""
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _generate_final_summary(self, detailed_analysis_str: str) -> Dict[str, Any]:
        system_message = self.prompt_generate_final_summary.format(interview_language=self.interview_language)

        prompt = f"""
        --- èƒ½åŠ›åˆ†ææ•°æ® ---
        {detailed_analysis_str}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_job_match_and_career(self, detailed_analysis_str: str, jd: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_job_match_and_career.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_personality(self, jd: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_personality.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_salary_market(self, jd: str, transcript_text: str, detailed_analysis_str: str) -> Dict[str, Any]:
        system_message = self.prompt_salary_market.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        """
        
        response_str = self._call_llm(prompt, system_message, enable_search=False)
        if not response_str:
            return {}
        
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(f"è–ªé…¬åˆ†æJSONè§£æå¤±è´¥: {e}")
            return {}

    def _user_report(self, jd: str, transcript_text: str, hr_report, personality, salary) -> dict[str, Any]:
        system_message = self.prompt_user_report.format(interview_language=self.interview_language)
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        
        --- é¢è¯•å®˜çš„è¯„ä»· ---
        {hr_report}
        
        --- æ€§æ ¼åˆ†æ ---
        {json.dumps(personality, ensure_ascii=False)}
        
        --- è–ªé…¬åˆ†æ ---
        {json.dumps(salary, ensure_ascii=False)}
        
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _format_transcript(self, transcript_json: List[Dict]) -> str:
        lines = []
        for entry in transcript_json:
            role_cn = "é¢è¯•å®˜" if entry['role'] == 'interviewer' else "å€™é€‰äºº"
            lines.append(f"[å½“å‰å¯¹è¯è½®æ•°ï¼š{entry['timestamp']}] {role_cn}: {entry['content']}")
        return "\n".join(lines)

    def generate_report(self, transcript_json_str: str, jd: str,interview_id:str,url_list:list[str],is_mp4:bool,interview_language:str)   :
        try:
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- æ¥æ”¶åˆ°é¢è¯•è®°å½•ï¼Œå¼€å§‹åˆ†æ")
            zero_time = time.time()
            self.interview_language=self.language_dict[interview_language][0]
            transcript_data = json.loads(transcript_json_str)
            try:
                transcript_text = self._format_transcript(transcript_data)
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•æ–‡æœ¬è®°å½•è§£æå‡ºé”™ï¼Œ{e}ï¼Œå¼€å§‹ä½¿ç”¨æºæ•°æ®")
                transcript_text = transcript_data

            competencies = self._extract_competencies(jd,transcript_text)
            all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            if not all_competency_keys :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} -- è€ƒæ ¸ç»´åº¦æŠ½å–å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                competencies = self._extract_competencies(jd, transcript_text)
                all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è€ƒæ ¸ç»´åº¦æŠ½å–æˆåŠŸï¼š{competencies}")

            detailed_analysis = []
            total_score = 0

            for competency in all_competency_keys:
                start_time=time.time()
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ­£åœ¨åˆ†æ '{competency}'...")
                analysis_result = self._analyze_single_competency(competency, transcript_text)
                if not analysis_result :
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†æç»´åº¦ï¼š{competency} å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    analysis_result = self._analyze_single_competency(competency, transcript_text)
                analysis_result['competency'] = competency
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†ææˆåŠŸï¼š{competency}ï¼Œè€—æ—¶{time.time()-start_time}s ")
                detailed_analysis.append(analysis_result)
                total_score += analysis_result.get('score', 0)

            detailed_analysis_str = json.dumps(detailed_analysis, indent=2, ensure_ascii=False)
            
            # 3. å²—ä½é€‚é…åº¦åˆ†æ + èŒä¸šå‘å±•è§„åˆ’
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æ...")
            job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            if not job_match:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æå®Œæˆ")
            
            # 4. æ€§æ ¼æ·±åº¦åˆ†æ
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹æ€§æ ¼æ·±åº¦åˆ†æ...")
            personality = self._analyze_personality(jd, transcript_text)
            if not personality:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                personality = self._analyze_personality(jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼æ·±åº¦åˆ†æå®Œæˆ")
            
            # 5. è–ªé…¬å¸‚åœºè¯„ä¼°
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹è–ªé…¬å¸‚åœºè¯„ä¼°...")
            try:
                salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
                    logging.warning(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬å¸‚åœºè¯„ä¼°å®Œæˆ")
            except Exception as e:
                logging.error(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¼‚å¸¸: {e}")
                salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
            
            # 6. ç”ŸæˆHRæ€»ç»“
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”ŸæˆHRæ€»ç»“...")
            final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ–‡æœ¬æŠ¥å‘Šæ€»ç»“å¤±è´¥ï¼Œå†æ¬¡å°è¯• - ")
                final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å†æ¬¡å°è¯•æ€»ç»“å¤±è´¥ï¼Œä¸»åŠ¨è¿”å›codeï¼š1 çŠ¶æ€ - ")
                a=1/0
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  HRæ€»ç»“ç”Ÿæˆå®Œæˆ")

            # 7. å¤šæ¨¡æ€åˆ†æ
            overall_score = round(total_score / len(all_competency_keys), 1) if all_competency_keys else -1
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å¤šæ¨¡æ€é£æ ¼åˆ†æ...")
            style=style_report(url_list=url_list,interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            if not style:
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€æŠ¥å‘Šè¯„ä¼°å‡ºé”™ï¼Œå¯åŠ¨ä¿åº•æœºåˆ¶...")
                style=style_report(url_list=[],interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€é£æ ¼åˆ†æå®Œæˆ")

            # 8. ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š
            hr_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
            }
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š...")
            user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            if not user_report:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šå·²ç”Ÿæˆ")

            # 9. èšåˆæœ€ç»ˆæŠ¥å‘Š
            final_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
                "competency_model_used": competencies,
                "job_match_analysis": job_match,
                "personality_analysis": personality,
                "salary_analysis": salary,
                "style_report": style,
                "user_report": user_report
            }

            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æœ€ç»ˆæŠ¥å‘Šå·²ç”Ÿæˆ...")

            content_json = json.dumps(final_report, ensure_ascii=False)
            try:
                with get_session() as session:
                    stmt = (
                        update(SimulateReport)
                        .where(SimulateReport.interview_id == interview_id)
                        .values(
                            content=content_json,
                            updated_at=datetime.now()
                        )
                    )

                    session.exec(stmt)
                    session.flush()
                    logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-é¢è¯•æŠ¥å‘Šæ›´æ–°æˆåŠŸ")
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-å…¥åº“å¤±è´¥ï¼Œé”™è¯¯: {str(e)}")

            re = json.dumps({
                "result": final_report,
                "code": 0,
                "interview_id": int(interview_id),
            }, ensure_ascii=False)

            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šæˆåŠŸï¼Œæ€»è€—æ—¶{time.time()-zero_time}sï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")

        except Exception as e:
            logging.error(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼Œé”™è¯¯ï¼š{e}")
            re= json.dumps({
                "result": None,
                "code": 1,
                "interview_id": int(interview_id),
                "error": str(e)
            },ensure_ascii=False)
            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼ï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")
            return None

```

```python
import json
import logging
import time
import os
from datetime import datetime
from typing import Dict, List, Any
import requests
from openai import OpenAI
from app.config import url_config
from app.database import get_session
from models import SimulateReport
from service.multimodal_report import style_report
from app.config import ai_config
from sqlmodel import update
qwen_api_key = ai_config['api_key']

config = url_config
post_url = config['interview_report_post_url']
qwen_api_uri = ai_config['api_uri']
model_name = ai_config['api_model']


class AIInterviewAssessor:
    def __init__(self):
        self.llm_client = OpenAI(
            api_key=qwen_api_key,
            base_url=qwen_api_uri,
        )
        self.language_dict={
            'zhongwen': ('ä¸­æ–‡', 'ä½ å¥½ï¼Œé¢è¯•å®˜ï¼è®©æˆ‘ä»¬ç”¨ä¸­æ–‡äº¤æµï¼', 'longxiaochun_v2'),
            'yingwen': ('è‹±æ–‡', "Hello, interviewer!Let's communicate in English!", 'longxiaochun_v2'),
            'riyu': ('æ—¥è¯­', 'ã“ã‚“ã«ã¡ã¯ã€é¢æ¥å®˜ï¼æ—¥æœ¬èªã§è©±ã—åˆã„ã¾ã—ã‚‡ã†ï¼', 'loongtomoka_v2'),
            'hanyu': ('éŸ©è¯­', 'ì•ˆë…•í•˜ì„¸ìš”, ë©´ì ‘ê´€ë‹˜!í•œêµ­ì–´ë¡œ ëŒ€í™”í•´ìš”!', 'loongkyong_v2'),
            'xibanyayu': ('è¥¿ç­ç‰™è¯­', 'Â¡Hola, entrevistador!Â¡Hablemos en espaÃ±ol!', 'sambert-camila-v1'),
            'yinniyu': ('å°å°¼è¯­', 'Halo, pewawancara!Ayo berkomunikasi dalam bahasa Indonesia!', 'sambert-indah-v1'),
            'fayu': ('æ³•è¯­', 'Bonjour, intervieweur !Parlons en franÃ§ais !', 'sambert-clara-v1'),
            'deyu': ('å¾·è¯­', 'Hallo, Interviewer!Lass uns auf Deutsch sprechen!', 'sambert-hanna-v1'),
            'taiyu': ('æ³°è¯­', 'à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¹ˆà¸°/à¸„à¸£à¸±à¸š, à¸œà¸¹à¹‰à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œ!à¸¡à¸²à¸à¸¹à¸”à¸„à¸¸à¸¢à¸à¸±à¸™à¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¸à¸±à¸™à¹€à¸–à¸­à¸°!', 'sambert-waan-v1')
        }
        self.interview_language='ä¸­æ–‡'
        
        self._load_prompts()

    def _load_prompts(self):
        base_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
        prompts_dir = os.path.join(base_dir, 'prompts', 'evaluation_report')
        
        with open(os.path.join(prompts_dir, 'extract_competencies.txt'), 'r', encoding='utf-8') as f:
            self.prompt_extract_competencies = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_single_competency.txt'), 'r', encoding='utf-8') as f:
            self.prompt_analyze_single_competency = f.read()
        
        with open(os.path.join(prompts_dir, 'generate_final_summary.txt'), 'r', encoding='utf-8') as f:
            self.prompt_generate_final_summary = f.read()
        
        with open(os.path.join(prompts_dir, 'user_report.txt'), 'r', encoding='utf-8') as f:
            self.prompt_user_report = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_job_match_and_career.txt'), 'r', encoding='utf-8') as f:
            self.prompt_job_match_and_career = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_personality.txt'), 'r', encoding='utf-8') as f:
            self.prompt_personality = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_salary_market.txt'), 'r', encoding='utf-8') as f:
            self.prompt_salary_market = f.read()

    def _call_llm(self, prompt: str, system_message: str, enable_search: bool = False) -> str | None:

        params = {
            "seed": 6,
            "model": model_name,
            "temperature": 0.3,
            "response_format": {"type": "json_object"},
            "messages": [{"role": "system", "content": system_message},
                        {"role": "user", "content": prompt}]
        }
        
        # if enable_search:
        #     params["tools"] = [{"type": "web_search"}]
        
        try:
            response = self.llm_client.chat.completions.create(**params)
            content_text = response.choices[0].message.content
            return content_text
        except Exception as e:
            logging.error(f"ï¼ï¼ï¼LLMè°ƒç”¨å¤±è´¥ï¼š{e}")
            return None

    def _extract_competencies(self, jd: str,transcript_text:str) -> Dict[str, List[str]]:
        system_message = self.prompt_extract_competencies.format(interview_language=self.interview_language)

        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """

        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_single_competency(self, competency: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_analyze_single_competency.format(
            competency=competency,
            interview_language=self.interview_language
        )
        prompt = f"""
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _generate_final_summary(self, detailed_analysis_str: str) -> Dict[str, Any]:
        system_message = self.prompt_generate_final_summary.format(interview_language=self.interview_language)

        prompt = f"""
        --- èƒ½åŠ›åˆ†ææ•°æ® ---
        {detailed_analysis_str}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_job_match_and_career(self, detailed_analysis_str: str, jd: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_job_match_and_career.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_personality(self, jd: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_personality.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_salary_market(self, jd: str, transcript_text: str, detailed_analysis_str: str) -> Dict[str, Any]:
        system_message = self.prompt_salary_market.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        """
        
        response_str = self._call_llm(prompt, system_message, enable_search=False)
        if not response_str:
            return {}
        
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(f"è–ªé…¬åˆ†æJSONè§£æå¤±è´¥: {e}")
            return {}

    def _user_report(self, jd: str, transcript_text: str, hr_report, personality, salary) -> dict[str, Any]:
        system_message = self.prompt_user_report.format(interview_language=self.interview_language)
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        
        --- é¢è¯•å®˜çš„è¯„ä»· ---
        {hr_report}
        
        --- æ€§æ ¼åˆ†æ ---
        {json.dumps(personality, ensure_ascii=False)}
        
        --- è–ªé…¬åˆ†æ ---
        {json.dumps(salary, ensure_ascii=False)}
        
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _format_transcript(self, transcript_json: List[Dict]) -> str:
        lines = []
        for entry in transcript_json:
            role_cn = "é¢è¯•å®˜" if entry['role'] == 'interviewer' else "å€™é€‰äºº"
            lines.append(f"[å½“å‰å¯¹è¯è½®æ•°ï¼š{entry['timestamp']}] {role_cn}: {entry['content']}")
        return "\n".join(lines)

    def generate_report(self, transcript_json_str: str, jd: str,interview_id:str,url_list:list[str],is_mp4:bool,interview_language:str)   :
        try:
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- æ¥æ”¶åˆ°é¢è¯•è®°å½•ï¼Œå¼€å§‹åˆ†æ")
            zero_time = time.time()
            self.interview_language=self.language_dict[interview_language][0]
            transcript_data = json.loads(transcript_json_str)
            try:
                transcript_text = self._format_transcript(transcript_data)
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•æ–‡æœ¬è®°å½•è§£æå‡ºé”™ï¼Œ{e}ï¼Œå¼€å§‹ä½¿ç”¨æºæ•°æ®")
                transcript_text = transcript_data

            competencies = self._extract_competencies(jd,transcript_text)
            all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            if not all_competency_keys :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} -- è€ƒæ ¸ç»´åº¦æŠ½å–å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                competencies = self._extract_competencies(jd, transcript_text)
                all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è€ƒæ ¸ç»´åº¦æŠ½å–æˆåŠŸï¼š{competencies}")

            detailed_analysis = []
            total_score = 0

            for competency in all_competency_keys:
                start_time=time.time()
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ­£åœ¨åˆ†æ '{competency}'...")
                analysis_result = self._analyze_single_competency(competency, transcript_text)
                if not analysis_result :
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†æç»´åº¦ï¼š{competency} å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    analysis_result = self._analyze_single_competency(competency, transcript_text)
                analysis_result['competency'] = competency
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†ææˆåŠŸï¼š{competency}ï¼Œè€—æ—¶{time.time()-start_time}s ")
                detailed_analysis.append(analysis_result)
                total_score += analysis_result.get('score', 0)

            detailed_analysis_str = json.dumps(detailed_analysis, indent=2, ensure_ascii=False)
            
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æ...")
            job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            if not job_match:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æå®Œæˆ")
            
            # 4. æ€§æ ¼æ·±åº¦åˆ†æ
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹æ€§æ ¼æ·±åº¦åˆ†æ...")
            personality = self._analyze_personality(jd, transcript_text)
            if not personality:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                personality = self._analyze_personality(jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼æ·±åº¦åˆ†æå®Œæˆ")
            
            # 5. è–ªé…¬å¸‚åœºè¯„ä¼°
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹è–ªé…¬å¸‚åœºè¯„ä¼°...")
            try:
                salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
                    logging.warning(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬å¸‚åœºè¯„ä¼°å®Œæˆ")
            except Exception as e:
                logging.error(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¼‚å¸¸: {e}")
                salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
            
            # 6. ç”ŸæˆHRæ€»ç»“
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”ŸæˆHRæ€»ç»“...")
            final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ–‡æœ¬æŠ¥å‘Šæ€»ç»“å¤±è´¥ï¼Œå†æ¬¡å°è¯• - ")
                final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å†æ¬¡å°è¯•æ€»ç»“å¤±è´¥ï¼Œä¸»åŠ¨è¿”å›codeï¼š1 çŠ¶æ€ - ")
                a=1/0
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  HRæ€»ç»“ç”Ÿæˆå®Œæˆ")

            # 7. å¤šæ¨¡æ€åˆ†æ
            overall_score = round(total_score / len(all_competency_keys), 1) if all_competency_keys else -1
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å¤šæ¨¡æ€é£æ ¼åˆ†æ...")
            style=style_report(url_list=url_list,interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            if not style:
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€æŠ¥å‘Šè¯„ä¼°å‡ºé”™ï¼Œå¯åŠ¨ä¿åº•æœºåˆ¶...")
                style=style_report(url_list=[],interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€é£æ ¼åˆ†æå®Œæˆ")

            # 8. ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š
            hr_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
            }
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š...")
            user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            if not user_report:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šå·²ç”Ÿæˆ")

            # 9. èšåˆæœ€ç»ˆæŠ¥å‘Š
            final_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
                "competency_model_used": competencies,
                "job_match_analysis": job_match,
                "personality_analysis": personality,
                "salary_analysis": salary,
                "style_report": style,
                "user_report": user_report
            }

            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æœ€ç»ˆæŠ¥å‘Šå·²ç”Ÿæˆ...")

            content_json = json.dumps(final_report, ensure_ascii=False)
            try:
                with get_session() as session:
                    stmt = (
                        update(SimulateReport)
                        .where(SimulateReport.interview_id == interview_id)
                        .values(
                            content=content_json,
                            updated_at=datetime.now()
                        )
                    )

                    session.exec(stmt)
                    session.flush()
                    logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-é¢è¯•æŠ¥å‘Šæ›´æ–°æˆåŠŸ")
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-å…¥åº“å¤±è´¥ï¼Œé”™è¯¯: {str(e)}")

            re = json.dumps({
                "result": final_report,
                "code": 0,
                "interview_id": int(interview_id),
            }, ensure_ascii=False)

            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šæˆåŠŸï¼Œæ€»è€—æ—¶{time.time()-zero_time}sï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")

        except Exception as e:
            logging.error(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼Œé”™è¯¯ï¼š{e}")
            re= json.dumps({
                "result": None,
                "code": 1,
                "interview_id": int(interview_id),
                "error": str(e)
            },ensure_ascii=False)
            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼ï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")
            return None

```

```python
import json
import logging
import time
import os
from datetime import datetime
from typing import Dict, List, Any
import requests
from openai import OpenAI
from app.config import url_config
from app.database import get_session
from models import SimulateReport
from service.multimodal_report import style_report
from app.config import ai_config
from sqlmodel import update
qwen_api_key = ai_config['api_key']

config = url_config
post_url = config['interview_report_post_url']
qwen_api_uri = ai_config['api_uri']
model_name = ai_config['api_model']


class AIInterviewAssessor:
    def __init__(self):
        self.llm_client = OpenAI(
            api_key=qwen_api_key,
            base_url=qwen_api_uri,
        )
        self.language_dict={
            'zhongwen': ('ä¸­æ–‡', 'ä½ å¥½ï¼Œé¢è¯•å®˜ï¼è®©æˆ‘ä»¬ç”¨ä¸­æ–‡äº¤æµï¼', 'longxiaochun_v2'),
            'yingwen': ('è‹±æ–‡', "Hello, interviewer!Let's communicate in English!", 'longxiaochun_v2'),
            'riyu': ('æ—¥è¯­', 'ã“ã‚“ã«ã¡ã¯ã€é¢æ¥å®˜ï¼æ—¥æœ¬èªã§è©±ã—åˆã„ã¾ã—ã‚‡ã†ï¼', 'loongtomoka_v2'),
            'hanyu': ('éŸ©è¯­', 'ì•ˆë…•í•˜ì„¸ìš”, ë©´ì ‘ê´€ë‹˜!í•œêµ­ì–´ë¡œ ëŒ€í™”í•´ìš”!', 'loongkyong_v2'),
            'xibanyayu': ('è¥¿ç­ç‰™è¯­', 'Â¡Hola, entrevistador!Â¡Hablemos en espaÃ±ol!', 'sambert-camila-v1'),
            'yinniyu': ('å°å°¼è¯­', 'Halo, pewawancara!Ayo berkomunikasi dalam bahasa Indonesia!', 'sambert-indah-v1'),
            'fayu': ('æ³•è¯­', 'Bonjour, intervieweur !Parlons en franÃ§ais !', 'sambert-clara-v1'),
            'deyu': ('å¾·è¯­', 'Hallo, Interviewer!Lass uns auf Deutsch sprechen!', 'sambert-hanna-v1'),
            'taiyu': ('æ³°è¯­', 'à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¹ˆà¸°/à¸„à¸£à¸±à¸š, à¸œà¸¹à¹‰à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œ!à¸¡à¸²à¸à¸¹à¸”à¸„à¸¸à¸¢à¸à¸±à¸™à¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¸à¸±à¸™à¹€à¸–à¸­à¸°!', 'sambert-waan-v1')
        }
        self.interview_language='ä¸­æ–‡'
        
        self._load_prompts()

    def _load_prompts(self):
        base_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
        prompts_dir = os.path.join(base_dir, 'prompts', 'evaluation_report')
        
        with open(os.path.join(prompts_dir, 'extract_competencies.txt'), 'r', encoding='utf-8') as f:
            self.prompt_extract_competencies = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_single_competency.txt'), 'r', encoding='utf-8') as f:
            self.prompt_analyze_single_competency = f.read()
        
        with open(os.path.join(prompts_dir, 'generate_final_summary.txt'), 'r', encoding='utf-8') as f:
            self.prompt_generate_final_summary = f.read()
        
        with open(os.path.join(prompts_dir, 'user_report.txt'), 'r', encoding='utf-8') as f:
            self.prompt_user_report = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_job_match_and_career.txt'), 'r', encoding='utf-8') as f:
            self.prompt_job_match_and_career = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_personality.txt'), 'r', encoding='utf-8') as f:
            self.prompt_personality = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_salary_market.txt'), 'r', encoding='utf-8') as f:
            self.prompt_salary_market = f.read()

    def _call_llm(self, prompt: str, system_message: str, enable_search: bool = False) -> str | None:

        params = {
            "seed": 6,
            "model": model_name,
            "temperature": 0.3,
            "response_format": {"type": "json_object"},
            "messages": [{"role": "system", "content": system_message},
                        {"role": "user", "content": prompt}]
        }
        
        # if enable_search:
        #     params["tools"] = [{"type": "web_search"}]
        
        try:
            response = self.llm_client.chat.completions.create(**params)
            content_text = response.choices[0].message.content
            return content_text
        except Exception as e:
            logging.error(f"ï¼ï¼ï¼LLMè°ƒç”¨å¤±è´¥ï¼š{e}")
            return None

    def _extract_competencies(self, jd: str,transcript_text:str) -> Dict[str, List[str]]:
        system_message = self.prompt_extract_competencies.format(interview_language=self.interview_language)

        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """

        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_single_competency(self, competency: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_analyze_single_competency.format(
            competency=competency,
            interview_language=self.interview_language
        )
        prompt = f"""
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _generate_final_summary(self, detailed_analysis_str: str) -> Dict[str, Any]:
        system_message = self.prompt_generate_final_summary.format(interview_language=self.interview_language)

        prompt = f"""
        --- èƒ½åŠ›åˆ†ææ•°æ® ---
        {detailed_analysis_str}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_job_match_and_career(self, detailed_analysis_str: str, jd: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_job_match_and_career.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_personality(self, jd: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_personality.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_salary_market(self, jd: str, transcript_text: str, detailed_analysis_str: str) -> Dict[str, Any]:
        system_message = self.prompt_salary_market.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        """
        
        response_str = self._call_llm(prompt, system_message, enable_search=False)
        if not response_str:
            return {}
        
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(f"è–ªé…¬åˆ†æJSONè§£æå¤±è´¥: {e}")
            return {}

    def _user_report(self, jd: str, transcript_text: str, hr_report, personality, salary) -> dict[str, Any]:
        system_message = self.prompt_user_report.format(interview_language=self.interview_language)
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        
        --- é¢è¯•å®˜çš„è¯„ä»· ---
        {hr_report}
        
        --- æ€§æ ¼åˆ†æ ---
        {json.dumps(personality, ensure_ascii=False)}
        
        --- è–ªé…¬åˆ†æ ---
        {json.dumps(salary, ensure_ascii=False)}
        
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _format_transcript(self, transcript_json: List[Dict]) -> str:
        lines = []
        for entry in transcript_json:
            role_cn = "é¢è¯•å®˜" if entry['role'] == 'interviewer' else "å€™é€‰äºº"
            lines.append(f"[å½“å‰å¯¹è¯è½®æ•°ï¼š{entry['timestamp']}] {role_cn}: {entry['content']}")
        return "\n".join(lines)

    def generate_report(self, transcript_json_str: str, jd: str,interview_id:str,url_list:list[str],is_mp4:bool,interview_language:str)   :
        try:
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- æ¥æ”¶åˆ°é¢è¯•è®°å½•ï¼Œå¼€å§‹åˆ†æ")
            zero_time = time.time()
            self.interview_language=self.language_dict[interview_language][0]
            transcript_data = json.loads(transcript_json_str)
            try:
                transcript_text = self._format_transcript(transcript_data)
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•æ–‡æœ¬è®°å½•è§£æå‡ºé”™ï¼Œ{e}ï¼Œå¼€å§‹ä½¿ç”¨æºæ•°æ®")
                transcript_text = transcript_data

            competencies = self._extract_competencies(jd,transcript_text)
            all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            if not all_competency_keys :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} -- è€ƒæ ¸ç»´åº¦æŠ½å–å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                competencies = self._extract_competencies(jd, transcript_text)
                all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è€ƒæ ¸ç»´åº¦æŠ½å–æˆåŠŸï¼š{competencies}")

            detailed_analysis = []
            total_score = 0

            for competency in all_competency_keys:
                start_time=time.time()
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ­£åœ¨åˆ†æ '{competency}'...")
                analysis_result = self._analyze_single_competency(competency, transcript_text)
                if not analysis_result :
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†æç»´åº¦ï¼š{competency} å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    analysis_result = self._analyze_single_competency(competency, transcript_text)
                analysis_result['competency'] = competency
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†ææˆåŠŸï¼š{competency}ï¼Œè€—æ—¶{time.time()-start_time}s ")
                detailed_analysis.append(analysis_result)
                total_score += analysis_result.get('score', 0)

            detailed_analysis_str = json.dumps(detailed_analysis, indent=2, ensure_ascii=False)
            
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æ...")
            job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            if not job_match:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æå®Œæˆ")
            
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹æ€§æ ¼æ·±åº¦åˆ†æ...")
            personality = self._analyze_personality(jd, transcript_text)
            if not personality:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                personality = self._analyze_personality(jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼æ·±åº¦åˆ†æå®Œæˆ")
            
            # 5. è–ªé…¬å¸‚åœºè¯„ä¼°
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹è–ªé…¬å¸‚åœºè¯„ä¼°...")
            try:
                salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
                    logging.warning(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬å¸‚åœºè¯„ä¼°å®Œæˆ")
            except Exception as e:
                logging.error(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¼‚å¸¸: {e}")
                salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
            
            # 6. ç”ŸæˆHRæ€»ç»“
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”ŸæˆHRæ€»ç»“...")
            final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ–‡æœ¬æŠ¥å‘Šæ€»ç»“å¤±è´¥ï¼Œå†æ¬¡å°è¯• - ")
                final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å†æ¬¡å°è¯•æ€»ç»“å¤±è´¥ï¼Œä¸»åŠ¨è¿”å›codeï¼š1 çŠ¶æ€ - ")
                a=1/0
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  HRæ€»ç»“ç”Ÿæˆå®Œæˆ")

            # 7. å¤šæ¨¡æ€åˆ†æ
            overall_score = round(total_score / len(all_competency_keys), 1) if all_competency_keys else -1
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å¤šæ¨¡æ€é£æ ¼åˆ†æ...")
            style=style_report(url_list=url_list,interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            if not style:
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€æŠ¥å‘Šè¯„ä¼°å‡ºé”™ï¼Œå¯åŠ¨ä¿åº•æœºåˆ¶...")
                style=style_report(url_list=[],interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€é£æ ¼åˆ†æå®Œæˆ")

            # 8. ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š
            hr_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
            }
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š...")
            user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            if not user_report:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šå·²ç”Ÿæˆ")

            # 9. èšåˆæœ€ç»ˆæŠ¥å‘Š
            final_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
                "competency_model_used": competencies,
                "job_match_analysis": job_match,
                "personality_analysis": personality,
                "salary_analysis": salary,
                "style_report": style,
                "user_report": user_report
            }

            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æœ€ç»ˆæŠ¥å‘Šå·²ç”Ÿæˆ...")

            content_json = json.dumps(final_report, ensure_ascii=False)
            try:
                with get_session() as session:
                    stmt = (
                        update(SimulateReport)
                        .where(SimulateReport.interview_id == interview_id)
                        .values(
                            content=content_json,
                            updated_at=datetime.now()
                        )
                    )

                    session.exec(stmt)
                    session.flush()
                    logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-é¢è¯•æŠ¥å‘Šæ›´æ–°æˆåŠŸ")
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-å…¥åº“å¤±è´¥ï¼Œé”™è¯¯: {str(e)}")

            re = json.dumps({
                "result": final_report,
                "code": 0,
                "interview_id": int(interview_id),
            }, ensure_ascii=False)

            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šæˆåŠŸï¼Œæ€»è€—æ—¶{time.time()-zero_time}sï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")

        except Exception as e:
            logging.error(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼Œé”™è¯¯ï¼š{e}")
            re= json.dumps({
                "result": None,
                "code": 1,
                "interview_id": int(interview_id),
                "error": str(e)
            },ensure_ascii=False)
            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼ï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")
            return None

```

```python
import json
import logging
import time
import os
from datetime import datetime
from typing import Dict, List, Any
import requests
from openai import OpenAI
from app.config import url_config
from app.database import get_session
from models import SimulateReport
from service.multimodal_report import style_report
from app.config import ai_config
from sqlmodel import update
qwen_api_key = ai_config['api_key']

config = url_config
post_url = config['interview_report_post_url']
qwen_api_uri = ai_config['api_uri']
model_name = ai_config['api_model']


class AIInterviewAssessor:
    def __init__(self):
        self.llm_client = OpenAI(
            api_key=qwen_api_key,
            base_url=qwen_api_uri,
        )
        self.language_dict={
            'zhongwen': ('ä¸­æ–‡', 'ä½ å¥½ï¼Œé¢è¯•å®˜ï¼è®©æˆ‘ä»¬ç”¨ä¸­æ–‡äº¤æµï¼', 'longxiaochun_v2'),
            'yingwen': ('è‹±æ–‡', "Hello, interviewer!Let's communicate in English!", 'longxiaochun_v2'),
            'riyu': ('æ—¥è¯­', 'ã“ã‚“ã«ã¡ã¯ã€é¢æ¥å®˜ï¼æ—¥æœ¬èªã§è©±ã—åˆã„ã¾ã—ã‚‡ã†ï¼', 'loongtomoka_v2'),
            'hanyu': ('éŸ©è¯­', 'ì•ˆë…•í•˜ì„¸ìš”, ë©´ì ‘ê´€ë‹˜!í•œêµ­ì–´ë¡œ ëŒ€í™”í•´ìš”!', 'loongkyong_v2'),
            'xibanyayu': ('è¥¿ç­ç‰™è¯­', 'Â¡Hola, entrevistador!Â¡Hablemos en espaÃ±ol!', 'sambert-camila-v1'),
            'yinniyu': ('å°å°¼è¯­', 'Halo, pewawancara!Ayo berkomunikasi dalam bahasa Indonesia!', 'sambert-indah-v1'),
            'fayu': ('æ³•è¯­', 'Bonjour, intervieweur !Parlons en franÃ§ais !', 'sambert-clara-v1'),
            'deyu': ('å¾·è¯­', 'Hallo, Interviewer!Lass uns auf Deutsch sprechen!', 'sambert-hanna-v1'),
            'taiyu': ('æ³°è¯­', 'à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¹ˆà¸°/à¸„à¸£à¸±à¸š, à¸œà¸¹à¹‰à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œ!à¸¡à¸²à¸à¸¹à¸”à¸„à¸¸à¸¢à¸à¸±à¸™à¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¸à¸±à¸™à¹€à¸–à¸­à¸°!', 'sambert-waan-v1')
        }
        self.interview_language='ä¸­æ–‡'
        
        self._load_prompts()

    def _load_prompts(self):
        base_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
        prompts_dir = os.path.join(base_dir, 'prompts', 'evaluation_report')
        
        with open(os.path.join(prompts_dir, 'extract_competencies.txt'), 'r', encoding='utf-8') as f:
            self.prompt_extract_competencies = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_single_competency.txt'), 'r', encoding='utf-8') as f:
            self.prompt_analyze_single_competency = f.read()
        
        with open(os.path.join(prompts_dir, 'generate_final_summary.txt'), 'r', encoding='utf-8') as f:
            self.prompt_generate_final_summary = f.read()
        
        with open(os.path.join(prompts_dir, 'user_report.txt'), 'r', encoding='utf-8') as f:
            self.prompt_user_report = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_job_match_and_career.txt'), 'r', encoding='utf-8') as f:
            self.prompt_job_match_and_career = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_personality.txt'), 'r', encoding='utf-8') as f:
            self.prompt_personality = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_salary_market.txt'), 'r', encoding='utf-8') as f:
            self.prompt_salary_market = f.read()

    def _call_llm(self, prompt: str, system_message: str, enable_search: bool = False) -> str | None:

        params = {
            "seed": 6,
            "model": model_name,
            "temperature": 0.3,
            "response_format": {"type": "json_object"},
            "messages": [{"role": "system", "content": system_message},
                        {"role": "user", "content": prompt}]
        }
        
        # if enable_search:
        #     params["tools"] = [{"type": "web_search"}]
        
        try:
            response = self.llm_client.chat.completions.create(**params)
            content_text = response.choices[0].message.content
            return content_text
        except Exception as e:
            logging.error(f"ï¼ï¼ï¼LLMè°ƒç”¨å¤±è´¥ï¼š{e}")
            return None

    def _extract_competencies(self, jd: str,transcript_text:str) -> Dict[str, List[str]]:
        system_message = self.prompt_extract_competencies.format(interview_language=self.interview_language)

        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """

        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_single_competency(self, competency: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_analyze_single_competency.format(
            competency=competency,
            interview_language=self.interview_language
        )
        prompt = f"""
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _generate_final_summary(self, detailed_analysis_str: str) -> Dict[str, Any]:
        system_message = self.prompt_generate_final_summary.format(interview_language=self.interview_language)

        prompt = f"""
        --- èƒ½åŠ›åˆ†ææ•°æ® ---
        {detailed_analysis_str}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_job_match_and_career(self, detailed_analysis_str: str, jd: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_job_match_and_career.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_personality(self, jd: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_personality.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_salary_market(self, jd: str, transcript_text: str, detailed_analysis_str: str) -> Dict[str, Any]:
        system_message = self.prompt_salary_market.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        """
        
        response_str = self._call_llm(prompt, system_message, enable_search=False)
        if not response_str:
            return {}
        
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(f"è–ªé…¬åˆ†æJSONè§£æå¤±è´¥: {e}")
            return {}

    def _user_report(self, jd: str, transcript_text: str, hr_report, personality, salary) -> dict[str, Any]:
        system_message = self.prompt_user_report.format(interview_language=self.interview_language)
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        
        --- é¢è¯•å®˜çš„è¯„ä»· ---
        {hr_report}
        
        --- æ€§æ ¼åˆ†æ ---
        {json.dumps(personality, ensure_ascii=False)}
        
        --- è–ªé…¬åˆ†æ ---
        {json.dumps(salary, ensure_ascii=False)}
        
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _format_transcript(self, transcript_json: List[Dict]) -> str:
        lines = []
        for entry in transcript_json:
            role_cn = "é¢è¯•å®˜" if entry['role'] == 'interviewer' else "å€™é€‰äºº"
            lines.append(f"[å½“å‰å¯¹è¯è½®æ•°ï¼š{entry['timestamp']}] {role_cn}: {entry['content']}")
        return "\n".join(lines)

    def generate_report(self, transcript_json_str: str, jd: str,interview_id:str,url_list:list[str],is_mp4:bool,interview_language:str)   :
        try:
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- æ¥æ”¶åˆ°é¢è¯•è®°å½•ï¼Œå¼€å§‹åˆ†æ")
            zero_time = time.time()
            self.interview_language=self.language_dict[interview_language][0]
            transcript_data = json.loads(transcript_json_str)
            try:
                transcript_text = self._format_transcript(transcript_data)
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•æ–‡æœ¬è®°å½•è§£æå‡ºé”™ï¼Œ{e}ï¼Œå¼€å§‹ä½¿ç”¨æºæ•°æ®")
                transcript_text = transcript_data

            competencies = self._extract_competencies(jd,transcript_text)
            all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            if not all_competency_keys :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} -- è€ƒæ ¸ç»´åº¦æŠ½å–å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                competencies = self._extract_competencies(jd, transcript_text)
                all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è€ƒæ ¸ç»´åº¦æŠ½å–æˆåŠŸï¼š{competencies}")

            detailed_analysis = []
            total_score = 0

            for competency in all_competency_keys:
                start_time=time.time()
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ­£åœ¨åˆ†æ '{competency}'...")
                analysis_result = self._analyze_single_competency(competency, transcript_text)
                if not analysis_result :
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†æç»´åº¦ï¼š{competency} å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    analysis_result = self._analyze_single_competency(competency, transcript_text)
                analysis_result['competency'] = competency
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†ææˆåŠŸï¼š{competency}ï¼Œè€—æ—¶{time.time()-start_time}s ")
                detailed_analysis.append(analysis_result)
                total_score += analysis_result.get('score', 0)

            detailed_analysis_str = json.dumps(detailed_analysis, indent=2, ensure_ascii=False)
            
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æ...")
            job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            if not job_match:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æå®Œæˆ")
            
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹æ€§æ ¼æ·±åº¦åˆ†æ...")
            personality = self._analyze_personality(jd, transcript_text)
            if not personality:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                personality = self._analyze_personality(jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼æ·±åº¦åˆ†æå®Œæˆ")
            
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹è–ªé…¬å¸‚åœºè¯„ä¼°...")
            try:
                salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
                    logging.warning(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬å¸‚åœºè¯„ä¼°å®Œæˆ")
            except Exception as e:
                logging.error(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¼‚å¸¸: {e}")
                salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
            
            # 6. ç”ŸæˆHRæ€»ç»“
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”ŸæˆHRæ€»ç»“...")
            final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ–‡æœ¬æŠ¥å‘Šæ€»ç»“å¤±è´¥ï¼Œå†æ¬¡å°è¯• - ")
                final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å†æ¬¡å°è¯•æ€»ç»“å¤±è´¥ï¼Œä¸»åŠ¨è¿”å›codeï¼š1 çŠ¶æ€ - ")
                a=1/0
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  HRæ€»ç»“ç”Ÿæˆå®Œæˆ")

            # 7. å¤šæ¨¡æ€åˆ†æ
            overall_score = round(total_score / len(all_competency_keys), 1) if all_competency_keys else -1
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å¤šæ¨¡æ€é£æ ¼åˆ†æ...")
            style=style_report(url_list=url_list,interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            if not style:
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€æŠ¥å‘Šè¯„ä¼°å‡ºé”™ï¼Œå¯åŠ¨ä¿åº•æœºåˆ¶...")
                style=style_report(url_list=[],interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€é£æ ¼åˆ†æå®Œæˆ")

            # 8. ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š
            hr_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
            }
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š...")
            user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            if not user_report:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šå·²ç”Ÿæˆ")

            # 9. èšåˆæœ€ç»ˆæŠ¥å‘Š
            final_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
                "competency_model_used": competencies,
                "job_match_analysis": job_match,
                "personality_analysis": personality,
                "salary_analysis": salary,
                "style_report": style,
                "user_report": user_report
            }

            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æœ€ç»ˆæŠ¥å‘Šå·²ç”Ÿæˆ...")

            content_json = json.dumps(final_report, ensure_ascii=False)
            try:
                with get_session() as session:
                    stmt = (
                        update(SimulateReport)
                        .where(SimulateReport.interview_id == interview_id)
                        .values(
                            content=content_json,
                            updated_at=datetime.now()
                        )
                    )

                    session.exec(stmt)
                    session.flush()
                    logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-é¢è¯•æŠ¥å‘Šæ›´æ–°æˆåŠŸ")
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-å…¥åº“å¤±è´¥ï¼Œé”™è¯¯: {str(e)}")

            re = json.dumps({
                "result": final_report,
                "code": 0,
                "interview_id": int(interview_id),
            }, ensure_ascii=False)

            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šæˆåŠŸï¼Œæ€»è€—æ—¶{time.time()-zero_time}sï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")

        except Exception as e:
            logging.error(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼Œé”™è¯¯ï¼š{e}")
            re= json.dumps({
                "result": None,
                "code": 1,
                "interview_id": int(interview_id),
                "error": str(e)
            },ensure_ascii=False)
            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼ï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")
            return None

```

```python
import json
import logging
import time
import os
from datetime import datetime
from typing import Dict, List, Any
import requests
from openai import OpenAI
from app.config import url_config
from app.database import get_session
from models import SimulateReport
from service.multimodal_report import style_report
from app.config import ai_config
from sqlmodel import update
qwen_api_key = ai_config['api_key']

config = url_config
post_url = config['interview_report_post_url']
qwen_api_uri = ai_config['api_uri']
model_name = ai_config['api_model']


class AIInterviewAssessor:
    def __init__(self):
        self.llm_client = OpenAI(
            api_key=qwen_api_key,
            base_url=qwen_api_uri,
        )
        self.language_dict={
            'zhongwen': ('ä¸­æ–‡', 'ä½ å¥½ï¼Œé¢è¯•å®˜ï¼è®©æˆ‘ä»¬ç”¨ä¸­æ–‡äº¤æµï¼', 'longxiaochun_v2'),
            'yingwen': ('è‹±æ–‡', "Hello, interviewer!Let's communicate in English!", 'longxiaochun_v2'),
            'riyu': ('æ—¥è¯­', 'ã“ã‚“ã«ã¡ã¯ã€é¢æ¥å®˜ï¼æ—¥æœ¬èªã§è©±ã—åˆã„ã¾ã—ã‚‡ã†ï¼', 'loongtomoka_v2'),
            'hanyu': ('éŸ©è¯­', 'ì•ˆë…•í•˜ì„¸ìš”, ë©´ì ‘ê´€ë‹˜!í•œêµ­ì–´ë¡œ ëŒ€í™”í•´ìš”!', 'loongkyong_v2'),
            'xibanyayu': ('è¥¿ç­ç‰™è¯­', 'Â¡Hola, entrevistador!Â¡Hablemos en espaÃ±ol!', 'sambert-camila-v1'),
            'yinniyu': ('å°å°¼è¯­', 'Halo, pewawancara!Ayo berkomunikasi dalam bahasa Indonesia!', 'sambert-indah-v1'),
            'fayu': ('æ³•è¯­', 'Bonjour, intervieweur !Parlons en franÃ§ais !', 'sambert-clara-v1'),
            'deyu': ('å¾·è¯­', 'Hallo, Interviewer!Lass uns auf Deutsch sprechen!', 'sambert-hanna-v1'),
            'taiyu': ('æ³°è¯­', 'à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¹ˆà¸°/à¸„à¸£à¸±à¸š, à¸œà¸¹à¹‰à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œ!à¸¡à¸²à¸à¸¹à¸”à¸„à¸¸à¸¢à¸à¸±à¸™à¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¸à¸±à¸™à¹€à¸–à¸­à¸°!', 'sambert-waan-v1')
        }
        self.interview_language='ä¸­æ–‡'
        
        self._load_prompts()

    def _load_prompts(self):
        base_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
        prompts_dir = os.path.join(base_dir, 'prompts', 'evaluation_report')
        
        with open(os.path.join(prompts_dir, 'extract_competencies.txt'), 'r', encoding='utf-8') as f:
            self.prompt_extract_competencies = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_single_competency.txt'), 'r', encoding='utf-8') as f:
            self.prompt_analyze_single_competency = f.read()
        
        with open(os.path.join(prompts_dir, 'generate_final_summary.txt'), 'r', encoding='utf-8') as f:
            self.prompt_generate_final_summary = f.read()
        
        with open(os.path.join(prompts_dir, 'user_report.txt'), 'r', encoding='utf-8') as f:
            self.prompt_user_report = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_job_match_and_career.txt'), 'r', encoding='utf-8') as f:
            self.prompt_job_match_and_career = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_personality.txt'), 'r', encoding='utf-8') as f:
            self.prompt_personality = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_salary_market.txt'), 'r', encoding='utf-8') as f:
            self.prompt_salary_market = f.read()

    def _call_llm(self, prompt: str, system_message: str, enable_search: bool = False) -> str | None:

        params = {
            "seed": 6,
            "model": model_name,
            "temperature": 0.3,
            "response_format": {"type": "json_object"},
            "messages": [{"role": "system", "content": system_message},
                        {"role": "user", "content": prompt}]
        }
        
        # if enable_search:
        #     params["tools"] = [{"type": "web_search"}]
        
        try:
            response = self.llm_client.chat.completions.create(**params)
            content_text = response.choices[0].message.content
            return content_text
        except Exception as e:
            logging.error(f"ï¼ï¼ï¼LLMè°ƒç”¨å¤±è´¥ï¼š{e}")
            return None

    def _extract_competencies(self, jd: str,transcript_text:str) -> Dict[str, List[str]]:
        system_message = self.prompt_extract_competencies.format(interview_language=self.interview_language)

        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """

        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_single_competency(self, competency: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_analyze_single_competency.format(
            competency=competency,
            interview_language=self.interview_language
        )
        prompt = f"""
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _generate_final_summary(self, detailed_analysis_str: str) -> Dict[str, Any]:
        system_message = self.prompt_generate_final_summary.format(interview_language=self.interview_language)

        prompt = f"""
        --- èƒ½åŠ›åˆ†ææ•°æ® ---
        {detailed_analysis_str}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_job_match_and_career(self, detailed_analysis_str: str, jd: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_job_match_and_career.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_personality(self, jd: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_personality.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_salary_market(self, jd: str, transcript_text: str, detailed_analysis_str: str) -> Dict[str, Any]:
        system_message = self.prompt_salary_market.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        """
        
        response_str = self._call_llm(prompt, system_message, enable_search=False)
        if not response_str:
            return {}
        
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(f"è–ªé…¬åˆ†æJSONè§£æå¤±è´¥: {e}")
            return {}

    def _user_report(self, jd: str, transcript_text: str, hr_report, personality, salary) -> dict[str, Any]:
        system_message = self.prompt_user_report.format(interview_language=self.interview_language)
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        
        --- é¢è¯•å®˜çš„è¯„ä»· ---
        {hr_report}
        
        --- æ€§æ ¼åˆ†æ ---
        {json.dumps(personality, ensure_ascii=False)}
        
        --- è–ªé…¬åˆ†æ ---
        {json.dumps(salary, ensure_ascii=False)}
        
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _format_transcript(self, transcript_json: List[Dict]) -> str:
        lines = []
        for entry in transcript_json:
            role_cn = "é¢è¯•å®˜" if entry['role'] == 'interviewer' else "å€™é€‰äºº"
            lines.append(f"[å½“å‰å¯¹è¯è½®æ•°ï¼š{entry['timestamp']}] {role_cn}: {entry['content']}")
        return "\n".join(lines)

    def generate_report(self, transcript_json_str: str, jd: str,interview_id:str,url_list:list[str],is_mp4:bool,interview_language:str)   :
        try:
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- æ¥æ”¶åˆ°é¢è¯•è®°å½•ï¼Œå¼€å§‹åˆ†æ")
            zero_time = time.time()
            self.interview_language=self.language_dict[interview_language][0]
            transcript_data = json.loads(transcript_json_str)
            try:
                transcript_text = self._format_transcript(transcript_data)
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•æ–‡æœ¬è®°å½•è§£æå‡ºé”™ï¼Œ{e}ï¼Œå¼€å§‹ä½¿ç”¨æºæ•°æ®")
                transcript_text = transcript_data

            competencies = self._extract_competencies(jd,transcript_text)
            all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            if not all_competency_keys :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} -- è€ƒæ ¸ç»´åº¦æŠ½å–å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                competencies = self._extract_competencies(jd, transcript_text)
                all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è€ƒæ ¸ç»´åº¦æŠ½å–æˆåŠŸï¼š{competencies}")

            detailed_analysis = []
            total_score = 0

            for competency in all_competency_keys:
                start_time=time.time()
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ­£åœ¨åˆ†æ '{competency}'...")
                analysis_result = self._analyze_single_competency(competency, transcript_text)
                if not analysis_result :
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†æç»´åº¦ï¼š{competency} å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    analysis_result = self._analyze_single_competency(competency, transcript_text)
                analysis_result['competency'] = competency
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†ææˆåŠŸï¼š{competency}ï¼Œè€—æ—¶{time.time()-start_time}s ")
                detailed_analysis.append(analysis_result)
                total_score += analysis_result.get('score', 0)

            detailed_analysis_str = json.dumps(detailed_analysis, indent=2, ensure_ascii=False)
            
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æ...")
            job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            if not job_match:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æå®Œæˆ")
            
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹æ€§æ ¼æ·±åº¦åˆ†æ...")
            personality = self._analyze_personality(jd, transcript_text)
            if not personality:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                personality = self._analyze_personality(jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼æ·±åº¦åˆ†æå®Œæˆ")
            
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹è–ªé…¬å¸‚åœºè¯„ä¼°...")
            try:
                salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
                    logging.warning(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬å¸‚åœºè¯„ä¼°å®Œæˆ")
            except Exception as e:
                logging.error(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¼‚å¸¸: {e}")
                salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
            
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”ŸæˆHRæ€»ç»“...")
            final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ–‡æœ¬æŠ¥å‘Šæ€»ç»“å¤±è´¥ï¼Œå†æ¬¡å°è¯• - ")
                final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å†æ¬¡å°è¯•æ€»ç»“å¤±è´¥ï¼Œä¸»åŠ¨è¿”å›codeï¼š1 çŠ¶æ€ - ")
                a=1/0
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  HRæ€»ç»“ç”Ÿæˆå®Œæˆ")

            # 7. å¤šæ¨¡æ€åˆ†æ
            overall_score = round(total_score / len(all_competency_keys), 1) if all_competency_keys else -1
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å¤šæ¨¡æ€é£æ ¼åˆ†æ...")
            style=style_report(url_list=url_list,interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            if not style:
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€æŠ¥å‘Šè¯„ä¼°å‡ºé”™ï¼Œå¯åŠ¨ä¿åº•æœºåˆ¶...")
                style=style_report(url_list=[],interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€é£æ ¼åˆ†æå®Œæˆ")

            # 8. ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š
            hr_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
            }
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š...")
            user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            if not user_report:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šå·²ç”Ÿæˆ")

            # 9. èšåˆæœ€ç»ˆæŠ¥å‘Š
            final_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
                "competency_model_used": competencies,
                "job_match_analysis": job_match,
                "personality_analysis": personality,
                "salary_analysis": salary,
                "style_report": style,
                "user_report": user_report
            }

            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æœ€ç»ˆæŠ¥å‘Šå·²ç”Ÿæˆ...")

            content_json = json.dumps(final_report, ensure_ascii=False)
            try:
                with get_session() as session:
                    stmt = (
                        update(SimulateReport)
                        .where(SimulateReport.interview_id == interview_id)
                        .values(
                            content=content_json,
                            updated_at=datetime.now()
                        )
                    )

                    session.exec(stmt)
                    session.flush()
                    logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-é¢è¯•æŠ¥å‘Šæ›´æ–°æˆåŠŸ")
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-å…¥åº“å¤±è´¥ï¼Œé”™è¯¯: {str(e)}")

            re = json.dumps({
                "result": final_report,
                "code": 0,
                "interview_id": int(interview_id),
            }, ensure_ascii=False)

            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šæˆåŠŸï¼Œæ€»è€—æ—¶{time.time()-zero_time}sï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")

        except Exception as e:
            logging.error(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼Œé”™è¯¯ï¼š{e}")
            re= json.dumps({
                "result": None,
                "code": 1,
                "interview_id": int(interview_id),
                "error": str(e)
            },ensure_ascii=False)
            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼ï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")
            return None

```

```python
import json
import logging
import time
import os
from datetime import datetime
from typing import Dict, List, Any
import requests
from openai import OpenAI
from app.config import url_config
from app.database import get_session
from models import SimulateReport
from service.multimodal_report import style_report
from app.config import ai_config
from sqlmodel import update
qwen_api_key = ai_config['api_key']

config = url_config
post_url = config['interview_report_post_url']
qwen_api_uri = ai_config['api_uri']
model_name = ai_config['api_model']


class AIInterviewAssessor:
    def __init__(self):
        self.llm_client = OpenAI(
            api_key=qwen_api_key,
            base_url=qwen_api_uri,
        )
        self.language_dict={
            'zhongwen': ('ä¸­æ–‡', 'ä½ å¥½ï¼Œé¢è¯•å®˜ï¼è®©æˆ‘ä»¬ç”¨ä¸­æ–‡äº¤æµï¼', 'longxiaochun_v2'),
            'yingwen': ('è‹±æ–‡', "Hello, interviewer!Let's communicate in English!", 'longxiaochun_v2'),
            'riyu': ('æ—¥è¯­', 'ã“ã‚“ã«ã¡ã¯ã€é¢æ¥å®˜ï¼æ—¥æœ¬èªã§è©±ã—åˆã„ã¾ã—ã‚‡ã†ï¼', 'loongtomoka_v2'),
            'hanyu': ('éŸ©è¯­', 'ì•ˆë…•í•˜ì„¸ìš”, ë©´ì ‘ê´€ë‹˜!í•œêµ­ì–´ë¡œ ëŒ€í™”í•´ìš”!', 'loongkyong_v2'),
            'xibanyayu': ('è¥¿ç­ç‰™è¯­', 'Â¡Hola, entrevistador!Â¡Hablemos en espaÃ±ol!', 'sambert-camila-v1'),
            'yinniyu': ('å°å°¼è¯­', 'Halo, pewawancara!Ayo berkomunikasi dalam bahasa Indonesia!', 'sambert-indah-v1'),
            'fayu': ('æ³•è¯­', 'Bonjour, intervieweur !Parlons en franÃ§ais !', 'sambert-clara-v1'),
            'deyu': ('å¾·è¯­', 'Hallo, Interviewer!Lass uns auf Deutsch sprechen!', 'sambert-hanna-v1'),
            'taiyu': ('æ³°è¯­', 'à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¹ˆà¸°/à¸„à¸£à¸±à¸š, à¸œà¸¹à¹‰à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œ!à¸¡à¸²à¸à¸¹à¸”à¸„à¸¸à¸¢à¸à¸±à¸™à¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¸à¸±à¸™à¹€à¸–à¸­à¸°!', 'sambert-waan-v1')
        }
        self.interview_language='ä¸­æ–‡'
        
        self._load_prompts()

    def _load_prompts(self):
        base_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
        prompts_dir = os.path.join(base_dir, 'prompts', 'evaluation_report')
        
        with open(os.path.join(prompts_dir, 'extract_competencies.txt'), 'r', encoding='utf-8') as f:
            self.prompt_extract_competencies = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_single_competency.txt'), 'r', encoding='utf-8') as f:
            self.prompt_analyze_single_competency = f.read()
        
        with open(os.path.join(prompts_dir, 'generate_final_summary.txt'), 'r', encoding='utf-8') as f:
            self.prompt_generate_final_summary = f.read()
        
        with open(os.path.join(prompts_dir, 'user_report.txt'), 'r', encoding='utf-8') as f:
            self.prompt_user_report = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_job_match_and_career.txt'), 'r', encoding='utf-8') as f:
            self.prompt_job_match_and_career = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_personality.txt'), 'r', encoding='utf-8') as f:
            self.prompt_personality = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_salary_market.txt'), 'r', encoding='utf-8') as f:
            self.prompt_salary_market = f.read()

    def _call_llm(self, prompt: str, system_message: str, enable_search: bool = False) -> str | None:

        params = {
            "seed": 6,
            "model": model_name,
            "temperature": 0.3,
            "response_format": {"type": "json_object"},
            "messages": [{"role": "system", "content": system_message},
                        {"role": "user", "content": prompt}]
        }
        
        # if enable_search:
        #     params["tools"] = [{"type": "web_search"}]
        
        try:
            response = self.llm_client.chat.completions.create(**params)
            content_text = response.choices[0].message.content
            return content_text
        except Exception as e:
            logging.error(f"ï¼ï¼ï¼LLMè°ƒç”¨å¤±è´¥ï¼š{e}")
            return None

    def _extract_competencies(self, jd: str,transcript_text:str) -> Dict[str, List[str]]:
        system_message = self.prompt_extract_competencies.format(interview_language=self.interview_language)

        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """

        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_single_competency(self, competency: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_analyze_single_competency.format(
            competency=competency,
            interview_language=self.interview_language
        )
        prompt = f"""
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _generate_final_summary(self, detailed_analysis_str: str) -> Dict[str, Any]:
        system_message = self.prompt_generate_final_summary.format(interview_language=self.interview_language)

        prompt = f"""
        --- èƒ½åŠ›åˆ†ææ•°æ® ---
        {detailed_analysis_str}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_job_match_and_career(self, detailed_analysis_str: str, jd: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_job_match_and_career.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_personality(self, jd: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_personality.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_salary_market(self, jd: str, transcript_text: str, detailed_analysis_str: str) -> Dict[str, Any]:
        system_message = self.prompt_salary_market.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        """
        
        response_str = self._call_llm(prompt, system_message, enable_search=False)
        if not response_str:
            return {}
        
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(f"è–ªé…¬åˆ†æJSONè§£æå¤±è´¥: {e}")
            return {}

    def _user_report(self, jd: str, transcript_text: str, hr_report, personality, salary) -> dict[str, Any]:
        system_message = self.prompt_user_report.format(interview_language=self.interview_language)
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        
        --- é¢è¯•å®˜çš„è¯„ä»· ---
        {hr_report}
        
        --- æ€§æ ¼åˆ†æ ---
        {json.dumps(personality, ensure_ascii=False)}
        
        --- è–ªé…¬åˆ†æ ---
        {json.dumps(salary, ensure_ascii=False)}
        
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _format_transcript(self, transcript_json: List[Dict]) -> str:
        lines = []
        for entry in transcript_json:
            role_cn = "é¢è¯•å®˜" if entry['role'] == 'interviewer' else "å€™é€‰äºº"
            lines.append(f"[å½“å‰å¯¹è¯è½®æ•°ï¼š{entry['timestamp']}] {role_cn}: {entry['content']}")
        return "\n".join(lines)

    def generate_report(self, transcript_json_str: str, jd: str,interview_id:str,url_list:list[str],is_mp4:bool,interview_language:str)   :
        try:
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- æ¥æ”¶åˆ°é¢è¯•è®°å½•ï¼Œå¼€å§‹åˆ†æ")
            zero_time = time.time()
            self.interview_language=self.language_dict[interview_language][0]
            transcript_data = json.loads(transcript_json_str)
            try:
                transcript_text = self._format_transcript(transcript_data)
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•æ–‡æœ¬è®°å½•è§£æå‡ºé”™ï¼Œ{e}ï¼Œå¼€å§‹ä½¿ç”¨æºæ•°æ®")
                transcript_text = transcript_data

            competencies = self._extract_competencies(jd,transcript_text)
            all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            if not all_competency_keys :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} -- è€ƒæ ¸ç»´åº¦æŠ½å–å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                competencies = self._extract_competencies(jd, transcript_text)
                all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è€ƒæ ¸ç»´åº¦æŠ½å–æˆåŠŸï¼š{competencies}")

            detailed_analysis = []
            total_score = 0

            for competency in all_competency_keys:
                start_time=time.time()
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ­£åœ¨åˆ†æ '{competency}'...")
                analysis_result = self._analyze_single_competency(competency, transcript_text)
                if not analysis_result :
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†æç»´åº¦ï¼š{competency} å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    analysis_result = self._analyze_single_competency(competency, transcript_text)
                analysis_result['competency'] = competency
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†ææˆåŠŸï¼š{competency}ï¼Œè€—æ—¶{time.time()-start_time}s ")
                detailed_analysis.append(analysis_result)
                total_score += analysis_result.get('score', 0)

            detailed_analysis_str = json.dumps(detailed_analysis, indent=2, ensure_ascii=False)
            
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æ...")
            job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            if not job_match:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æå®Œæˆ")
            
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹æ€§æ ¼æ·±åº¦åˆ†æ...")
            personality = self._analyze_personality(jd, transcript_text)
            if not personality:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                personality = self._analyze_personality(jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼æ·±åº¦åˆ†æå®Œæˆ")
            
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹è–ªé…¬å¸‚åœºè¯„ä¼°...")
            try:
                salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
                    logging.warning(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬å¸‚åœºè¯„ä¼°å®Œæˆ")
            except Exception as e:
                logging.error(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¼‚å¸¸: {e}")
                salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
            
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”ŸæˆHRæ€»ç»“...")
            final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ–‡æœ¬æŠ¥å‘Šæ€»ç»“å¤±è´¥ï¼Œå†æ¬¡å°è¯• - ")
                final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å†æ¬¡å°è¯•æ€»ç»“å¤±è´¥ï¼Œä¸»åŠ¨è¿”å›codeï¼š1 çŠ¶æ€ - ")
                a=1/0
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  HRæ€»ç»“ç”Ÿæˆå®Œæˆ")

            overall_score = round(total_score / len(all_competency_keys), 1) if all_competency_keys else -1
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å¤šæ¨¡æ€é£æ ¼åˆ†æ...")
            style=style_report(url_list=url_list,interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            if not style:
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€æŠ¥å‘Šè¯„ä¼°å‡ºé”™ï¼Œå¯åŠ¨ä¿åº•æœºåˆ¶...")
                style=style_report(url_list=[],interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€é£æ ¼åˆ†æå®Œæˆ")

            # 8. ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š
            hr_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
            }
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š...")
            user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            if not user_report:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šå·²ç”Ÿæˆ")

            # 9. èšåˆæœ€ç»ˆæŠ¥å‘Š
            final_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
                "competency_model_used": competencies,
                "job_match_analysis": job_match,
                "personality_analysis": personality,
                "salary_analysis": salary,
                "style_report": style,
                "user_report": user_report
            }

            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æœ€ç»ˆæŠ¥å‘Šå·²ç”Ÿæˆ...")

            content_json = json.dumps(final_report, ensure_ascii=False)
            try:
                with get_session() as session:
                    stmt = (
                        update(SimulateReport)
                        .where(SimulateReport.interview_id == interview_id)
                        .values(
                            content=content_json,
                            updated_at=datetime.now()
                        )
                    )

                    session.exec(stmt)
                    session.flush()
                    logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-é¢è¯•æŠ¥å‘Šæ›´æ–°æˆåŠŸ")
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-å…¥åº“å¤±è´¥ï¼Œé”™è¯¯: {str(e)}")

            re = json.dumps({
                "result": final_report,
                "code": 0,
                "interview_id": int(interview_id),
            }, ensure_ascii=False)

            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šæˆåŠŸï¼Œæ€»è€—æ—¶{time.time()-zero_time}sï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")

        except Exception as e:
            logging.error(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼Œé”™è¯¯ï¼š{e}")
            re= json.dumps({
                "result": None,
                "code": 1,
                "interview_id": int(interview_id),
                "error": str(e)
            },ensure_ascii=False)
            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼ï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")
            return None

```

```python
import json
import logging
import time
import os
from datetime import datetime
from typing import Dict, List, Any
import requests
from openai import OpenAI
from app.config import url_config
from app.database import get_session
from models import SimulateReport
from service.multimodal_report import style_report
from app.config import ai_config
from sqlmodel import update
qwen_api_key = ai_config['api_key']

config = url_config
post_url = config['interview_report_post_url']
qwen_api_uri = ai_config['api_uri']
model_name = ai_config['api_model']


class AIInterviewAssessor:
    def __init__(self):
        self.llm_client = OpenAI(
            api_key=qwen_api_key,
            base_url=qwen_api_uri,
        )
        self.language_dict={
            'zhongwen': ('ä¸­æ–‡', 'ä½ å¥½ï¼Œé¢è¯•å®˜ï¼è®©æˆ‘ä»¬ç”¨ä¸­æ–‡äº¤æµï¼', 'longxiaochun_v2'),
            'yingwen': ('è‹±æ–‡', "Hello, interviewer!Let's communicate in English!", 'longxiaochun_v2'),
            'riyu': ('æ—¥è¯­', 'ã“ã‚“ã«ã¡ã¯ã€é¢æ¥å®˜ï¼æ—¥æœ¬èªã§è©±ã—åˆã„ã¾ã—ã‚‡ã†ï¼', 'loongtomoka_v2'),
            'hanyu': ('éŸ©è¯­', 'ì•ˆë…•í•˜ì„¸ìš”, ë©´ì ‘ê´€ë‹˜!í•œêµ­ì–´ë¡œ ëŒ€í™”í•´ìš”!', 'loongkyong_v2'),
            'xibanyayu': ('è¥¿ç­ç‰™è¯­', 'Â¡Hola, entrevistador!Â¡Hablemos en espaÃ±ol!', 'sambert-camila-v1'),
            'yinniyu': ('å°å°¼è¯­', 'Halo, pewawancara!Ayo berkomunikasi dalam bahasa Indonesia!', 'sambert-indah-v1'),
            'fayu': ('æ³•è¯­', 'Bonjour, intervieweur !Parlons en franÃ§ais !', 'sambert-clara-v1'),
            'deyu': ('å¾·è¯­', 'Hallo, Interviewer!Lass uns auf Deutsch sprechen!', 'sambert-hanna-v1'),
            'taiyu': ('æ³°è¯­', 'à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¹ˆà¸°/à¸„à¸£à¸±à¸š, à¸œà¸¹à¹‰à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œ!à¸¡à¸²à¸à¸¹à¸”à¸„à¸¸à¸¢à¸à¸±à¸™à¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¸à¸±à¸™à¹€à¸–à¸­à¸°!', 'sambert-waan-v1')
        }
        self.interview_language='ä¸­æ–‡'
        
        self._load_prompts()

    def _load_prompts(self):
        base_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
        prompts_dir = os.path.join(base_dir, 'prompts', 'evaluation_report')
        
        with open(os.path.join(prompts_dir, 'extract_competencies.txt'), 'r', encoding='utf-8') as f:
            self.prompt_extract_competencies = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_single_competency.txt'), 'r', encoding='utf-8') as f:
            self.prompt_analyze_single_competency = f.read()
        
        with open(os.path.join(prompts_dir, 'generate_final_summary.txt'), 'r', encoding='utf-8') as f:
            self.prompt_generate_final_summary = f.read()
        
        with open(os.path.join(prompts_dir, 'user_report.txt'), 'r', encoding='utf-8') as f:
            self.prompt_user_report = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_job_match_and_career.txt'), 'r', encoding='utf-8') as f:
            self.prompt_job_match_and_career = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_personality.txt'), 'r', encoding='utf-8') as f:
            self.prompt_personality = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_salary_market.txt'), 'r', encoding='utf-8') as f:
            self.prompt_salary_market = f.read()

    def _call_llm(self, prompt: str, system_message: str, enable_search: bool = False) -> str | None:

        params = {
            "seed": 6,
            "model": model_name,
            "temperature": 0.3,
            "response_format": {"type": "json_object"},
            "messages": [{"role": "system", "content": system_message},
                        {"role": "user", "content": prompt}]
        }
        
        # if enable_search:
        #     params["tools"] = [{"type": "web_search"}]
        
        try:
            response = self.llm_client.chat.completions.create(**params)
            content_text = response.choices[0].message.content
            return content_text
        except Exception as e:
            logging.error(f"ï¼ï¼ï¼LLMè°ƒç”¨å¤±è´¥ï¼š{e}")
            return None

    def _extract_competencies(self, jd: str,transcript_text:str) -> Dict[str, List[str]]:
        system_message = self.prompt_extract_competencies.format(interview_language=self.interview_language)

        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """

        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_single_competency(self, competency: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_analyze_single_competency.format(
            competency=competency,
            interview_language=self.interview_language
        )
        prompt = f"""
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _generate_final_summary(self, detailed_analysis_str: str) -> Dict[str, Any]:
        system_message = self.prompt_generate_final_summary.format(interview_language=self.interview_language)

        prompt = f"""
        --- èƒ½åŠ›åˆ†ææ•°æ® ---
        {detailed_analysis_str}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_job_match_and_career(self, detailed_analysis_str: str, jd: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_job_match_and_career.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_personality(self, jd: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_personality.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_salary_market(self, jd: str, transcript_text: str, detailed_analysis_str: str) -> Dict[str, Any]:
        system_message = self.prompt_salary_market.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        """
        
        response_str = self._call_llm(prompt, system_message, enable_search=False)
        if not response_str:
            return {}
        
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(f"è–ªé…¬åˆ†æJSONè§£æå¤±è´¥: {e}")
            return {}

    def _user_report(self, jd: str, transcript_text: str, hr_report, personality, salary) -> dict[str, Any]:
        system_message = self.prompt_user_report.format(interview_language=self.interview_language)
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        
        --- é¢è¯•å®˜çš„è¯„ä»· ---
        {hr_report}
        
        --- æ€§æ ¼åˆ†æ ---
        {json.dumps(personality, ensure_ascii=False)}
        
        --- è–ªé…¬åˆ†æ ---
        {json.dumps(salary, ensure_ascii=False)}
        
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _format_transcript(self, transcript_json: List[Dict]) -> str:
        lines = []
        for entry in transcript_json:
            role_cn = "é¢è¯•å®˜" if entry['role'] == 'interviewer' else "å€™é€‰äºº"
            lines.append(f"[å½“å‰å¯¹è¯è½®æ•°ï¼š{entry['timestamp']}] {role_cn}: {entry['content']}")
        return "\n".join(lines)

    def generate_report(self, transcript_json_str: str, jd: str,interview_id:str,url_list:list[str],is_mp4:bool,interview_language:str)   :
        try:
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- æ¥æ”¶åˆ°é¢è¯•è®°å½•ï¼Œå¼€å§‹åˆ†æ")
            zero_time = time.time()
            self.interview_language=self.language_dict[interview_language][0]
            transcript_data = json.loads(transcript_json_str)
            try:
                transcript_text = self._format_transcript(transcript_data)
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•æ–‡æœ¬è®°å½•è§£æå‡ºé”™ï¼Œ{e}ï¼Œå¼€å§‹ä½¿ç”¨æºæ•°æ®")
                transcript_text = transcript_data

            competencies = self._extract_competencies(jd,transcript_text)
            all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            if not all_competency_keys :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} -- è€ƒæ ¸ç»´åº¦æŠ½å–å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                competencies = self._extract_competencies(jd, transcript_text)
                all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è€ƒæ ¸ç»´åº¦æŠ½å–æˆåŠŸï¼š{competencies}")

            detailed_analysis = []
            total_score = 0

            for competency in all_competency_keys:
                start_time=time.time()
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ­£åœ¨åˆ†æ '{competency}'...")
                analysis_result = self._analyze_single_competency(competency, transcript_text)
                if not analysis_result :
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†æç»´åº¦ï¼š{competency} å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    analysis_result = self._analyze_single_competency(competency, transcript_text)
                analysis_result['competency'] = competency
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†ææˆåŠŸï¼š{competency}ï¼Œè€—æ—¶{time.time()-start_time}s ")
                detailed_analysis.append(analysis_result)
                total_score += analysis_result.get('score', 0)

            detailed_analysis_str = json.dumps(detailed_analysis, indent=2, ensure_ascii=False)
            
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æ...")
            job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            if not job_match:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æå®Œæˆ")
            
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹æ€§æ ¼æ·±åº¦åˆ†æ...")
            personality = self._analyze_personality(jd, transcript_text)
            if not personality:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                personality = self._analyze_personality(jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼æ·±åº¦åˆ†æå®Œæˆ")
            
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹è–ªé…¬å¸‚åœºè¯„ä¼°...")
            try:
                salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
                    logging.warning(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬å¸‚åœºè¯„ä¼°å®Œæˆ")
            except Exception as e:
                logging.error(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¼‚å¸¸: {e}")
                salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
            
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”ŸæˆHRæ€»ç»“...")
            final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ–‡æœ¬æŠ¥å‘Šæ€»ç»“å¤±è´¥ï¼Œå†æ¬¡å°è¯• - ")
                final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å†æ¬¡å°è¯•æ€»ç»“å¤±è´¥ï¼Œä¸»åŠ¨è¿”å›codeï¼š1 çŠ¶æ€ - ")
                a=1/0
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  HRæ€»ç»“ç”Ÿæˆå®Œæˆ")

            overall_score = round(total_score / len(all_competency_keys), 1) if all_competency_keys else -1
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å¤šæ¨¡æ€é£æ ¼åˆ†æ...")
            style=style_report(url_list=url_list,interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            if not style:
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€æŠ¥å‘Šè¯„ä¼°å‡ºé”™ï¼Œå¯åŠ¨ä¿åº•æœºåˆ¶...")
                style=style_report(url_list=[],interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€é£æ ¼åˆ†æå®Œæˆ")

            hr_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
            }
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š...")
            user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            if not user_report:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šå·²ç”Ÿæˆ")

            # 9. èšåˆæœ€ç»ˆæŠ¥å‘Š
            final_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
                "competency_model_used": competencies,
                "job_match_analysis": job_match,
                "personality_analysis": personality,
                "salary_analysis": salary,
                "style_report": style,
                "user_report": user_report
            }

            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æœ€ç»ˆæŠ¥å‘Šå·²ç”Ÿæˆ...")

            content_json = json.dumps(final_report, ensure_ascii=False)
            try:
                with get_session() as session:
                    stmt = (
                        update(SimulateReport)
                        .where(SimulateReport.interview_id == interview_id)
                        .values(
                            content=content_json,
                            updated_at=datetime.now()
                        )
                    )

                    session.exec(stmt)
                    session.flush()
                    logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-é¢è¯•æŠ¥å‘Šæ›´æ–°æˆåŠŸ")
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-å…¥åº“å¤±è´¥ï¼Œé”™è¯¯: {str(e)}")

            re = json.dumps({
                "result": final_report,
                "code": 0,
                "interview_id": int(interview_id),
            }, ensure_ascii=False)

            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šæˆåŠŸï¼Œæ€»è€—æ—¶{time.time()-zero_time}sï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")

        except Exception as e:
            logging.error(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼Œé”™è¯¯ï¼š{e}")
            re= json.dumps({
                "result": None,
                "code": 1,
                "interview_id": int(interview_id),
                "error": str(e)
            },ensure_ascii=False)
            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼ï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")
            return None

```

```python
import json
import logging
import time
import os
from datetime import datetime
from typing import Dict, List, Any
import requests
from openai import OpenAI
from app.config import url_config
from app.database import get_session
from models import SimulateReport
from service.multimodal_report import style_report
from app.config import ai_config
from sqlmodel import update
qwen_api_key = ai_config['api_key']

config = url_config
post_url = config['interview_report_post_url']
qwen_api_uri = ai_config['api_uri']
model_name = ai_config['api_model']


class AIInterviewAssessor:
    def __init__(self):
        self.llm_client = OpenAI(
            api_key=qwen_api_key,
            base_url=qwen_api_uri,
        )
        self.language_dict={
            'zhongwen': ('ä¸­æ–‡', 'ä½ å¥½ï¼Œé¢è¯•å®˜ï¼è®©æˆ‘ä»¬ç”¨ä¸­æ–‡äº¤æµï¼', 'longxiaochun_v2'),
            'yingwen': ('è‹±æ–‡', "Hello, interviewer!Let's communicate in English!", 'longxiaochun_v2'),
            'riyu': ('æ—¥è¯­', 'ã“ã‚“ã«ã¡ã¯ã€é¢æ¥å®˜ï¼æ—¥æœ¬èªã§è©±ã—åˆã„ã¾ã—ã‚‡ã†ï¼', 'loongtomoka_v2'),
            'hanyu': ('éŸ©è¯­', 'ì•ˆë…•í•˜ì„¸ìš”, ë©´ì ‘ê´€ë‹˜!í•œêµ­ì–´ë¡œ ëŒ€í™”í•´ìš”!', 'loongkyong_v2'),
            'xibanyayu': ('è¥¿ç­ç‰™è¯­', 'Â¡Hola, entrevistador!Â¡Hablemos en espaÃ±ol!', 'sambert-camila-v1'),
            'yinniyu': ('å°å°¼è¯­', 'Halo, pewawancara!Ayo berkomunikasi dalam bahasa Indonesia!', 'sambert-indah-v1'),
            'fayu': ('æ³•è¯­', 'Bonjour, intervieweur !Parlons en franÃ§ais !', 'sambert-clara-v1'),
            'deyu': ('å¾·è¯­', 'Hallo, Interviewer!Lass uns auf Deutsch sprechen!', 'sambert-hanna-v1'),
            'taiyu': ('æ³°è¯­', 'à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¹ˆà¸°/à¸„à¸£à¸±à¸š, à¸œà¸¹à¹‰à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œ!à¸¡à¸²à¸à¸¹à¸”à¸„à¸¸à¸¢à¸à¸±à¸™à¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¸à¸±à¸™à¹€à¸–à¸­à¸°!', 'sambert-waan-v1')
        }
        self.interview_language='ä¸­æ–‡'
        
        self._load_prompts()

    def _load_prompts(self):
        base_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
        prompts_dir = os.path.join(base_dir, 'prompts', 'evaluation_report')
        
        with open(os.path.join(prompts_dir, 'extract_competencies.txt'), 'r', encoding='utf-8') as f:
            self.prompt_extract_competencies = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_single_competency.txt'), 'r', encoding='utf-8') as f:
            self.prompt_analyze_single_competency = f.read()
        
        with open(os.path.join(prompts_dir, 'generate_final_summary.txt'), 'r', encoding='utf-8') as f:
            self.prompt_generate_final_summary = f.read()
        
        with open(os.path.join(prompts_dir, 'user_report.txt'), 'r', encoding='utf-8') as f:
            self.prompt_user_report = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_job_match_and_career.txt'), 'r', encoding='utf-8') as f:
            self.prompt_job_match_and_career = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_personality.txt'), 'r', encoding='utf-8') as f:
            self.prompt_personality = f.read()
        
        with open(os.path.join(prompts_dir, 'analyze_salary_market.txt'), 'r', encoding='utf-8') as f:
            self.prompt_salary_market = f.read()

    def _call_llm(self, prompt: str, system_message: str, enable_search: bool = False) -> str | None:

        params = {
            "seed": 6,
            "model": model_name,
            "temperature": 0.3,
            "response_format": {"type": "json_object"},
            "messages": [{"role": "system", "content": system_message},
                        {"role": "user", "content": prompt}]
        }
        
        # if enable_search:
        #     params["tools"] = [{"type": "web_search"}]
        
        try:
            response = self.llm_client.chat.completions.create(**params)
            content_text = response.choices[0].message.content
            return content_text
        except Exception as e:
            logging.error(f"ï¼ï¼ï¼LLMè°ƒç”¨å¤±è´¥ï¼š{e}")
            return None

    def _extract_competencies(self, jd: str,transcript_text:str) -> Dict[str, List[str]]:
        system_message = self.prompt_extract_competencies.format(interview_language=self.interview_language)

        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """

        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_single_competency(self, competency: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_analyze_single_competency.format(
            competency=competency,
            interview_language=self.interview_language
        )
        prompt = f"""
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _generate_final_summary(self, detailed_analysis_str: str) -> Dict[str, Any]:
        system_message = self.prompt_generate_final_summary.format(interview_language=self.interview_language)

        prompt = f"""
        --- èƒ½åŠ›åˆ†ææ•°æ® ---
        {detailed_analysis_str}
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _analyze_job_match_and_career(self, detailed_analysis_str: str, jd: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_job_match_and_career.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_personality(self, jd: str, transcript_text: str) -> Dict[str, Any]:
        system_message = self.prompt_personality.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        """
        
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}
    
    def _analyze_salary_market(self, jd: str, transcript_text: str, detailed_analysis_str: str) -> Dict[str, Any]:
        system_message = self.prompt_salary_market.format(interview_language=self.interview_language)
        
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- é¢è¯•è®°å½• ---
        {transcript_text}
        
        --- èƒ½åŠ›è¯„ä¼°è¯¦æƒ… ---
        {detailed_analysis_str}
        """
        
        response_str = self._call_llm(prompt, system_message, enable_search=False)
        if not response_str:
            return {}
        
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(f"è–ªé…¬åˆ†æJSONè§£æå¤±è´¥: {e}")
            return {}

    def _user_report(self, jd: str, transcript_text: str, hr_report, personality, salary) -> dict[str, Any]:
        system_message = self.prompt_user_report.format(interview_language=self.interview_language)
        prompt = f"""
        --- å²—ä½æè¿° ---
        {jd}
        
        --- å®Œæ•´é¢è¯•æ–‡å­—è®°å½• ---
        {transcript_text}
        
        --- é¢è¯•å®˜çš„è¯„ä»· ---
        {hr_report}
        
        --- æ€§æ ¼åˆ†æ ---
        {json.dumps(personality, ensure_ascii=False)}
        
        --- è–ªé…¬åˆ†æ ---
        {json.dumps(salary, ensure_ascii=False)}
        
        """
        response_str = self._call_llm(prompt, system_message)
        try:
            mydict = json.loads(response_str)
            return mydict
        except Exception as e:
            logging.error(e)
            return {}

    def _format_transcript(self, transcript_json: List[Dict]) -> str:
        lines = []
        for entry in transcript_json:
            role_cn = "é¢è¯•å®˜" if entry['role'] == 'interviewer' else "å€™é€‰äºº"
            lines.append(f"[å½“å‰å¯¹è¯è½®æ•°ï¼š{entry['timestamp']}] {role_cn}: {entry['content']}")
        return "\n".join(lines)

    def generate_report(self, transcript_json_str: str, jd: str,interview_id:str,url_list:list[str],is_mp4:bool,interview_language:str)   :
        try:
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- æ¥æ”¶åˆ°é¢è¯•è®°å½•ï¼Œå¼€å§‹åˆ†æ")
            zero_time = time.time()
            self.interview_language=self.language_dict[interview_language][0]
            transcript_data = json.loads(transcript_json_str)
            try:
                transcript_text = self._format_transcript(transcript_data)
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•æ–‡æœ¬è®°å½•è§£æå‡ºé”™ï¼Œ{e}ï¼Œå¼€å§‹ä½¿ç”¨æºæ•°æ®")
                transcript_text = transcript_data

            competencies = self._extract_competencies(jd,transcript_text)
            all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            if not all_competency_keys :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} -- è€ƒæ ¸ç»´åº¦æŠ½å–å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                competencies = self._extract_competencies(jd, transcript_text)
                all_competency_keys = [skill for cat in competencies.values() for skill in cat]
            logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è€ƒæ ¸ç»´åº¦æŠ½å–æˆåŠŸï¼š{competencies}")

            detailed_analysis = []
            total_score = 0

            for competency in all_competency_keys:
                start_time=time.time()
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ­£åœ¨åˆ†æ '{competency}'...")
                analysis_result = self._analyze_single_competency(competency, transcript_text)
                if not analysis_result :
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†æç»´åº¦ï¼š{competency} å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    analysis_result = self._analyze_single_competency(competency, transcript_text)
                analysis_result['competency'] = competency
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  åˆ†ææˆåŠŸï¼š{competency}ï¼Œè€—æ—¶{time.time()-start_time}s ")
                detailed_analysis.append(analysis_result)
                total_score += analysis_result.get('score', 0)

            detailed_analysis_str = json.dumps(detailed_analysis, indent=2, ensure_ascii=False)
            
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æ...")
            job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            if not job_match:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                job_match = self._analyze_job_match_and_career(detailed_analysis_str, jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å²—ä½é€‚é…åº¦å’ŒèŒä¸šå‘å±•åˆ†æå®Œæˆ")
            
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹æ€§æ ¼æ·±åº¦åˆ†æ...")
            personality = self._analyze_personality(jd, transcript_text)
            if not personality:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼åˆ†æå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                personality = self._analyze_personality(jd, transcript_text)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æ€§æ ¼æ·±åº¦åˆ†æå®Œæˆ")
            
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹è–ªé…¬å¸‚åœºè¯„ä¼°...")
            try:
                salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                    salary = self._analyze_salary_market(jd, transcript_text, detailed_analysis_str)
                if not salary:
                    salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
                    logging.warning(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬å¸‚åœºè¯„ä¼°å®Œæˆ")
            except Exception as e:
                logging.error(f" --- é¢è¯•ID ï¼š{interview_id} --  è–ªé…¬è¯„ä¼°å¼‚å¸¸: {e}")
                salary = {"å¸‚åœºè–ªèµ„èŒƒå›´": "æ•°æ®ä¸è¶³", "æ¨èè–ªèµ„": "éœ€è¿›ä¸€æ­¥è°ƒç ”"}
            
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”ŸæˆHRæ€»ç»“...")
            final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  æ–‡æœ¬æŠ¥å‘Šæ€»ç»“å¤±è´¥ï¼Œå†æ¬¡å°è¯• - ")
                final_summary = self._generate_final_summary(detailed_analysis_str)
            if not final_summary :
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å†æ¬¡å°è¯•æ€»ç»“å¤±è´¥ï¼Œä¸»åŠ¨è¿”å›codeï¼š1 çŠ¶æ€ - ")
                a=1/0
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  HRæ€»ç»“ç”Ÿæˆå®Œæˆ")

            overall_score = round(total_score / len(all_competency_keys), 1) if all_competency_keys else -1
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹å¤šæ¨¡æ€é£æ ¼åˆ†æ...")
            style=style_report(url_list=url_list,interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            if not style:
                logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€æŠ¥å‘Šè¯„ä¼°å‡ºé”™ï¼Œå¯åŠ¨ä¿åº•æœºåˆ¶...")
                style=style_report(url_list=[],interview_id=interview_id,is_mp4=is_mp4,interview_language=self.interview_language)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¤šæ¨¡æ€é£æ ¼åˆ†æå®Œæˆ")

            hr_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
            }
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å¼€å§‹ç”Ÿæˆå€™é€‰äººæŠ¥å‘Š...")
            user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            if not user_report:
                logging.info(f" --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œå†æ¬¡å°è¯•")
                user_report=self._user_report(jd, transcript_text, hr_report, personality, salary)
            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  å€™é€‰äººæŠ¥å‘Šå·²ç”Ÿæˆ")

            final_report = {
                "overall_assessment": {
                    "match_score": overall_score,
                    "conclusion": final_summary.get("conclusion"),
                    "highlights": final_summary.get("highlights"),
                    "potential_risks": final_summary.get("risks")
                },
                "detailed_analysis": detailed_analysis,
                "competency_model_used": competencies,
                "job_match_analysis": job_match,
                "personality_analysis": personality,
                "salary_analysis": salary,
                "style_report": style,
                "user_report": user_report
            }

            logging.info(f"  --- é¢è¯•ID ï¼š{interview_id} --  æœ€ç»ˆæŠ¥å‘Šå·²ç”Ÿæˆ...")

            content_json = json.dumps(final_report, ensure_ascii=False)
            try:
                with get_session() as session:
                    stmt = (
                        update(SimulateReport)
                        .where(SimulateReport.interview_id == interview_id)
                        .values(
                            content=content_json,
                            updated_at=datetime.now()
                        )
                    )

                    session.exec(stmt)
                    session.flush()
                    logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-é¢è¯•æŠ¥å‘Šæ›´æ–°æˆåŠŸ")
            except Exception as e:
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-å…¥åº“å¤±è´¥ï¼Œé”™è¯¯: {str(e)}")

            re = json.dumps({
                "result": final_report,
                "code": 0,
                "interview_id": int(interview_id),
            }, ensure_ascii=False)

            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šæˆåŠŸï¼Œæ€»è€—æ—¶{time.time()-zero_time}sï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")

        except Exception as e:
            logging.error(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼Œé”™è¯¯ï¼š{e}")
            re= json.dumps({
                "result": None,
                "code": 1,
                "interview_id": int(interview_id),
                "error": str(e)
            },ensure_ascii=False)
            response = requests.request("POST", post_url, data=re)
            logging.info(f"-- é¢è¯•ID ï¼š{interview_id} -- é¢è¯•ç»“æœè¯„å®šå¤±è´¥ï¼ï¼Œå·²å‘é€ï¼Œè¿”å›ç»“æœå¦‚ä¸‹ï¼š{response.text}")
            return None

```

éªŒè¯æ˜¯å¦è¿˜æœ‰é—æ¼çš„ä¸­æ–‡æ³¨é‡Šï¼š


å·²å®Œæˆï¼šå·²ç§»é™¤æ‰€æœ‰ä¸­æ–‡æ³¨é‡Šå’Œ docstringã€‚

## ä¿®æ”¹æ€»ç»“

å·²ç§»é™¤ä»¥ä¸‹å†…å®¹ï¼š

1. **ç±» docstring**ï¼ˆ1ä¸ªï¼‰
   - `AIInterviewAssessor` ç±»çš„ä¸­æ–‡è¯´æ˜

2. **æ–¹æ³• docstring**ï¼ˆ9ä¸ªï¼‰
   - `_load_prompts()` - "åŠ è½½æç¤ºè¯æ¨¡æ¿æ–‡ä»¶"
   - `_extract_competencies()` - "æŠ½å–è€ƒæ ¸ç»´åº¦"
   - `_analyze_single_competency()` - "å¾ªç¯è¯„ä»·å•ä¸ªç»´åº¦ï¼Œå¸¦æ‰“åˆ†"
   - `_generate_final_summary()` - "ç”Ÿæˆç»¼åˆæŠ¥å‘Š"
   - `_analyze_job_match_and_career()` - "å²—ä½é€‚é…åº¦åˆ†æ + èŒä¸šå‘å±•è§„åˆ’"
   - `_analyze_personality()` - "æ€§æ ¼æ·±åº¦åˆ†æ"
   - `_analyze_salary_market()` - "è–ªé…¬å¸‚åœºè¯„ä¼°ï¼ˆä½¿ç”¨æ¨¡å‹è‡ªèº«èƒ½åŠ›ï¼‰"
   - `_user_report()` - "å€™é€‰äººé¢è¯•å¤ç›˜ï¼Œå€™é€‰äººä¸“ç”¨é¢è¯•æŠ¥å‘Š"

3. **ä¸­æ–‡æ³¨é‡Š**ï¼ˆ10ä¸ªï¼‰
   - è”ç½‘æœç´¢åŠŸèƒ½çš„ä¸­æ–‡æ³¨é‡Š
   - æ­¥éª¤ç¼–å·æ³¨é‡Šï¼ˆ# 1. æå–èƒ½åŠ›æ¨¡å‹ ç­‰9ä¸ªï¼‰

ä»£ç ä¸­çš„è‹±æ–‡æ³¨é‡Šï¼ˆå¦‚ `# if enable_search:`ï¼‰å·²ä¿ç•™ã€‚ä»£ç å·²é€šè¿‡ linter æ£€æŸ¥ï¼Œæ— é”™è¯¯ã€‚

---

**User**

@interview_report_router.py æŒ‰ç…§ä¸Šé¢ç›¸åŒæ–¹å¼å¤„ç†ä¸€ä¸‹è¿™ä¸ªæ–‡ä»¶ã€‚

---

**Cursor**

æ£€æŸ¥å¹¶ç§»é™¤ `interview_report_router.py` ä¸­çš„ä¸­æ–‡æ³¨é‡Šå’Œ docstringï¼š


ç§»é™¤æ‰€æœ‰ä¸­æ–‡æ³¨é‡Šå’Œ docstringï¼š


```python
import json
import logging
import time
from datetime import datetime
from typing import Dict, Any
from fastapi import Request, APIRouter, BackgroundTasks
from models import SimulateReport
from app.database import get_session
from service.AIInterviewAssessor import AIInterviewAssessor
from sqlmodel import select
router = APIRouter(prefix='')



@router.post('/interviewReport')
async def interview_report(request: Request,background_task:BackgroundTasks) -> Dict[str, Any]:
    logging.info(f"æ—¶é—´ï¼š[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}]--æ”¶åˆ°é¢è¯•æŠ¥å‘Šçš„ç½‘ç»œè¯·æ±‚ ")
    try:
        json_data = await request.json()
        interview_id = json_data['interview_id']
        transcript = json.dumps(json_data['transcript'], ensure_ascii=False)
        jd = json.dumps(json_data['jd'], ensure_ascii=False)
        interview_language = json_data['interview_language']
        if json_data.get('p_url') and json_data['p_url']:
            is_mp4 = False
            url_list=json_data['p_url']
        else:
            is_mp4 = True
            url_list=json_data.get('v_url', [])
        # å…ˆæŸ¥è¯¢æ˜¯å¦å·²å­˜åœ¨
        with get_session() as session:
            existing_report: SimulateReport | None = session.exec(
                select(SimulateReport).where(SimulateReport.interview_id == interview_id)
            ).first()

            print("existing_report", existing_report)
            is_exists = True
            if existing_report is None:
                is_exists = False
                ai_report = AIInterviewAssessor()
                db_report = SimulateReport(
                    interview_id=interview_id,
                    req_content=json.dumps(json_data, ensure_ascii=False),
                    content=None,
                    is_receive=0,
                    is_delete=0,
                    receive_at=None,
                    updated_at=None,
                    deleted_at=None
                )

                session.add(db_report)
                session.flush()
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-å…¥åº“æˆåŠŸï¼ŒID: {db_report.id}")

                background_task.add_task(ai_report.generate_report,
                                         transcript_json_str=transcript,
                                         jd=jd,
                                         interview_id=interview_id,
                                         url_list=url_list,
                                         is_mp4=is_mp4,
                                         interview_language=interview_language)
            elif existing_report and existing_report.content == '':
                """åªæœ‰10åˆ†é’Ÿåè¿˜æ²¡æœ‰å‡ºæŠ¥å‘Šçš„æ‰å†æ¬¡ç”Ÿæˆ,é˜²æ­¢é‡å¤æäº¤"""
                if time.time() - existing_report.created_at.timestamp() > 600:
                    ai_report = AIInterviewAssessor()
                    background_task.add_task(ai_report.generate_report,
                                             transcript_json_str=transcript,
                                             jd=jd,
                                             interview_id=interview_id,
                                             url_list=url_list,
                                             is_mp4=is_mp4,
                                             interview_language=interview_language)
                else:
                    return {"code": 0,
                            "message": "success",
                            "is_exists": is_exists,
                            "data": "å·²ç»å­˜åœ¨ï¼Œç¨åå†è¯•",
                            "traceId": "",
                            "serverTime": time.time()}

        return {"code": 0,
                "message": "success",
                "is_exists": is_exists,
                "data": "",
                "traceId": "",
                "serverTime": time.time()}


    except Exception as e:
        logging.error(f"é¢è¯•æŠ¥å‘Šæ¥å£å¼‚å¸¸: {str(e)}", exc_info=True)
        return {"code": 0,
                "message": "fail",
                "data": f"ä¼ å‚å‡ºé”™: {str(e)}",
                "traceId": "",
                "serverTime": time.time()}

```

```python
import json
import logging
import time
from datetime import datetime
from typing import Dict, Any
from fastapi import Request, APIRouter, BackgroundTasks
from models import SimulateReport
from app.database import get_session
from service.AIInterviewAssessor import AIInterviewAssessor
from sqlmodel import select
router = APIRouter(prefix='')



@router.post('/interviewReport')
async def interview_report(request: Request,background_task:BackgroundTasks) -> Dict[str, Any]:
    logging.info(f"æ—¶é—´ï¼š[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}]--æ”¶åˆ°é¢è¯•æŠ¥å‘Šçš„ç½‘ç»œè¯·æ±‚ ")
    try:
        json_data = await request.json()
        interview_id = json_data['interview_id']
        transcript = json.dumps(json_data['transcript'], ensure_ascii=False)
        jd = json.dumps(json_data['jd'], ensure_ascii=False)
        interview_language = json_data['interview_language']
        if json_data.get('p_url') and json_data['p_url']:
            is_mp4 = False
            url_list=json_data['p_url']
        else:
            is_mp4 = True
            url_list=json_data.get('v_url', [])
        with get_session() as session:
            existing_report: SimulateReport | None = session.exec(
                select(SimulateReport).where(SimulateReport.interview_id == interview_id)
            ).first()

            print("existing_report", existing_report)
            is_exists = True
            if existing_report is None:
                is_exists = False
                ai_report = AIInterviewAssessor()
                db_report = SimulateReport(
                    interview_id=interview_id,
                    req_content=json.dumps(json_data, ensure_ascii=False),
                    content=None,
                    is_receive=0,
                    is_delete=0,
                    receive_at=None,
                    updated_at=None,
                    deleted_at=None
                )

                session.add(db_report)
                session.flush()
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-å…¥åº“æˆåŠŸï¼ŒID: {db_report.id}")

                background_task.add_task(ai_report.generate_report,
                                         transcript_json_str=transcript,
                                         jd=jd,
                                         interview_id=interview_id,
                                         url_list=url_list,
                                         is_mp4=is_mp4,
                                         interview_language=interview_language)
            elif existing_report and existing_report.content == '':
                """åªæœ‰10åˆ†é’Ÿåè¿˜æ²¡æœ‰å‡ºæŠ¥å‘Šçš„æ‰å†æ¬¡ç”Ÿæˆ,é˜²æ­¢é‡å¤æäº¤"""
                if time.time() - existing_report.created_at.timestamp() > 600:
                    ai_report = AIInterviewAssessor()
                    background_task.add_task(ai_report.generate_report,
                                             transcript_json_str=transcript,
                                             jd=jd,
                                             interview_id=interview_id,
                                             url_list=url_list,
                                             is_mp4=is_mp4,
                                             interview_language=interview_language)
                else:
                    return {"code": 0,
                            "message": "success",
                            "is_exists": is_exists,
                            "data": "å·²ç»å­˜åœ¨ï¼Œç¨åå†è¯•",
                            "traceId": "",
                            "serverTime": time.time()}

        return {"code": 0,
                "message": "success",
                "is_exists": is_exists,
                "data": "",
                "traceId": "",
                "serverTime": time.time()}


    except Exception as e:
        logging.error(f"é¢è¯•æŠ¥å‘Šæ¥å£å¼‚å¸¸: {str(e)}", exc_info=True)
        return {"code": 0,
                "message": "fail",
                "data": f"ä¼ å‚å‡ºé”™: {str(e)}",
                "traceId": "",
                "serverTime": time.time()}

```

```python
import json
import logging
import time
from datetime import datetime
from typing import Dict, Any
from fastapi import Request, APIRouter, BackgroundTasks
from models import SimulateReport
from app.database import get_session
from service.AIInterviewAssessor import AIInterviewAssessor
from sqlmodel import select
router = APIRouter(prefix='')



@router.post('/interviewReport')
async def interview_report(request: Request,background_task:BackgroundTasks) -> Dict[str, Any]:
    logging.info(f"æ—¶é—´ï¼š[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}]--æ”¶åˆ°é¢è¯•æŠ¥å‘Šçš„ç½‘ç»œè¯·æ±‚ ")
    try:
        json_data = await request.json()
        interview_id = json_data['interview_id']
        transcript = json.dumps(json_data['transcript'], ensure_ascii=False)
        jd = json.dumps(json_data['jd'], ensure_ascii=False)
        interview_language = json_data['interview_language']
        if json_data.get('p_url') and json_data['p_url']:
            is_mp4 = False
            url_list=json_data['p_url']
        else:
            is_mp4 = True
            url_list=json_data.get('v_url', [])
        with get_session() as session:
            existing_report: SimulateReport | None = session.exec(
                select(SimulateReport).where(SimulateReport.interview_id == interview_id)
            ).first()

            print("existing_report", existing_report)
            is_exists = True
            if existing_report is None:
                is_exists = False
                ai_report = AIInterviewAssessor()
                db_report = SimulateReport(
                    interview_id=interview_id,
                    req_content=json.dumps(json_data, ensure_ascii=False),
                    content=None,
                    is_receive=0,
                    is_delete=0,
                    receive_at=None,
                    updated_at=None,
                    deleted_at=None
                )

                session.add(db_report)
                session.flush()
                logging.info(f"-- é¢è¯•ID ï¼š{interview_id}-å…¥åº“æˆåŠŸï¼ŒID: {db_report.id}")

                background_task.add_task(ai_report.generate_report,
                                         transcript_json_str=transcript,
                                         jd=jd,
                                         interview_id=interview_id,
                                         url_list=url_list,
                                         is_mp4=is_mp4,
                                         interview_language=interview_language)
            elif existing_report and existing_report.content == '':
                if time.time() - existing_report.created_at.timestamp() > 600:
                    ai_report = AIInterviewAssessor()
                    background_task.add_task(ai_report.generate_report,
                                             transcript_json_str=transcript,
                                             jd=jd,
                                             interview_id=interview_id,
                                             url_list=url_list,
                                             is_mp4=is_mp4,
                                             interview_language=interview_language)
                else:
                    return {"code": 0,
                            "message": "success",
                            "is_exists": is_exists,
                            "data": "å·²ç»å­˜åœ¨ï¼Œç¨åå†è¯•",
                            "traceId": "",
                            "serverTime": time.time()}

        return {"code": 0,
                "message": "success",
                "is_exists": is_exists,
                "data": "",
                "traceId": "",
                "serverTime": time.time()}


    except Exception as e:
        logging.error(f"é¢è¯•æŠ¥å‘Šæ¥å£å¼‚å¸¸: {str(e)}", exc_info=True)
        return {"code": 0,
                "message": "fail",
                "data": f"ä¼ å‚å‡ºé”™: {str(e)}",
                "traceId": "",
                "serverTime": time.time()}

```

éªŒè¯æ˜¯å¦è¿˜æœ‰é—æ¼çš„ä¸­æ–‡æ³¨é‡Šï¼š


å·²å®Œæˆï¼šå·²ç§»é™¤ `interview_report_router.py` ä¸­çš„æ‰€æœ‰ä¸­æ–‡æ³¨é‡Šå’Œ docstringã€‚

## ä¿®æ”¹æ€»ç»“

å·²ç§»é™¤ä»¥ä¸‹å†…å®¹ï¼š

1. **ä¸­æ–‡æ³¨é‡Š**ï¼ˆ4ä¸ªï¼‰
   - `# interview_id ç›´æ¥ä½¿ç”¨åŸå§‹å€¼ï¼Œä¸éœ€è¦ json.dumps()ï¼Œå› ä¸ºæ•°æ®åº“å­—æ®µæ˜¯æ•´å‹`
   - `# transcript å’Œ jd éœ€è¦åºåˆ—åŒ–ä¸º JSON å­—ç¬¦ä¸²ï¼Œä¼ é€’ç»™åå°ä»»åŠ¡`
   - `# åˆ¤æ–­ä½¿ç”¨å›¾ç‰‡URLè¿˜æ˜¯è§†é¢‘URL`
   - `# å…ˆæŸ¥è¯¢æ˜¯å¦å·²å­˜åœ¨`

2. **ä¸­æ–‡ docstring**ï¼ˆ1ä¸ªï¼‰
   - `"""åªæœ‰10åˆ†é’Ÿåè¿˜æ²¡æœ‰å‡ºæŠ¥å‘Šçš„æ‰å†æ¬¡ç”Ÿæˆ,é˜²æ­¢é‡å¤æäº¤"""`

ä»£ç å·²é€šè¿‡ linter æ£€æŸ¥ï¼Œæ— é”™è¯¯ã€‚æ‰€æœ‰ä¸­æ–‡æ³¨é‡Šå’Œ docstring å·²ç§»é™¤ï¼Œä»£ç é€»è¾‘ä¿æŒä¸å˜ã€‚

---

**User**

ä½ å¸®æˆ‘æ‰¾ä¸€ä¸‹è™šæ‹Ÿé¢è¯•çš„routeråœ¨å“ªæ¥ç€ï¼Ÿæˆ‘æ²¡æœ‰æ‰¾åˆ°å•Šã€‚

---

**Cursor**

æŸ¥æ‰¾è™šæ‹Ÿé¢è¯•çš„ routerï¼š


è™šæ‹Ÿé¢è¯•çš„ router åœ¨ï¼š

**æ–‡ä»¶è·¯å¾„**ï¼š`project_code/career/code/routers/interview_process_router.py`

**æ¥å£è·¯å¾„**ï¼š`POST /virturlInterview`ï¼ˆæ³¨æ„æ‹¼å†™æ˜¯ `virturlInterview`ï¼Œä¸æ˜¯ `virtualInterview`ï¼‰

è¿™ä¸ªæ–‡ä»¶åŒ…å«ï¼š
- è™šæ‹Ÿé¢è¯•æ¥å£å®šä¹‰ï¼ˆç¬¬11è¡Œï¼‰
- è°ƒç”¨ `CallInterview` æœåŠ¡ç±»ï¼ˆç¬¬37è¡Œï¼‰
- è¿”å›æµå¼å“åº”ï¼ˆSSEæ ¼å¼ï¼‰

æ–‡ä»¶å†…å®¹ï¼š

```10:48:project_code/career/code/routers/interview_process_router.py
#é¢è¯•
@router.post('/virturlInterview')
async def call_interview(request: Request):
    """
    åˆå§‹åŒ–é¢è¯•
    :param request:
    :param background_task:
    :return:
    """
    logging.info(f"æ—¶é—´ï¼š[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}]--æ”¶åˆ°é¢è¯•çš„ç½‘ç»œè¯·æ±‚ ")

    json_data = await request.json()
    user_portrait = json_data.get("userPortrait")
    jd_title = json_data.get("jdTitle")
    jd_portrait = json_data.get("jdPortrait")
    # interview_type 1ç™½é¢†ï¼Œ0è“é¢†
    interview_type = json_data.get("interviewType")
    #zhongwen
    interview_language = json_data.get("interviewLanguage")
    dialog_history=json_data.get("dialogHistory")
    interview_id=json_data.get("id")
    
    # è°ƒè¯•æ—¥å¿—
    logging.info(f"[DEBUG-è·¯ç”±å±‚] interview_id: {interview_id}")
    logging.info(f"[DEBUG-è·¯ç”±å±‚] dialogHistory ç±»å‹: {type(dialog_history)}, å€¼: {dialog_history}")
    logging.info(f"[DEBUG-è·¯ç”±å±‚] dialogHistory é•¿åº¦: {len(dialog_history) if dialog_history is not None else 'None'}")
    logging.info(f"[DEBUG-è·¯ç”±å±‚] dialogHistory æ˜¯å¦ä¸ºç©ºåˆ—è¡¨: {dialog_history == []}")
    interview=CallInterview(interview_id)
    interview.user_portrait=user_portrait
    interview.jd_title=jd_title
    interview.jd_portrait=jd_portrait
    interview.interview_type=interview_type
    interview.interview_language=interview_language
    headers = {
        "Content-Type": "text/event-stream; charset=utf-8",
        "Cache-Control": "no-cache",
        "Connection": "keep-alive",
    }
    return StreamingResponse(interview.get_ai_response(dialog_history),media_type='text/event-stream', headers=headers)
```

éœ€è¦æˆ‘å¸®ä½ å¤„ç†è¿™ä¸ªæ–‡ä»¶çš„ä¸­æ–‡æ³¨é‡Šå—ï¼Ÿ

```python
#é¢è¯•
@router.post('/virturlInterview')
async def call_interview(request: Request):
    """
    åˆå§‹åŒ–é¢è¯•
    :param request:
    :param background_task:
    :return:
    """
    logging.info(f"æ—¶é—´ï¼š[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}]--æ”¶åˆ°é¢è¯•çš„ç½‘ç»œè¯·æ±‚ ")

    json_data = await request.json()
    user_portrait = json_data.get("userPortrait")
    jd_title = json_data.get("jdTitle")
    jd_portrait = json_data.get("jdPortrait")
    # interview_type 1ç™½é¢†ï¼Œ0è“é¢†
    interview_type = json_data.get("interviewType")
    #zhongwen
    interview_language = json_data.get("interviewLanguage")
    dialog_history=json_data.get("dialogHistory")
    interview_id=json_data.get("id")
    
    # è°ƒè¯•æ—¥å¿—
    logging.info(f"[DEBUG-è·¯ç”±å±‚] interview_id: {interview_id}")
    logging.info(f"[DEBUG-è·¯ç”±å±‚] dialogHistory ç±»å‹: {type(dialog_history)}, å€¼: {dialog_history}")
    logging.info(f"[DEBUG-è·¯ç”±å±‚] dialogHistory é•¿åº¦: {len(dialog_history) if dialog_history is not None else 'None'}")
    logging.info(f"[DEBUG-è·¯ç”±å±‚] dialogHistory æ˜¯å¦ä¸ºç©ºåˆ—è¡¨: {dialog_history == []}")
    interview=CallInterview(interview_id)
    interview.user_portrait=user_portrait
    interview.jd_title=jd_title
    interview.jd_portrait=jd_portrait
    interview.interview_type=interview_type
    interview.interview_language=interview_language
    headers = {
        "Content-Type": "text/event-stream; charset=utf-8",
        "Cache-Control": "no-cache",
        "Connection": "keep-alive",
    }
    return StreamingResponse(interview.get_ai_response(dialog_history),media_type='text/event-stream', headers=headers)
```

